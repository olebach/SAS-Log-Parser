{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff22c905",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "In order to sucessfully launch the SAS Log Parser, the user has to perform the following steps:\n",
    "\n",
    "#### 1. Preparing the log\n",
    "The classical log outputted by SAS is not suited for parsing in SAS. Instead, it is required to use the log prepared by the proc scaproc procedure. Scaproc captures information about input, output, and the use of macro symbols from a SAS job while it is running, providing more information for the tool.\n",
    "\n",
    "In order to obtain the log, the user has to place two scaproc procedures (record and write) before and after the analyzed process:\n",
    "\n",
    "```{sas}\n",
    "/* SET PATH TO SAVE THE SCAPROC PROCEDURE LOG FILE*/\n",
    "%let path = path_to_store_txt_file;\n",
    "proc scaproc; \n",
    "   record \"&path./record.txt\" OPENTIMES EXPANDMACROS; \n",
    "run;\n",
    "\n",
    "/* PROCESS TO BE ANALYZED SHOULD BE PLACED HERE */\n",
    "\n",
    "/* WRITE LOG TO THE FILE IN PRIEVIOUSLY STATED FILE PATCH */\n",
    "proc scaproc; \n",
    "   write; \n",
    "run;\n",
    "```\n",
    "\n",
    "#### 2. Running the dashboard\n",
    "Once the scaproc log is obtained, it can be read into the Jupyter notebook where the code performs the following actions:\n",
    "1) **The Log parsing** section extracts the information form the txt file and prepares 3 tables: \n",
    "    df_log contains information on all the actions performed by the SAS process, \n",
    "    df_code is a short summary of the SAS code (code syntax, exection time, procedure used, etc. \n",
    "    df_connections contains the information about all tables used in the process and their relationships\n",
    "\n",
    "2) **The Graph Data** section generates a networkx Graph and preforms network analysis on the table connections.\n",
    "\n",
    "3) **The Dash plot** section creates all components necessary for the dashboard visualisation (network plot, table, interactions, etc.) and launches a local Dash server for the dashboard under <http://127.0.0.1:8050/>\n",
    "\n",
    "#### 3. Dashboard features\n",
    "The dashboard has 3 functionalities encoded for performing SAS code analysis:\n",
    "\n",
    "1) **Table filtering** - dash tables support filtering operations, e.g. comparison operators (>, gt, <=, le), string search (contains <table_name>) or multiple conditions ( {Task ID} = 1 or {Task ID} = 10). Once the data is filtered, the data in the network graph will adjust accordingly to highlight corresponding tables and connections. For more information oon filter queries please consult <https://dash.plotly.com/datatable/filtering>.\n",
    "\n",
    "2) **Network selection** - the plotly graph has multiple operations availiable for plot view manipulation - zoom, pan, autoscale, etc. Additionally, if the user uses the select tool (Box select or Lasso select) to filter tables for analysis, the table will update in order to show the corresponding codes.\n",
    "\n",
    "3) **The Reset button** reverts the table and network plot to their initial state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83a556ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please specify the location of the txt file:\n",
    "path = 'sample_sas_log.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f494414b",
   "metadata": {},
   "source": [
    "# 1. Log parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0371fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# Plots\n",
    "import networkx as nx\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.offline as py\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Dash\n",
    "import dash\n",
    "import dash_table\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1489d9a",
   "metadata": {},
   "source": [
    "#### 1.1 Extract df from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62547408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Task Type</th>\n",
       "      <th>Task ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JOBSTARTTIME 26AUG2021:19:24:29.94</td>\n",
       "      <td>JOBSTARTTIME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TASKSTARTTIME 26AUG2021:19:24:29.94</td>\n",
       "      <td>TASKSTARTTIME</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATASET INPUT SEQ #C00003.CLASS.DATA</td>\n",
       "      <td>DATASET</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LIBNAME #C00003 V9 '/opt/sas/bin/SASFoundation...</td>\n",
       "      <td>LIBNAME</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>ELAPSED 7</td>\n",
       "      <td>ELAPSED</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>PROCNAME SORT</td>\n",
       "      <td>PROCNAME</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>proc sort data=work.data3 out=work.sort1;\\n\\tb...</td>\n",
       "      <td>STEP</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>JOBENDTIME 26AUG2021:19:24:30.14</td>\n",
       "      <td>JOBENDTIME</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>END</td>\n",
       "      <td>END</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text      Task Type  Task ID\n",
       "0                                                                 NaN        0\n",
       "1                  JOBSTARTTIME 26AUG2021:19:24:29.94    JOBSTARTTIME        0\n",
       "2                 TASKSTARTTIME 26AUG2021:19:24:29.94   TASKSTARTTIME        1\n",
       "3                DATASET INPUT SEQ #C00003.CLASS.DATA         DATASET        1\n",
       "4    LIBNAME #C00003 V9 '/opt/sas/bin/SASFoundation...        LIBNAME        1\n",
       "..                                                 ...            ...      ...\n",
       "172                                        ELAPSED 7          ELAPSED       10\n",
       "173                                     PROCNAME SORT        PROCNAME       10\n",
       "174  proc sort data=work.data3 out=work.sort1;\\n\\tb...           STEP       10\n",
       "175                  JOBENDTIME 26AUG2021:19:24:30.14      JOBENDTIME       11\n",
       "176                                               END             END       11\n",
       "\n",
       "[177 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def txt_to_df(path):\n",
    "\n",
    "    # 1.1 Read Data\n",
    "    f = open(path, 'r')\n",
    "    content = f.read()\n",
    "    content_list = content.split('/* JOBSPLIT: ')\n",
    "    f.close()\n",
    "    df = pd.DataFrame(content_list, columns=['Text'])\n",
    "\n",
    "    # 1.2. Define Task type\n",
    "    df['Task Type'] = df[\"Text\"].str.split().str[0]\n",
    "\n",
    "    # 1.3 Assign Task ID\n",
    "    df = df.reset_index(drop=True)\n",
    "    task_list = [0] \n",
    "    for index, row in df.iterrows():\n",
    "        if (row['Task Type'] == 'TASKSTARTTIME') | (row['Task Type'] == 'JOBENDTIME'):\n",
    "            task_list.append(task_list[index] +1)\n",
    "        else:\n",
    "            task_list.append(task_list[index])   \n",
    "    df['Task ID'] = task_list[1:]\n",
    "\n",
    "    # 1.4 Remove unessesary text\n",
    "    df['Text'] = df[['Text','Task Type']].apply(lambda x: x[0].replace('\\n\\n','\\n').replace('STEP SOURCE FOLLOWS */\\n','') if x[1]=='STEP' \n",
    "                                                          else x[0].replace('*/\\n','')\n",
    "                                                , axis = 1)\n",
    "\n",
    "    df['Task ID'] = df['Task ID'].astype('int')\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_log = txt_to_df(path)\n",
    "df_log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c4d547",
   "metadata": {},
   "source": [
    "#### 1.2. Extract info about Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32a6868e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task ID</th>\n",
       "      <th>Code</th>\n",
       "      <th>Procedure</th>\n",
       "      <th>Start Time</th>\n",
       "      <th>Elapsed Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\\n/* YOUR CODE HERE*/\\n/* Step 1 */\\ndata work...</td>\n",
       "      <td>DATASTEP</td>\n",
       "      <td>2021-08-26 19:24:29.940</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>data work.data2;\\n\\tset work.data1;\\n\\tlog_h_w...</td>\n",
       "      <td>DATASTEP</td>\n",
       "      <td>2021-08-26 19:24:29.960</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>proc sql;\\n\\tcreate table work.procsql1 as\\n\\t...</td>\n",
       "      <td>SQL</td>\n",
       "      <td>2021-08-26 19:24:29.970</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>proc sql;\\n\\tcreate table work.procsql_join1 a...</td>\n",
       "      <td>SQL</td>\n",
       "      <td>2021-08-26 19:24:29.980</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>proc means data=sashelp.class;\\n\\tvar Age;\\nru...</td>\n",
       "      <td>MEANS</td>\n",
       "      <td>2021-08-26 19:24:29.990</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>proc freq data=sashelp.class;\\n\\ttable Sex;\\nr...</td>\n",
       "      <td>FREQ</td>\n",
       "      <td>2021-08-26 19:24:30.020</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>proc ttest data=sashelp.class;\\n class sex;\\n...</td>\n",
       "      <td>TTEST</td>\n",
       "      <td>2021-08-26 19:24:30.040</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>proc freq data=sashelp.cars;\\n table origin *...</td>\n",
       "      <td>FREQ</td>\n",
       "      <td>2021-08-26 19:24:30.070</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>data work.data3;\\n\\tset sashelp.class; where a...</td>\n",
       "      <td>DATASTEP</td>\n",
       "      <td>2021-08-26 19:24:30.110</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>proc sort data=work.data3 out=work.sort1;\\n\\tb...</td>\n",
       "      <td>SORT</td>\n",
       "      <td>2021-08-26 19:24:30.130</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Task ID                                               Code Procedure  \\\n",
       "0        1  \\n/* YOUR CODE HERE*/\\n/* Step 1 */\\ndata work...  DATASTEP   \n",
       "1        2  data work.data2;\\n\\tset work.data1;\\n\\tlog_h_w...  DATASTEP   \n",
       "2        3  proc sql;\\n\\tcreate table work.procsql1 as\\n\\t...       SQL   \n",
       "3        4  proc sql;\\n\\tcreate table work.procsql_join1 a...       SQL   \n",
       "4        5  proc means data=sashelp.class;\\n\\tvar Age;\\nru...     MEANS   \n",
       "5        6  proc freq data=sashelp.class;\\n\\ttable Sex;\\nr...      FREQ   \n",
       "6        7   proc ttest data=sashelp.class;\\n class sex;\\n...     TTEST   \n",
       "7        8   proc freq data=sashelp.cars;\\n table origin *...      FREQ   \n",
       "8        9  data work.data3;\\n\\tset sashelp.class; where a...  DATASTEP   \n",
       "9       10  proc sort data=work.data3 out=work.sort1;\\n\\tb...      SORT   \n",
       "\n",
       "                Start Time  Elapsed Time  \n",
       "0  2021-08-26 19:24:29.940         0.020  \n",
       "1  2021-08-26 19:24:29.960         0.006  \n",
       "2  2021-08-26 19:24:29.970         0.007  \n",
       "3  2021-08-26 19:24:29.980         0.009  \n",
       "4  2021-08-26 19:24:29.990         0.029  \n",
       "5  2021-08-26 19:24:30.020         0.021  \n",
       "6  2021-08-26 19:24:30.040         0.032  \n",
       "7  2021-08-26 19:24:30.070         0.035  \n",
       "8  2021-08-26 19:24:30.110         0.020  \n",
       "9  2021-08-26 19:24:30.130         0.007  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def df_to_code(df):\n",
    "\n",
    "    #-------------------------------------------\n",
    "    # 2.1 Extract the Code Syntax\n",
    "    df_code = df.loc[(df_log['Task Type'].isin(['STEP']))].copy()\n",
    "    df_code.drop(['Task Type'], inplace=True, axis=1)\n",
    "    df_code = df_code.rename(columns={'Text': 'Code'})\n",
    "    df_code = df_code[['Task ID', 'Code']]\n",
    "\n",
    "    #-------------------------------------------\n",
    "    # 2.2. Prepare info about Start Time\n",
    "    df_taskstarttime = df_log.loc[(df_log['Task Type'].isin(['TASKSTARTTIME']))].copy()\n",
    "    df_taskstarttime['Start Time'] = df_taskstarttime['Text'].str.split().str[1]\n",
    "    df_taskstarttime['Start Time'] = pd.to_datetime(df_taskstarttime['Start Time'], format='%d%b%Y:%H:%M:%S.%f')\n",
    "    df_taskstarttime.drop(['Text', 'Task Type'], inplace=True, axis=1)\n",
    "\n",
    "    #-------------------------------------------\n",
    "    # 2.3. Prepare info about Elapsed Time\n",
    "    df_elapsedtime = df_log.loc[(df_log['Task Type'].isin(['ELAPSED']))].copy()\n",
    "    df_elapsedtime['Elapsed Time'] = df_elapsedtime['Text'].str.split().str[1].astype('int')/1000\n",
    "    df_elapsedtime.drop(['Text', 'Task Type'], inplace=True, axis=1)\n",
    "\n",
    "    #-------------------------------------------\n",
    "    # 2.4. Prepare info about Procedure Names\n",
    "    df_procedure = df_log.loc[(df_log['Task Type'].isin(['PROCNAME']))].copy()\n",
    "    df_procedure['Procedure'] = df_procedure['Text'].str.split().str[1]\n",
    "    df_procedure.drop(['Text', 'Task Type'], inplace=True, axis=1)\n",
    "\n",
    "    #-------------------------------------------\n",
    "    # 2.5 Output\n",
    "    df_code = df_code.merge(df_procedure, on=['Task ID'], how = 'outer')\\\n",
    "                     .merge(df_taskstarttime, on=['Task ID'], how = 'outer')\\\n",
    "                     .merge(df_elapsedtime, on=['Task ID'], how = 'outer')\n",
    "    \n",
    "    df_code['Start Time'] = df_code['Start Time'].astype('str')\n",
    "    df_code['Task ID'] = df_code['Task ID'].astype('int')\n",
    "    \n",
    "    return df_code\n",
    "\n",
    "df_code = df_to_code(df_log)\n",
    "df_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d1ed38",
   "metadata": {},
   "source": [
    "#### 1.3. Extract Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b3953c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task ID</th>\n",
       "      <th>SubTask ID</th>\n",
       "      <th>Source ID</th>\n",
       "      <th>Target ID</th>\n",
       "      <th>Input Table</th>\n",
       "      <th>Output Table</th>\n",
       "      <th>Start Time</th>\n",
       "      <th>Elapsed Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0:0:#C00003.CLASS:DATA</td>\n",
       "      <td>1:1:WORK.DATA1:DATA</td>\n",
       "      <td>#C00003.CLASS</td>\n",
       "      <td>WORK.DATA1</td>\n",
       "      <td>2021-08-26 19:24:29.940</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1:1:WORK.DATA1:DATA</td>\n",
       "      <td>2:1:WORK.DATA2:DATA</td>\n",
       "      <td>WORK.DATA1</td>\n",
       "      <td>WORK.DATA2</td>\n",
       "      <td>2021-08-26 19:24:29.960</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2:1:WORK.DATA2:DATA</td>\n",
       "      <td>3:1:WORK.PROCSQL1:DATA</td>\n",
       "      <td>WORK.DATA2</td>\n",
       "      <td>WORK.PROCSQL1</td>\n",
       "      <td>2021-08-26 19:24:29.970</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1:1:WORK.DATA1:DATA</td>\n",
       "      <td>4:1:WORK.PROCSQL_JOIN1:DATA</td>\n",
       "      <td>WORK.DATA1</td>\n",
       "      <td>WORK.PROCSQL_JOIN1</td>\n",
       "      <td>2021-08-26 19:24:29.980</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2:1:WORK.DATA2:DATA</td>\n",
       "      <td>4:1:WORK.PROCSQL_JOIN1:DATA</td>\n",
       "      <td>WORK.DATA2</td>\n",
       "      <td>WORK.PROCSQL_JOIN1</td>\n",
       "      <td>2021-08-26 19:24:29.980</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0:0:#C00003.CLASS:DATA</td>\n",
       "      <td>5:1:No Output:Empty</td>\n",
       "      <td>#C00003.CLASS</td>\n",
       "      <td>_null_</td>\n",
       "      <td>2021-08-26 19:24:29.990</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0:0:#C00003.CLASS:DATA</td>\n",
       "      <td>6:1:WORK.'SASTMP-000000401':UTILITY</td>\n",
       "      <td>#C00003.CLASS</td>\n",
       "      <td>WORK.'SASTMP-000000401'</td>\n",
       "      <td>2021-08-26 19:24:30.020</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0:0:WORK.'SASTMP-000000401':UTILITY</td>\n",
       "      <td>6:1:WORK.'SASTMP-000000401':UTILITY</td>\n",
       "      <td>WORK.'SASTMP-000000401'</td>\n",
       "      <td>WORK.'SASTMP-000000401'</td>\n",
       "      <td>2021-08-26 19:24:30.020</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0:0:#C00003.CLASS:DATA</td>\n",
       "      <td>7:1:No Output:Empty</td>\n",
       "      <td>#C00003.CLASS</td>\n",
       "      <td>_null_</td>\n",
       "      <td>2021-08-26 19:24:30.040</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0:0:#C00003.CARS:DATA</td>\n",
       "      <td>8:1:WORK.'SASTMP-000000404':UTILITY</td>\n",
       "      <td>#C00003.CARS</td>\n",
       "      <td>WORK.'SASTMP-000000404'</td>\n",
       "      <td>2021-08-26 19:24:30.070</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0:0:#C00003.CARS:DATA</td>\n",
       "      <td>8:1:WORK.'SASTMP-000000405':UTILITY</td>\n",
       "      <td>#C00003.CARS</td>\n",
       "      <td>WORK.'SASTMP-000000405'</td>\n",
       "      <td>2021-08-26 19:24:30.070</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0:0:WORK.'SASTMP-000000404':UTILITY</td>\n",
       "      <td>8:1:WORK.'SASTMP-000000404':UTILITY</td>\n",
       "      <td>WORK.'SASTMP-000000404'</td>\n",
       "      <td>WORK.'SASTMP-000000404'</td>\n",
       "      <td>2021-08-26 19:24:30.070</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0:0:WORK.'SASTMP-000000404':UTILITY</td>\n",
       "      <td>8:1:WORK.'SASTMP-000000405':UTILITY</td>\n",
       "      <td>WORK.'SASTMP-000000404'</td>\n",
       "      <td>WORK.'SASTMP-000000405'</td>\n",
       "      <td>2021-08-26 19:24:30.070</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0:0:WORK.'SASTMP-000000405':UTILITY</td>\n",
       "      <td>8:1:WORK.'SASTMP-000000404':UTILITY</td>\n",
       "      <td>WORK.'SASTMP-000000405'</td>\n",
       "      <td>WORK.'SASTMP-000000404'</td>\n",
       "      <td>2021-08-26 19:24:30.070</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0:0:WORK.'SASTMP-000000405':UTILITY</td>\n",
       "      <td>8:1:WORK.'SASTMP-000000405':UTILITY</td>\n",
       "      <td>WORK.'SASTMP-000000405'</td>\n",
       "      <td>WORK.'SASTMP-000000405'</td>\n",
       "      <td>2021-08-26 19:24:30.070</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0:0:#C00003.CLASS:DATA</td>\n",
       "      <td>9:1:WORK.DATA3:DATA</td>\n",
       "      <td>#C00003.CLASS</td>\n",
       "      <td>WORK.DATA3</td>\n",
       "      <td>2021-08-26 19:24:30.110</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>9:1:WORK.DATA3:DATA</td>\n",
       "      <td>10:1:WORK.SORT1:DATA</td>\n",
       "      <td>WORK.DATA3</td>\n",
       "      <td>WORK.SORT1</td>\n",
       "      <td>2021-08-26 19:24:30.130</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Task ID  SubTask ID                            Source ID  \\\n",
       "0         1           1               0:0:#C00003.CLASS:DATA   \n",
       "1         2           1                  1:1:WORK.DATA1:DATA   \n",
       "2         3           1                  2:1:WORK.DATA2:DATA   \n",
       "3         4           1                  1:1:WORK.DATA1:DATA   \n",
       "4         4           1                  2:1:WORK.DATA2:DATA   \n",
       "5         5           1               0:0:#C00003.CLASS:DATA   \n",
       "6         6           1               0:0:#C00003.CLASS:DATA   \n",
       "7         6           1  0:0:WORK.'SASTMP-000000401':UTILITY   \n",
       "8         7           1               0:0:#C00003.CLASS:DATA   \n",
       "9         8           1                0:0:#C00003.CARS:DATA   \n",
       "10        8           1                0:0:#C00003.CARS:DATA   \n",
       "11        8           1  0:0:WORK.'SASTMP-000000404':UTILITY   \n",
       "12        8           1  0:0:WORK.'SASTMP-000000404':UTILITY   \n",
       "13        8           1  0:0:WORK.'SASTMP-000000405':UTILITY   \n",
       "14        8           1  0:0:WORK.'SASTMP-000000405':UTILITY   \n",
       "15        9           1               0:0:#C00003.CLASS:DATA   \n",
       "16       10           1                  9:1:WORK.DATA3:DATA   \n",
       "\n",
       "                              Target ID              Input Table  \\\n",
       "0                   1:1:WORK.DATA1:DATA            #C00003.CLASS   \n",
       "1                   2:1:WORK.DATA2:DATA               WORK.DATA1   \n",
       "2                3:1:WORK.PROCSQL1:DATA               WORK.DATA2   \n",
       "3           4:1:WORK.PROCSQL_JOIN1:DATA               WORK.DATA1   \n",
       "4           4:1:WORK.PROCSQL_JOIN1:DATA               WORK.DATA2   \n",
       "5                   5:1:No Output:Empty            #C00003.CLASS   \n",
       "6   6:1:WORK.'SASTMP-000000401':UTILITY            #C00003.CLASS   \n",
       "7   6:1:WORK.'SASTMP-000000401':UTILITY  WORK.'SASTMP-000000401'   \n",
       "8                   7:1:No Output:Empty            #C00003.CLASS   \n",
       "9   8:1:WORK.'SASTMP-000000404':UTILITY             #C00003.CARS   \n",
       "10  8:1:WORK.'SASTMP-000000405':UTILITY             #C00003.CARS   \n",
       "11  8:1:WORK.'SASTMP-000000404':UTILITY  WORK.'SASTMP-000000404'   \n",
       "12  8:1:WORK.'SASTMP-000000405':UTILITY  WORK.'SASTMP-000000404'   \n",
       "13  8:1:WORK.'SASTMP-000000404':UTILITY  WORK.'SASTMP-000000405'   \n",
       "14  8:1:WORK.'SASTMP-000000405':UTILITY  WORK.'SASTMP-000000405'   \n",
       "15                  9:1:WORK.DATA3:DATA            #C00003.CLASS   \n",
       "16                 10:1:WORK.SORT1:DATA               WORK.DATA3   \n",
       "\n",
       "               Output Table              Start Time  Elapsed Time  \n",
       "0                WORK.DATA1 2021-08-26 19:24:29.940          0.02  \n",
       "1                WORK.DATA2 2021-08-26 19:24:29.960          0.01  \n",
       "2             WORK.PROCSQL1 2021-08-26 19:24:29.970          0.01  \n",
       "3        WORK.PROCSQL_JOIN1 2021-08-26 19:24:29.980          0.01  \n",
       "4        WORK.PROCSQL_JOIN1 2021-08-26 19:24:29.980          0.01  \n",
       "5                    _null_ 2021-08-26 19:24:29.990          0.03  \n",
       "6   WORK.'SASTMP-000000401' 2021-08-26 19:24:30.020          0.02  \n",
       "7   WORK.'SASTMP-000000401' 2021-08-26 19:24:30.020          0.02  \n",
       "8                    _null_ 2021-08-26 19:24:30.040          0.03  \n",
       "9   WORK.'SASTMP-000000404' 2021-08-26 19:24:30.070          0.04  \n",
       "10  WORK.'SASTMP-000000405' 2021-08-26 19:24:30.070          0.04  \n",
       "11  WORK.'SASTMP-000000404' 2021-08-26 19:24:30.070          0.04  \n",
       "12  WORK.'SASTMP-000000405' 2021-08-26 19:24:30.070          0.04  \n",
       "13  WORK.'SASTMP-000000404' 2021-08-26 19:24:30.070          0.04  \n",
       "14  WORK.'SASTMP-000000405' 2021-08-26 19:24:30.070          0.04  \n",
       "15               WORK.DATA3 2021-08-26 19:24:30.110          0.02  \n",
       "16               WORK.SORT1 2021-08-26 19:24:30.130          0.01  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def df_to_connections(df):\n",
    "    \n",
    "    #-------------------------------------------\n",
    "    # 3.1 Extract Table info\n",
    "    # 3.1.a Get data\n",
    "    df_tables = df.loc[(df['Task Type'].isin(['DATASET', 'OPENTIME', 'TASKSTARTTIME',  'JOBENDTIME']))].copy()   \n",
    "\n",
    "    # 3.1.b # Extract table name and type\n",
    "    df_tables['Table'] = df_tables[['Text','Task Type']].apply(lambda x: x[0].split()[3]  if x[1]=='DATASET' \n",
    "                                                                         else (x[0].split()[1]   if x[1]=='OPENTIME' \n",
    "                                                                               else '')\n",
    "                                                               , axis = 1)\n",
    "    df_tables['Table type'] = df_tables['Table'].str.split('.').str[-1]                          # Extract table type\n",
    "    df_tables['Table'] = df_tables['Table'].apply(lambda x: '.'.join(x.split('.')[:-1]))         # Extract table name\n",
    "\n",
    "    # 3.1.c Define table type (Input, Output, Update)\n",
    "    df_tables['Dataset type'] = df_tables[['Text', 'Task Type']].apply(lambda x: x[0].split()[1]  if x[1]=='DATASET'\n",
    "                                                                                 else ''\n",
    "                                                                       , axis = 1)\n",
    "    df_tables['Dataset type'] = np.where(df_tables['Task Type'].isin(['OPENTIME']),\n",
    "                                          df_tables['Dataset type'].shift(),                     # Inherit table type\n",
    "                                          df_tables['Dataset type'])\n",
    "    \n",
    "    # 3.1.d Add sub-step indicator\n",
    "    df_tables = df_tables.reset_index(drop=True)\n",
    "    df_tables['Lag Task ID'] = df_tables['Task ID'].shift()\n",
    "    df_tables['Lag Dataset type'] = df_tables['Dataset type'].shift()\n",
    "    sub_step_list = [1]\n",
    "    for index, row in df_tables.iterrows():\n",
    "        if (row['Task ID'] != row['Lag Task ID']):\n",
    "            sub_step_list.append(1)                       # Reset sub-step\n",
    "        elif ((row['Lag Dataset type'] == 'OUTPUT') & (row['Dataset type'] == 'INPUT')) | \\\n",
    "             ((row['Lag Dataset type'] == 'OUTPUT') & (row['Dataset type'] == 'UPDATE')) | \\\n",
    "             ((row['Lag Dataset type'] == 'UPDATE') & (row['Dataset type'] == 'INPUT')):\n",
    "            sub_step_list.append(sub_step_list[index] +1) # Increase sub-step\n",
    "        else:\n",
    "            sub_step_list.append(sub_step_list[index])    # Keep sub-step\n",
    "    df_tables['SubTask ID'] = sub_step_list[1:]\n",
    "\n",
    "    # 3.1.e Correct case for updated tables\n",
    "    df_tables['Dataset type'] = df_tables['Dataset type'].replace({'UPDATE': 'UPDATE INPUT'})\n",
    "    df_update = df_tables.loc[df_tables['Dataset type'].isin(['UPDATE INPUT'])].copy()\n",
    "    df_update['Dataset type'] = df_update['Dataset type'].replace({'UPDATE INPUT': 'UPDATE OUTPUT'})\n",
    "    df_tables = df_tables.append(df_update).sort_values(['Task ID', 'SubTask ID', 'Dataset type'])\n",
    "    \n",
    "    # 3.1.f Add node index\n",
    "    node_id_dict = {}\n",
    "    node_id_list = []\n",
    "    for index, row in df_tables.iterrows():\n",
    "        # If update or output:\n",
    "        if (row['Dataset type'] == 'OUTPUT') | (row['Dataset type'] == 'UPDATE OUTPUT') :\n",
    "            # create node ID\n",
    "            node_id = str(row['Task ID']) +':'+ \\\n",
    "                      str(row['SubTask ID']) +':'+ \\\n",
    "                      row['Table'] +':'+ \\\n",
    "                      row['Table type']   \n",
    "            # update column\n",
    "            node_id_list.append(node_id)       \n",
    "            # update dict\n",
    "            node_id_dict[row['Table']] = node_id                                                                    \n",
    "\n",
    "        # If source table:\n",
    "        elif row['Table'] not in node_id_dict:\n",
    "            # create node ID\n",
    "            node_id = '0:0:' + \\\n",
    "                      row['Table']  +':'+ \\\n",
    "                      row['Table type']\n",
    "            # update column\n",
    "            node_id_list.append(node_id)                                                           \n",
    "            # update dict\n",
    "            node_id_dict[row['Table']] = node_id  \n",
    "        # If input:\n",
    "        else: \n",
    "            # use previous node ID \n",
    "            node_id_list.append(node_id_dict[row['Table']])                                                         \n",
    "    df_tables['Node Id'] = node_id_list\n",
    "\n",
    "    # 3.1.g Remove leftover tables\n",
    "    df_tables.drop(['Table type','Lag Task ID','Lag Dataset type'], inplace=True, axis=1)\n",
    "\n",
    "    #-------------------------------------------\n",
    "    # 3.2. Prepare info about Input tables\n",
    "    df_input = df_tables.loc[(df_tables['Task Type'].isin(['DATASET']) ) & \n",
    "                             (df_tables['Dataset type'].isin(['INPUT', 'UPDATE INPUT']))].copy()\n",
    "    df_input = df_input.rename(columns={'Table': 'Input Table',\n",
    "                                        'Node Id': 'Source ID'})\n",
    "    df_input.drop(['Text', 'Dataset type', 'Task Type'], inplace=True, axis=1)\n",
    "\n",
    "    #-------------------------------------------\n",
    "    # 3.3. Prepare info about Output tables\n",
    "    df_output = df_tables.loc[(df_tables['Task Type'].isin(['DATASET']) ) & \n",
    "                              (df_tables['Dataset type'].isin(['OUTPUT', 'UPDATE OUTPUT']))].copy()\n",
    "    df_output = df_output.rename(columns={'Table': 'Output Table',\n",
    "                                          'Node Id': 'Target ID'})\n",
    "    df_output.drop(['Text', 'Dataset type', 'Task Type'], inplace=True, axis=1)\n",
    "\n",
    "    #-------------------------------------------\n",
    "    # 3.4. Prepare info about Time Calculations\n",
    "    # 3.4.a Get Data\n",
    "    df_time = df_tables.loc[df_tables['Task Type'].isin(['OPENTIME', 'TASKSTARTTIME', 'JOBENDTIME'])].copy()\n",
    "\n",
    "    # 3.4.b Add time\n",
    "    df_time['Start Time'] = df_time[['Text','Task Type']].apply(lambda x: x[0].split()[2].replace('DATE:', '')  if x[1]=='OPENTIME'   # Inherit table type\n",
    "                                                                          else x[0].split()[1].replace('DATE:', '')\n",
    "                                                                , axis = 1)\n",
    "    df_time['Start Time']  = pd.to_datetime(df_time['Start Time'], format='%d%b%Y:%H:%M:%S.%f')\n",
    "\n",
    "    # 3.4.c Remove columns and rows\n",
    "    df_time.drop(['Table','Text','Task Type','Dataset type','Node Id'], inplace=True, axis=1)\n",
    "    df_time = df_time.drop_duplicates(subset=['Task ID', 'SubTask ID'], keep='first')\n",
    "\n",
    "    # 3.4.d Calculate time for each step\n",
    "    df_time['Elapsed Time'] = (df_time['Start Time'].shift(-1) - df_time['Start Time']).dt.total_seconds()\n",
    "    df_time['Elapsed Time'] = df_time['Elapsed Time'].round(2)\n",
    "\n",
    "    #-------------------------------------------\n",
    "    # 3.5. Output\n",
    "    # 3.5.a Merge the results for input and output tables + Elapsed time\n",
    "    df = df_input.merge(df_output, on=['Task ID', 'SubTask ID'], how = 'outer')\\\n",
    "                 .merge(df_time, on=['Task ID', 'SubTask ID'], how = 'left')\\\n",
    "                 .sort_values(['Task ID', 'SubTask ID'])\\\n",
    "                 .reset_index(drop = True)\n",
    "\n",
    "    # 3.5.b Fill missing for specific cases\n",
    "    df['Input Table'] = df['Input Table'].fillna('No Input')\n",
    "    df['Output Table'] = df['Output Table'].fillna('_null_')\n",
    "\n",
    "    # 3.5.c Correct Start time\n",
    "    df['Start Time'] = df['Start Time'].fillna(df['Start Time'].shift()) \n",
    "    df['Elapsed Time'] = df['Elapsed Time'].fillna(0)\n",
    "\n",
    "    # 3.5.d Correct Target node ID\n",
    "    df['Target ID'] = df['Target ID'].fillna(df['Task ID'].astype('str') +':'+ df['SubTask ID'].astype('str')+ ':No Output:Empty') \n",
    "\n",
    "    # 3.5.e Correct Source node ID\n",
    "    df['Source ID'] = df[['Input Table','Task ID','SubTask ID','Source ID']].apply(lambda x: str(x[1])+':'+str(int(x[2])-1)+':No Input:Empty' if x[0]=='No Input' \n",
    "                                                                                  else x[3], axis = 1)\n",
    "    \n",
    "    # 3.5.f Reorder columns\n",
    "    df = df[['Task ID','SubTask ID', 'Source ID','Target ID', 'Input Table','Output Table', 'Start Time','Elapsed Time']]\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_connections = df_to_connections(df_log)\n",
    "df_connections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb34879b",
   "metadata": {},
   "source": [
    "## 2. Graph data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18fa588f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for defining positions of tables\n",
    "#====================================================================================  \n",
    "\n",
    "def get_coords(G):\n",
    "    \n",
    "    #--------------------------------------------------------------------\n",
    "    # get source nodes \n",
    "    source_nodes = sorted([node for node in G.nodes() if G.in_degree(node) == 0])\n",
    "    \n",
    "    #--------------------------------------------------------------------\n",
    "    # Get nodes in traversal order\n",
    "    list_nodes = []\n",
    "    for i in range(len(source_nodes)):\n",
    "        # Define source node\n",
    "        source = source_nodes[i]\n",
    "        # Get nodes in depth order\n",
    "        list_nodes_depth = list(nx.dfs_preorder_nodes(G, source=source, depth_limit=None))\n",
    "        # Extend main list\n",
    "        list_nodes.extend(list_nodes_depth)\n",
    "        \n",
    "    #--------------------------------------------------------------------\n",
    "    # Add elements if missed\n",
    "    list_nodes_full = sorted(list(G.nodes))\n",
    "    list_nodes.extend(list_nodes_full)\n",
    "\n",
    "    #--------------------------------------------------------------------\n",
    "    # Create df\n",
    "    df_nodes = pd.DataFrame(list_nodes, columns =['Node'])\n",
    "    df_nodes['Task ID'] = df_nodes['Node'].str.split(':').str[0].astype('float')\n",
    "    df_nodes['SubTask ID'] = df_nodes['Node'].str.split(':').str[1].astype('float')\n",
    "    df_nodes = df_nodes.drop_duplicates(subset=['Node'], keep='first')\n",
    "    \n",
    "    #--------------------------------------------------------------------\n",
    "    # Assign y\n",
    "    df_nodes = df_nodes.reset_index(drop=True)\n",
    "    df_nodes['Lag Node'] = df_nodes['Node'].shift()\n",
    "    df_nodes['Lag Task ID'] = df_nodes['Task ID'].shift()\n",
    "    df_nodes['Lag SubTask ID'] = df_nodes['SubTask ID'].shift()\n",
    "    y_list = [0] \n",
    "    for index, row in df_nodes.iterrows():\n",
    "        # Get predecessors\n",
    "        predecessors = [c for c in G.predecessors( row['Node'] )]\n",
    "        if (row['Lag Node'] in predecessors):\n",
    "            if (row['Task ID'] == row['Lag Task ID'])  & (row['SubTask ID'] == row['Lag SubTask ID']):\n",
    "                y_list.append(y_list[index] + 1)\n",
    "            else: \n",
    "                y_list.append(y_list[index])\n",
    "        else:\n",
    "            y_list.append(y_list[index] + 1)\n",
    "    df_nodes['y'] = y_list[1:]\n",
    "    \n",
    "    #--------------------------------------------------------------------\n",
    "    # Reorder nodes\n",
    "    df_nodes = df_nodes.sort_values(by=['Task ID','SubTask ID'])\n",
    "\n",
    "    #--------------------------------------------------------------------\n",
    "    # Assign x\n",
    "    df_nodes = df_nodes.reset_index(drop=True)\n",
    "    df_nodes['Lag Task ID'] = df_nodes['Task ID'].shift()\n",
    "    df_nodes['Lag SubTask ID'] = df_nodes['SubTask ID'].shift()\n",
    "    x_list = [-2] \n",
    "    for index, row in df_nodes.iterrows():\n",
    "        # Move from task to task\n",
    "        if (row['Task ID'] != row ['Lag Task ID']):\n",
    "            x_list.append(x_list[index] + 2)\n",
    "        # Move from subtask to subtask        \n",
    "        elif (row['Task ID'] == row ['Lag Task ID']) & (row['SubTask ID'] != row ['Lag SubTask ID']):\n",
    "            x_list.append(x_list[index] + 1)  \n",
    "        else:\n",
    "            x_list.append(x_list[index])\n",
    "    df_nodes['x'] = x_list[1:]\n",
    "\n",
    "    #--------------------------------------------------------------------\n",
    "    # Coords dict\n",
    "    coords = df_nodes[['Node', 'x' , 'y']].set_index('Node').T.to_dict('list')\n",
    "    \n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c19a2cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for extracting data on connections\n",
    "#====================================================================================  \n",
    "\n",
    "def get_edge_df(G):\n",
    "    \n",
    "    edge_dict = {'edge_x':[],\n",
    "                 'edge_y':[],\n",
    "                 'node_x':[],\n",
    "                 'node_y':[],\n",
    "                 'text_x':[],\n",
    "                 'text_y':[],\n",
    "                 'step_id':[],\n",
    "                 'text_color_values':[],\n",
    "                 'text_labels':[]}\n",
    "\n",
    "    for edge in G.edges():\n",
    "        #--------------------------------------------------------------------\n",
    "        # Get Coords\n",
    "        x0, y0 = G.nodes[edge[0]]['coords']\n",
    "        x1, y1 = G.nodes[edge[1]]['coords']\n",
    "        x_mean = round( (x0+x1)/2, 4)\n",
    "        y_mean = round( (y0+y1)/2, 4)   \n",
    "\n",
    "        #--------------------------------------------------------------------\n",
    "        # Shift central points        \n",
    "        shift = (( (x1-x0)**2 + (y1-y0)**2 )**0.5) * 0.05    \n",
    "        # If Horizontal line\n",
    "        if x0 == x1:\n",
    "            x_mean = x_mean + shift\n",
    "        # If Vertical line            \n",
    "        elif y0 == y1:\n",
    "            y_mean = y_mean - shift\n",
    "\n",
    "        #--------------------------------------------------------------------\n",
    "        # Colorbar values\n",
    "        color_value = G.edges[edge[0],edge[1]]['Elapsed Time'] \n",
    "\n",
    "        #--------------------------------------------------------------------\n",
    "        # Hover text\n",
    "        text_label = 'Task ID: '+str(G.edges[edge[0],edge[1]]['Task ID'])\\\n",
    "                        +' '+\\\n",
    "                        'SubTask ID: '+str(G.edges[edge[0],edge[1]]['SubTask ID'])\\\n",
    "                        +'<br> '+\\\n",
    "                        'Input: '+str(G.edges[edge[0],edge[1]]['Input Table'])\\\n",
    "                        +'<br> '+\\\n",
    "                        'Output: '+str(G.edges[edge[0],edge[1]]['Output Table'])\\\n",
    "                        +'<br> '+\\\n",
    "                        'Elapsed Time: '+str(G.edges[edge[0],edge[1]]['Elapsed Time'])\n",
    "\n",
    "        #--------------------------------------------------------------------\n",
    "        # output\n",
    "        edge_dict['edge_x'].append(x0)\n",
    "        edge_dict['edge_y'].append(y0)    \n",
    "        edge_dict['node_x'].append(x1)\n",
    "        edge_dict['node_y'].append(y1)  \n",
    "        edge_dict['text_x'].append(x_mean)\n",
    "        edge_dict['text_y'].append(y_mean)  \n",
    "        edge_dict['step_id'].append(G.edges[edge[0],edge[1]]['Task ID']) \n",
    "        edge_dict['text_color_values'].append(color_value)   \n",
    "        edge_dict['text_labels'].append(text_label) \n",
    "\n",
    "    edge_df = pd.DataFrame(edge_dict)\n",
    "\n",
    "    return edge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adfc2e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for extracting data on connections\n",
    "#====================================================================================  \n",
    "\n",
    "def get_node_df(G):  \n",
    "\n",
    "    node_dict = {'node_x':[],\n",
    "                 'node_y':[],\n",
    "                 'node_label':[],\n",
    "                 'step_id':[],\n",
    "                 'node_group':[],\n",
    "                 'node_color':[],\n",
    "                 'node_shape':[]}\n",
    "    \n",
    "    for node in G.nodes():  \n",
    "        #--------------------------------------------------------------------\n",
    "        # Node Coords\n",
    "        x, y = G.nodes[node]['coords']\n",
    "        node_dict['node_x'].append(x)\n",
    "        node_dict['node_y'].append(y)   \n",
    "\n",
    "        #--------------------------------------------------------------------\n",
    "        # Node name\n",
    "        table_name = node.split(':')[2]\n",
    "        node_dict['node_label'].append(table_name)  \n",
    "        \n",
    "        #--------------------------------------------------------------------\n",
    "        # Step ID\n",
    "        node_dict['step_id'].append(node.split(':')[0])  \n",
    "        \n",
    "        #--------------------------------------------------------------------\n",
    "        # Table Type\n",
    "        table_type = node.split(':')[3]       \n",
    "        \n",
    "        #--------------------------------------------------------------------\n",
    "        # Predesessors\n",
    "        predecessors = [c.split(':')[2] for c in G.predecessors(node)]\n",
    "\n",
    "        #--------------------------------------------------------------------\n",
    "        # Node shape and color\n",
    "        # a) No Input node\n",
    "        if table_name == 'No Input':\n",
    "            node_dict['node_group'].append('No Input')  \n",
    "            node_dict['node_shape'].append('diamond-cross')  \n",
    "            node_dict['node_color'].append('grey')  \n",
    "        # b) No Output node\n",
    "        elif table_name == 'No Output':\n",
    "            node_dict['node_group'].append('No Output')  \n",
    "            node_dict['node_shape'].append('square-cross')  \n",
    "            node_dict['node_color'].append('grey')\n",
    "        # c) Temporary tables\n",
    "        elif table_type == 'UTILITY':\n",
    "            node_dict['node_group'].append('Technical Table')  \n",
    "            node_dict['node_shape'].append('star-square-dot')  \n",
    "            node_dict['node_color'].append('silver')\n",
    "        # d) Input node\n",
    "        elif G.in_degree(node) == 0:\n",
    "            node_dict['node_group'].append('Input Table')  \n",
    "            node_dict['node_shape'].append('diamond')  \n",
    "            node_dict['node_color'].append('gold')\n",
    "        # e) Output node\n",
    "        elif G.out_degree(node) == 0:\n",
    "            node_dict['node_group'].append('Output Table')  \n",
    "            node_dict['node_shape'].append('square')  \n",
    "            node_dict['node_color'].append('cyan')\n",
    "        # f) Updated node            \n",
    "        elif table_name in predecessors:\n",
    "            node_dict['node_group'].append('Updated Table')  \n",
    "            node_dict['node_shape'].append('cross')  \n",
    "            node_dict['node_color'].append('orange')\n",
    "        # g) Internal nodes\n",
    "        else:\n",
    "            node_dict['node_group'].append('Internal Table')  \n",
    "            node_dict['node_shape'].append('circle')  \n",
    "            node_dict['node_color'].append('blue')\n",
    "\n",
    "    node_df = pd.DataFrame(node_dict)\n",
    "    node_df['step_id'] = node_df['step_id'].astype('int')\n",
    "    \n",
    "    return node_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "def10b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiGraph with 16 nodes and 17 edges\n"
     ]
    }
   ],
   "source": [
    "# Function for generating a networkx Graph\n",
    "#====================================================================================  \n",
    "\n",
    "\n",
    "def get_graph_data(df):\n",
    "\n",
    "    # Create graph\n",
    "    G = nx.from_pandas_edgelist(df,\n",
    "                                'Source ID','Target ID',\n",
    "                                ['Task ID','SubTask ID','Input Table','Output Table','Start Time','Elapsed Time'],\n",
    "                                create_using=nx.DiGraph())\n",
    "    print(nx.info(G))\n",
    "\n",
    "    # Define positions of tables\n",
    "    coords = get_coords(G)\n",
    "    \n",
    "    # Add positions to the graph\n",
    "    nx.set_node_attributes(G, coords, 'coords') \n",
    "\n",
    "    # Create table for connections and label text\n",
    "    edge_df = get_edge_df(G)\n",
    "\n",
    "    # Create table for nodes\n",
    "    node_df = get_node_df(G)\n",
    "\n",
    "    # Combine the two tables\n",
    "    df_graph = edge_df.merge(node_df, on=['step_id', 'node_x', 'node_y'], how = 'outer')\n",
    "    \n",
    "    # Fill empty values \n",
    "    # 1. Edge coords\n",
    "    df_graph['edge_x'] = df_graph['edge_x'].replace(np.nan, 'None')\n",
    "    df_graph['edge_y'] = df_graph['edge_y'].replace(np.nan, 'None')\n",
    "    # 2. Text coords\n",
    "    df_graph['text_x'] = df_graph['text_x'].replace(np.nan, 'None')\n",
    "    df_graph['text_y'] = df_graph['text_y'].replace(np.nan, 'None')\n",
    "    # 3. Labels\n",
    "    df_graph['text_labels'] = df_graph['text_labels'].fillna('')\n",
    "    # 4. Color\n",
    "    df_graph['text_color_values'] = df_graph['text_color_values'].fillna(0)\n",
    "    \n",
    "    # Get color codes\n",
    "    norm = matplotlib.colors.Normalize(vmin=min(df_graph['text_color_values']), \n",
    "                                       vmax=max(df_graph['text_color_values']), \n",
    "                                       clip=True)\n",
    "    mapper = cm.ScalarMappable(norm=norm, cmap='RdYlGn_r')\n",
    "    df_graph['edge_hex'] = df_graph['text_color_values'].apply(lambda x: matplotlib.colors.to_hex(mapper.to_rgba(x), keep_alpha=False))\n",
    "    \n",
    "    df_graph = df_graph\n",
    "    return df_graph.sort_values(by=['step_id'])\n",
    "\n",
    "df_graph = get_graph_data(df_connections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7120ea",
   "metadata": {},
   "source": [
    "## 3. Dash plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dfee18",
   "metadata": {},
   "source": [
    "### 3.1. Network plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ff134f",
   "metadata": {},
   "source": [
    "#### 3.1.a Node Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f822a39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_trace(df):\n",
    "    \n",
    "    node_trace = go.Scatter(x = df['node_x'], \n",
    "                            y = df['node_y'],\n",
    "                            mode = 'markers',\n",
    "                            # Marker\n",
    "                            marker=dict(symbol = df['node_shape'], \n",
    "                                        color = df['node_color'],\n",
    "                                        size = 10),\n",
    "                            marker_line_color='black', \n",
    "                            marker_line_width=0.5,\n",
    "                            # Text\n",
    "                            text = df['node_label'],\n",
    "                            textposition = 'top center',\n",
    "                            # Legend\n",
    "                            showlegend=False,\n",
    "                            # Meta\n",
    "                            meta = df['step_id']\n",
    "                           )\n",
    "    \n",
    "    return node_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70a10734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# network plot\n",
    "node_trace = get_node_trace(df_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd01c94",
   "metadata": {},
   "source": [
    "#### 3.1.b. Edge Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f6a233e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_trace(df):\n",
    "    \n",
    "    edge_trace = []\n",
    "    edge_trace_outline = []    \n",
    "    for index, row in df.iterrows():\n",
    "        # Outline \n",
    "        edge_trace_outline.append(go.Scatter(x = [row['edge_x'], row['text_x'], row['node_x'], None],\n",
    "                                             y = [row['edge_y'], row['text_y'], row['node_y'], None],\n",
    "                                             mode = 'lines', \n",
    "                                             # line\n",
    "                                             line_shape = 'spline',\n",
    "                                             line = dict(width=3, \n",
    "                                                         dash='dot', \n",
    "                                                         color='grey'),\n",
    "                                             # Text\n",
    "                                             hoverinfo = 'none',\n",
    "                                             # Legend\n",
    "                                             showlegend=False,\n",
    "                                             # Meta\n",
    "                                             meta = row['step_id'] \n",
    "                                            )\n",
    "                         )\n",
    "        # Line\n",
    "        edge_trace.append(go.Scatter(x = [row['edge_x'], row['text_x'], row['node_x'], None],\n",
    "                                     y = [row['edge_y'], row['text_y'], row['node_y'], None],\n",
    "                                     mode = 'lines', \n",
    "                                     # line\n",
    "                                     line_shape = 'spline',\n",
    "                                     line = dict(width=1.5, \n",
    "                                                 dash='dot', \n",
    "                                                 color=row['edge_hex']),\n",
    "                                     # Text\n",
    "                                     hoverinfo = 'none',\n",
    "                                     # Legend\n",
    "                                     showlegend=False,\n",
    "                                     # Meta\n",
    "                                     meta = row['step_id'] \n",
    "                                    )\n",
    "                         )\n",
    "        \n",
    "    return edge_trace, edge_trace_outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "225a1191",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_trace, edge_trace_outline = get_edge_trace(df_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea193db9",
   "metadata": {},
   "source": [
    "#### 3.1.c Text trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "114ab78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_trace(df):\n",
    "    \n",
    "    text_trace = go.Scatter(x=df['text_x'], \n",
    "                            y=df['text_y'], \n",
    "                            # Marker\n",
    "                            mode = 'markers', \n",
    "                            marker_symbol = 'hexagram',\n",
    "                            marker=dict(showscale=True, \n",
    "                                        colorscale='RdYlGn', \n",
    "                                        reversescale=True,\n",
    "                                        size = 8, \n",
    "                                        color=df['text_color_values'],\n",
    "                                        colorbar=dict(thickness=15,\n",
    "                                                      title='Execution time (s)',\n",
    "                                                      xanchor='left',\n",
    "                                                      titleside='right')\n",
    "                                       ),                            \n",
    "                            marker_line_color='black', \n",
    "                            marker_line_width=0.5,\n",
    "                            # Text\n",
    "                            text = df['text_labels'],  \n",
    "                            textposition = 'top center',\n",
    "                            # Legend\n",
    "                            showlegend=False,\n",
    "                            # Meta\n",
    "                            meta = df['step_id']                           \n",
    "                           )\n",
    "    \n",
    "    return text_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f07309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_trace = get_text_trace(df_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7648fe4f",
   "metadata": {},
   "source": [
    "#### 3.1.d Network Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85785783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_network(edge_trace_outline, edge_trace, node_trace, text_trace):\n",
    "    fig = go.Figure(edge_trace_outline + edge_trace + [node_trace] + [text_trace]) \n",
    "    fig.update_layout(xaxis=dict(zeroline=False,\n",
    "                                 showticklabels=False),\n",
    "                      yaxis=dict(showgrid=False, \n",
    "                                 zeroline=False,\n",
    "                                 showticklabels=False,\n",
    "                                 autorange='reversed'),\n",
    "                      legend=dict(orientation='h',\n",
    "                                  x=1, y=1.02,\n",
    "                                  xanchor='right', yanchor='bottom'),\n",
    "                      margin=dict(t=0, b=10,\n",
    "                                  l=10, r=0)\n",
    "                     )\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b43ee913",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_net = draw_network(edge_trace_outline, edge_trace, node_trace, text_trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622a929d",
   "metadata": {},
   "source": [
    "#### 3.1.e Legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28f1e3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_legend():\n",
    "    fig = go.Figure(go.Scatter(x=[0,0,0,0,0,0,0],\n",
    "                               y=['No Input','No Output','Technical Table','Input Table','Output Table','Updated Table','Internal Table'] ,\n",
    "                               mode = 'markers',\n",
    "                               # Marker\n",
    "                               marker=dict(symbol = ['diamond-cross','square-cross','star-square-dot','diamond','square','cross','circle'],\n",
    "                                           color = ['grey','grey','silver','gold','cyan','orange','blue'],\n",
    "                                           size = 10),\n",
    "                               marker_line_color='black',\n",
    "                               marker_line_width=0.5,\n",
    "                               text = ['No Input','No Output','Technical Table','Input Table','Output Table','Updated Table','Internal Table'],\n",
    "                               # Legend\n",
    "                               showlegend=False)\n",
    "                          )\n",
    "    fig.update_layout(xaxis=dict(showgrid=False,\n",
    "                                 showticklabels=False),\n",
    "                      yaxis=dict(showgrid=False),\n",
    "                      xaxis_side=\"top\",\n",
    "                      margin=dict(t=0, b=10,\n",
    "                                  l=0, r=0),\n",
    "                      width = 100\n",
    "                     )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4607fdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_legend = draw_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb3dcf7",
   "metadata": {},
   "source": [
    "### 3.2 Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b424f802",
   "metadata": {},
   "source": [
    "#### 3.2.a Table filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64f2ec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operator dict\n",
    "operators = [['ge ', '>='],\n",
    "             ['le ', '<='],\n",
    "             ['lt ', '<'],\n",
    "             ['gt ', '>'],\n",
    "             ['ne ', '!='],\n",
    "             ['eq ', '='],\n",
    "             ['contains '],\n",
    "             ['datestartswith ']]\n",
    "\n",
    "#======================================================================\n",
    "# Filter query syntax split\n",
    "def split_filter_part(filter_part):\n",
    "    for operator_type in operators:\n",
    "        for operator in operator_type:\n",
    "            if operator in filter_part:\n",
    "                name_part, value_part = filter_part.split(operator, 1)\n",
    "                name = name_part[name_part.find('{') + 1: name_part.rfind('}')]\n",
    "\n",
    "                value_part = value_part.strip()\n",
    "                v0 = value_part[0]\n",
    "                if (v0 == value_part[-1] and v0 in (\"'\", '\"', '`')):\n",
    "                    value = value_part[1: -1].replace('\\\\' + v0, v0)\n",
    "                else:\n",
    "                    try:\n",
    "                        value = float(value_part)\n",
    "                    except ValueError:\n",
    "                        value = value_part\n",
    "\n",
    "                return name, operator_type[0].strip(), value\n",
    "\n",
    "    return [None] * 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fb293a",
   "metadata": {},
   "source": [
    "#### 3.2.b Draw Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63c1fd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_table(df):\n",
    "    table = dash_table.DataTable(id='table',\n",
    "                                 columns=[{'name': i, 'id': i} for i in df.columns],\n",
    "                                 data=df.to_dict('records'),\n",
    "                                 # Filtering\n",
    "                                 filter_action='native',\n",
    "                                 filter_query='',\n",
    "                                 # Styles\n",
    "                                 style_header={'fontWeight': 'bold',\n",
    "                                               'backgroundColor': 'rgb(48, 84, 150)',\n",
    "                                               'color': 'white'},\n",
    "                                 style_filter={'backgroundColor': 'rgb(142, 169, 219)',\n",
    "                                               'color': 'white'},\n",
    "                                 style_cell={'backgroundColor': 'rgb(217, 225, 242)',\n",
    "                                             'textAlign': 'left', 'color': 'black',\n",
    "                                             'width': '150px', 'minWidth': '180px', 'maxWidth': '180px',\n",
    "                                             'whiteSpace': 'pre-line'},\n",
    "                                 # Sorting\n",
    "                                 sort_action='native',\n",
    "                                 sort_mode='multi',\n",
    "                                 # Column size\n",
    "                                 style_cell_conditional=[{'if': {'column_id': 'Task ID'}, 'width': '5%'},\n",
    "                                                         {'if': {'column_id': 'Code'}, 'width': '75%'},\n",
    "                                                         {'if': {'column_id': 'Procedure'}, 'width': '5%'},\n",
    "                                                         {'if': {'column_id': 'Start Time'}, 'width': '10%'},\n",
    "                                                         {'if': {'column_id': 'Elapsed Time'}, 'width': '5%'}],\n",
    "                                 # Table size\n",
    "                                 fixed_rows={'headers': True},\n",
    "                                 style_table={'overflowY': 'scroll', \n",
    "                                              'border': 'thin lightgrey solid'}, \n",
    "                                )\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "daaff747",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_table = draw_table(df_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695dd840",
   "metadata": {},
   "source": [
    "### 3.3 Interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ac590c",
   "metadata": {},
   "source": [
    "#### 3.3.a Scatter -> Table interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22eb40a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_query(selectedData):\n",
    "    # Get list of selected Step IDs\n",
    "    x_values = []\n",
    "    for elements in selectedData['points']:\n",
    "        if 'meta' in elements:\n",
    "            if elements['meta'] not in x_values:\n",
    "                x_values.append( int(elements['meta']) )\n",
    "    # Generate filter query\n",
    "    query =''\n",
    "    if len(x_values) != 0:\n",
    "        # 2.1 Formulate query\n",
    "        for filter_value in x_values:\n",
    "            query = query + '{Task ID} = ' + str(filter_value) + ' or '\n",
    "        # 2.2. Remove last or\n",
    "        query = ' '.join(query.split(' ')[:-2])\n",
    "    return query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b292270f",
   "metadata": {},
   "source": [
    "#### 3.3.b Table  -> Scatter interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "326f5c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_scatter(filter_query):\n",
    "    # 1. Make copy of df and figure\n",
    "    dff = copy.copy(df_code) \n",
    "    fig_copy = copy.copy(fig_net) \n",
    "\n",
    "    # 2. Fetch step ids based on filter query\n",
    "    filtering_expressions = filter_query.split(' && ')\n",
    "    for filter_part in filtering_expressions:\n",
    "        col_name, operator, filter_value = split_filter_part(filter_part)\n",
    "        if operator in ('eq', 'ne', 'lt', 'le', 'gt', 'ge'):\n",
    "            dff = dff.loc[getattr(dff[col_name], operator)(filter_value)]\n",
    "        elif operator == 'contains':\n",
    "            dff = dff.loc[dff[col_name].str.contains(filter_value)]   \n",
    "        elif operator == 'datestartswith':\n",
    "            dff = dff.loc[dff[col_name].str.startswith(filter_value)]\n",
    "    step_list = list(dff['Task ID'])\n",
    "\n",
    "    # 3. Select figure traces that are in the filtered data\n",
    "    selected_points = []\n",
    "    fig_data = fig_copy['data']\n",
    "    for i in range(len(fig_data)):\n",
    "        meta = fig_data[i]['meta']\n",
    "        if isinstance(meta, int):\n",
    "            if meta in step_list:\n",
    "                selected_points.append(i)\n",
    "\n",
    "    # 4. Update figure\n",
    "    fig_copy.update_traces(selectedpoints = selected_points)\n",
    "\n",
    "    return fig_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304b1ccc",
   "metadata": {},
   "source": [
    "### 3.4. Dash Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74239372",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:8050/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [26/Aug/2021 22:39:04] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Aug/2021 22:39:04] \"\u001b[37mGET /_dash-dependencies HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Aug/2021 22:39:04] \"\u001b[37mGET /_dash-layout HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Aug/2021 22:39:04] \"\u001b[37mGET /_favicon.ico?v=1.20.0 HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Aug/2021 22:39:04] \"\u001b[37mGET /_dash-component-suites/dash_table/async-highlight.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Aug/2021 22:39:04] \"\u001b[37mGET /_dash-component-suites/dash_table/async-table.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Aug/2021 22:39:08] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Aug/2021 22:39:13] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full query ({Task ID} > 5) and ({Task ID} = 9 or {Task ID} = 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Aug/2021 22:39:59] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Server start\n",
    "app = dash.Dash()\n",
    "\n",
    "#======================================================================\n",
    "# Dash plot\n",
    "app.layout = html.Div([\n",
    "    #--------------------------------------------------------------\n",
    "    # 1. First row - Reset Button\n",
    "    html.Div(children=[html.Button('Reset Graphs', id='reset_button', n_clicks=0)],\n",
    "             className='row',\n",
    "             style={'height':'5%', 'display':'inline-block', 'vertical-align':'top', 'horizontal-align':'center'}), \n",
    "    \n",
    "    #--------------------------------------------------------------\n",
    "    # 2. Second row - Legend and Network\n",
    "    html.Div(children=[\n",
    "        # 1.1 first column of first row - Legend\n",
    "        html.Div(children=[dcc.Graph(id='legend', figure=fig_legend)],\n",
    "                 style={'width':'10%', 'display':'inline-block', 'vertical-align':'top', 'horizontal-align':'center'}),\n",
    "        # 1.2 second column of first row - Network\n",
    "        html.Div(children=[dcc.Graph(id='network', figure=fig_net)],\n",
    "                 style={'width':'90%', 'display':'inline-block', 'vertical-align':'top', 'horizontal-align':'center'}),\n",
    "    ], className='row'),\n",
    "    \n",
    "    #--------------------------------------------------------------\n",
    "    # 3. Third row - Table\n",
    "    html.Div(children=[fig_table], \n",
    "             className='row', \n",
    "             style={'width':'100%', 'vertical-align':'top', 'horizontal-align':'center'})\n",
    "])\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "# Add Scatter-Table-Reset interactions\n",
    "@app.callback([Output('reset_button','n_clicks'), Output('table', 'filter_query'), Output('network', 'figure')],\n",
    "              [Input('reset_button','n_clicks'), Input('table', 'filter_query'), Input('network', 'selectedData')],\n",
    "              prevent_initial_call = True)\n",
    "def update_figures(n_clicks, filter_query, selectedData):\n",
    "    \n",
    "    # 1. If reset is clicked - restart table and scatter\n",
    "    if n_clicks is not None and n_clicks > 0:  \n",
    "        return 0, '', fig_net   \n",
    "    \n",
    "\n",
    "\n",
    "    # 2. If filter is applied to Network plot - update query\n",
    "    elif selectedData is not None:\n",
    "        selected_query = update_query(selectedData)\n",
    "        if filter_query != '':            \n",
    "            full_query = '(' + filter_query + ') and (' + selected_query + ')' # Data selected based on query and scatter\n",
    "            return dash.no_update, full_query, dash.no_update\n",
    "        else:\n",
    "            return dash.no_update, selected_query, dash.no_update\n",
    "        \n",
    "    # 3. If filter is applied to Table - update Scatterplot\n",
    "    elif filter_query is not None and filter_query != '': \n",
    "        fig_updated = update_scatter(filter_query)\n",
    "        return dash.no_update, dash.no_update, fig_updated\n",
    "    \n",
    "    # 4. No change\n",
    "    else:\n",
    "        raise dash.exceptions.PreventUpdate\n",
    "        \n",
    "#======================================================================\n",
    "app.run_server(debug=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6e549c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
