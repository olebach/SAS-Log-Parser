{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "853578fc",
   "metadata": {},
   "source": [
    "# 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f80e5c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# Plots\n",
    "import networkx as nx\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.offline as py\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Dash\n",
    "import dash\n",
    "import dash_table\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83a556ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please specify the location of the txt file:\n",
    "path = 'Data/NEW_PIT.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f494414b",
   "metadata": {},
   "source": [
    "# 1. Log parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1489d9a",
   "metadata": {},
   "source": [
    "#### 1.1 Extract df from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62547408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_to_df(path):\n",
    "\n",
    "    # 1.1 Read Data\n",
    "    f = open(path, 'r')\n",
    "    content = f.read()\n",
    "    content_list = content.split('/* JOBSPLIT: ')\n",
    "    f.close()\n",
    "    df = pd.DataFrame(content_list, columns=['Text'])\n",
    "\n",
    "    # 1.2. Define Task type\n",
    "    df['Task Type'] = df[\"Text\"].str.split().str[0]\n",
    "\n",
    "    # 1.3 Assign Task ID\n",
    "    df = df.reset_index(drop=True)\n",
    "    task_list = [0] \n",
    "    for index, row in df.iterrows():\n",
    "        if (row['Task Type'] == 'TASKSTARTTIME') | (row['Task Type'] == 'JOBENDTIME'):\n",
    "            task_list.append(task_list[index] +1)\n",
    "        else:\n",
    "            task_list.append(task_list[index])   \n",
    "    df['Task ID'] = task_list[1:]\n",
    "\n",
    "    # 1.4 Remove unessesary text\n",
    "    df['Text'] = df[['Text','Task Type']].apply(lambda x: x[0].replace('\\n\\n','\\n').replace('STEP SOURCE FOLLOWS */\\n','') if x[1]=='STEP' \n",
    "                                                          else x[0].replace('*/\\n','')\n",
    "                                                , axis = 1)\n",
    "\n",
    "    df['Task ID'] = df['Task ID'].astype('int')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e1ee718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Task Type</th>\n",
       "      <th>Task ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JOBSTARTTIME 27JUL2021:10:34:25.72</td>\n",
       "      <td>JOBSTARTTIME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TASKSTARTTIME 27JUL2021:10:34:25.72</td>\n",
       "      <td>TASKSTARTTIME</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CATALOG INPUT WORK.SASMAC1.MTF_IFRS9_PD_PIT_BA...</td>\n",
       "      <td>CATALOG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LIBNAME WORK V9 '/opt/sas/saswork/SAS_work2019...</td>\n",
       "      <td>LIBNAME</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3976</th>\n",
       "      <td>ELAPSED 8</td>\n",
       "      <td>ELAPSED</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>PROCNAME DATASETS</td>\n",
       "      <td>PROCNAME</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>proc datasets lib = work nolist noprint memty...</td>\n",
       "      <td>STEP</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>JOBENDTIME 27JUL2021:10:36:37.94</td>\n",
       "      <td>JOBENDTIME</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>END</td>\n",
       "      <td>END</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3981 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text      Task Type  \\\n",
       "0                                                                  NaN   \n",
       "1                   JOBSTARTTIME 27JUL2021:10:34:25.72    JOBSTARTTIME   \n",
       "2                  TASKSTARTTIME 27JUL2021:10:34:25.72   TASKSTARTTIME   \n",
       "3     CATALOG INPUT WORK.SASMAC1.MTF_IFRS9_PD_PIT_BA...        CATALOG   \n",
       "4     LIBNAME WORK V9 '/opt/sas/saswork/SAS_work2019...        LIBNAME   \n",
       "...                                                 ...            ...   \n",
       "3976                                        ELAPSED 8          ELAPSED   \n",
       "3977                                 PROCNAME DATASETS        PROCNAME   \n",
       "3978   proc datasets lib = work nolist noprint memty...           STEP   \n",
       "3979                  JOBENDTIME 27JUL2021:10:36:37.94      JOBENDTIME   \n",
       "3980                                               END             END   \n",
       "\n",
       "      Task ID  \n",
       "0           0  \n",
       "1           0  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  \n",
       "...       ...  \n",
       "3976      163  \n",
       "3977      163  \n",
       "3978      163  \n",
       "3979      164  \n",
       "3980      164  \n",
       "\n",
       "[3981 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_log = txt_to_df(path)\n",
    "df_log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c4d547",
   "metadata": {},
   "source": [
    "#### 1.2. Extract info about Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32a6868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_code(df):\n",
    "\n",
    "    #-------------------------------------------\n",
    "    # 2.1 Extract the Code Syntax\n",
    "    df_code = df.loc[(df_log['Task Type'].isin(['STEP']))].copy()\n",
    "    df_code.drop(['Task Type'], inplace=True, axis=1)\n",
    "    df_code = df_code.rename(columns={'Text': 'Code'})\n",
    "    df_code = df_code[['Task ID', 'Code']]\n",
    "\n",
    "    #-------------------------------------------\n",
    "    # 2.2. Prepare info about Start Time\n",
    "    df_taskstarttime = df_log.loc[(df_log['Task Type'].isin(['TASKSTARTTIME']))].copy()\n",
    "    df_taskstarttime['Start Time'] = df_taskstarttime['Text'].str.split().str[1]\n",
    "    df_taskstarttime['Start Time'] = pd.to_datetime(df_taskstarttime['Start Time'], format='%d%b%Y:%H:%M:%S.%f')\n",
    "    df_taskstarttime.drop(['Text', 'Task Type'], inplace=True, axis=1)\n",
    "\n",
    "    #-------------------------------------------\n",
    "    # 2.3. Prepare info about Elapsed Time\n",
    "    df_elapsedtime = df_log.loc[(df_log['Task Type'].isin(['ELAPSED']))].copy()\n",
    "    df_elapsedtime['Elapsed Time'] = df_elapsedtime['Text'].str.split().str[1].astype('int')/1000\n",
    "    df_elapsedtime.drop(['Text', 'Task Type'], inplace=True, axis=1)\n",
    "\n",
    "    #-------------------------------------------\n",
    "    # 2.4. Prepare info about Procedure Names\n",
    "    df_procedure = df_log.loc[(df_log['Task Type'].isin(['PROCNAME']))].copy()\n",
    "    df_procedure['Procedure'] = df_procedure['Text'].str.split().str[1]\n",
    "    df_procedure.drop(['Text', 'Task Type'], inplace=True, axis=1)\n",
    "\n",
    "    #-------------------------------------------\n",
    "    # 2.5 Output\n",
    "    df_code = df_code.merge(df_procedure, on=['Task ID'], how = 'outer')\\\n",
    "                     .merge(df_taskstarttime, on=['Task ID'], how = 'outer')\\\n",
    "                     .merge(df_elapsedtime, on=['Task ID'], how = 'outer')\n",
    "    \n",
    "    df_code['Start Time'] = df_code['Start Time'].astype('str')\n",
    "    df_code['Task ID'] = df_code['Task ID'].astype('int')\n",
    "    \n",
    "    return df_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62c79e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task ID</th>\n",
       "      <th>Code</th>\n",
       "      <th>Procedure</th>\n",
       "      <th>Start Time</th>\n",
       "      <th>Elapsed Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>/*--------------------------------------------...</td>\n",
       "      <td>DATASTEP</td>\n",
       "      <td>2021-07-27 10:34:25.720</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>data _null_;\\n set __mtf_pd_pit_version;\\n mt...</td>\n",
       "      <td>DATASTEP</td>\n",
       "      <td>2021-07-27 10:34:25.730</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>proc sql noprint;\\n create table __mtf_pd_pit...</td>\n",
       "      <td>SQL</td>\n",
       "      <td>2021-07-27 10:34:25.740</td>\n",
       "      <td>2.941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>proc sql noprint;\\n create table __mtf_pd_pit...</td>\n",
       "      <td>SQL</td>\n",
       "      <td>2021-07-27 10:34:28.680</td>\n",
       "      <td>2.490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>proc sql noprint;\\n select count(*) into :__i...</td>\n",
       "      <td>SQL</td>\n",
       "      <td>2021-07-27 10:34:31.170</td>\n",
       "      <td>0.128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>159</td>\n",
       "      <td>proc transpose data=WORK.__MTF_PD_PIT_ODR_WID...</td>\n",
       "      <td>TRANSPOSE</td>\n",
       "      <td>2021-07-27 10:36:36.550</td>\n",
       "      <td>0.659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>160</td>\n",
       "      <td>proc sql noprint _method;\\n create table work...</td>\n",
       "      <td>SQL</td>\n",
       "      <td>2021-07-27 10:36:37.210</td>\n",
       "      <td>0.208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>161</td>\n",
       "      <td>proc datasets lib = work nolist noprint memty...</td>\n",
       "      <td>DATASETS</td>\n",
       "      <td>2021-07-27 10:36:37.420</td>\n",
       "      <td>0.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>162</td>\n",
       "      <td>proc datasets lib = work nolist noprint memty...</td>\n",
       "      <td>DATASETS</td>\n",
       "      <td>2021-07-27 10:36:37.890</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>163</td>\n",
       "      <td>proc datasets lib = work nolist noprint memty...</td>\n",
       "      <td>DATASETS</td>\n",
       "      <td>2021-07-27 10:36:37.930</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Task ID                                               Code  Procedure  \\\n",
       "0          1  /*--------------------------------------------...   DATASTEP   \n",
       "1          2   data _null_;\\n set __mtf_pd_pit_version;\\n mt...   DATASTEP   \n",
       "2          3   proc sql noprint;\\n create table __mtf_pd_pit...        SQL   \n",
       "3          4   proc sql noprint;\\n create table __mtf_pd_pit...        SQL   \n",
       "4          5   proc sql noprint;\\n select count(*) into :__i...        SQL   \n",
       "..       ...                                                ...        ...   \n",
       "158      159   proc transpose data=WORK.__MTF_PD_PIT_ODR_WID...  TRANSPOSE   \n",
       "159      160   proc sql noprint _method;\\n create table work...        SQL   \n",
       "160      161   proc datasets lib = work nolist noprint memty...   DATASETS   \n",
       "161      162   proc datasets lib = work nolist noprint memty...   DATASETS   \n",
       "162      163   proc datasets lib = work nolist noprint memty...   DATASETS   \n",
       "\n",
       "                  Start Time  Elapsed Time  \n",
       "0    2021-07-27 10:34:25.720         0.006  \n",
       "1    2021-07-27 10:34:25.730         0.007  \n",
       "2    2021-07-27 10:34:25.740         2.941  \n",
       "3    2021-07-27 10:34:28.680         2.490  \n",
       "4    2021-07-27 10:34:31.170         0.128  \n",
       "..                       ...           ...  \n",
       "158  2021-07-27 10:36:36.550         0.659  \n",
       "159  2021-07-27 10:36:37.210         0.208  \n",
       "160  2021-07-27 10:36:37.420         0.468  \n",
       "161  2021-07-27 10:36:37.890         0.044  \n",
       "162  2021-07-27 10:36:37.930         0.008  \n",
       "\n",
       "[163 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_code = df_to_code(df_log)\n",
    "df_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d1ed38",
   "metadata": {},
   "source": [
    "#### 1.3. Extract Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b3953c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_connections(df):\n",
    "    \n",
    "    #-------------------------------------------\n",
    "    # 3.1 Extract Table info\n",
    "    # 3.1.a Get data\n",
    "    df_tables = df.loc[(df['Task Type'].isin(['DATASET', 'OPENTIME', 'TASKSTARTTIME',  'JOBENDTIME']))].copy()   \n",
    "\n",
    "    # 3.1.b # Extract table name and type\n",
    "    df_tables['Table'] = df_tables[['Text','Task Type']].apply(lambda x: x[0].split()[3]  if x[1]=='DATASET' \n",
    "                                                                         else (x[0].split()[1]   if x[1]=='OPENTIME' \n",
    "                                                                               else '')\n",
    "                                                               , axis = 1)\n",
    "    df_tables['Table type'] = df_tables['Table'].str.split('.').str[-1]                          # Extract table type\n",
    "    df_tables['Table'] = df_tables['Table'].apply(lambda x: '.'.join(x.split('.')[:-1]))         # Extract table name\n",
    "\n",
    "    # 3.1.c Define table type (Input, Output, Update)\n",
    "    df_tables['Dataset type'] = df_tables[['Text', 'Task Type']].apply(lambda x: x[0].split()[1]  if x[1]=='DATASET'\n",
    "                                                                                 else ''\n",
    "                                                                       , axis = 1)\n",
    "    df_tables['Dataset type'] = np.where(df_tables['Task Type'].isin(['OPENTIME']),\n",
    "                                          df_tables['Dataset type'].shift(),                     # Inherit table type\n",
    "                                          df_tables['Dataset type'])\n",
    "    \n",
    "    # 3.1.d Add sub-step indicator\n",
    "    df_tables = df_tables.reset_index(drop=True)\n",
    "    df_tables['Lag Task ID'] = df_tables['Task ID'].shift()\n",
    "    df_tables['Lag Dataset type'] = df_tables['Dataset type'].shift()\n",
    "    sub_step_list = [1]\n",
    "    for index, row in df_tables.iterrows():\n",
    "        if (row['Task ID'] != row['Lag Task ID']):\n",
    "            sub_step_list.append(1)                       # Reset sub-step\n",
    "        elif ((row['Lag Dataset type'] == 'OUTPUT') & (row['Dataset type'] == 'INPUT')) | \\\n",
    "             ((row['Lag Dataset type'] == 'OUTPUT') & (row['Dataset type'] == 'UPDATE')) | \\\n",
    "             ((row['Lag Dataset type'] == 'UPDATE') & (row['Dataset type'] == 'INPUT')):\n",
    "            sub_step_list.append(sub_step_list[index] +1) # Increase sub-step\n",
    "        else:\n",
    "            sub_step_list.append(sub_step_list[index])    # Keep sub-step\n",
    "    df_tables['SubTask ID'] = sub_step_list[1:]\n",
    "\n",
    "    # 3.1.e Correct case for updated tables\n",
    "    df_tables['Dataset type'] = df_tables['Dataset type'].replace({'UPDATE': 'UPDATE INPUT'})\n",
    "    df_update = df_tables.loc[df_tables['Dataset type'].isin(['UPDATE INPUT'])].copy()\n",
    "    df_update['Dataset type'] = df_update['Dataset type'].replace({'UPDATE INPUT': 'UPDATE OUTPUT'})\n",
    "    df_tables = df_tables.append(df_update).sort_values(['Task ID', 'SubTask ID', 'Dataset type'])\n",
    "    \n",
    "    # 3.1.f Add node index\n",
    "    node_id_dict = {}\n",
    "    node_id_list = []\n",
    "    for index, row in df_tables.iterrows():\n",
    "        # If update or output:\n",
    "        if (row['Dataset type'] == 'OUTPUT') | (row['Dataset type'] == 'UPDATE OUTPUT') :\n",
    "            # create node ID\n",
    "            node_id = str(row['Task ID']) +':'+ \\\n",
    "                      str(row['SubTask ID']) +':'+ \\\n",
    "                      row['Table'] +':'+ \\\n",
    "                      row['Table type']   \n",
    "            # update column\n",
    "            node_id_list.append(node_id)       \n",
    "            # update dict\n",
    "            node_id_dict[row['Table']] = node_id                                                                    \n",
    "\n",
    "        # If source table:\n",
    "        elif row['Table'] not in node_id_dict:\n",
    "            # create node ID\n",
    "            node_id = '0:0:' + \\\n",
    "                      row['Table']  +':'+ \\\n",
    "                      row['Table type']\n",
    "            # update column\n",
    "            node_id_list.append(node_id)                                                           \n",
    "            # update dict\n",
    "            node_id_dict[row['Table']] = node_id  \n",
    "        # If input:\n",
    "        else: \n",
    "            # use previous node ID \n",
    "            node_id_list.append(node_id_dict[row['Table']])                                                         \n",
    "    df_tables['Node Id'] = node_id_list\n",
    "\n",
    "    # 3.1.g Remove leftover tables\n",
    "    df_tables.drop(['Table type','Lag Task ID','Lag Dataset type'], inplace=True, axis=1)\n",
    "\n",
    "    #-------------------------------------------\n",
    "    # 3.2. Prepare info about Input tables\n",
    "    df_input = df_tables.loc[(df_tables['Task Type'].isin(['DATASET']) ) & \n",
    "                             (df_tables['Dataset type'].isin(['INPUT', 'UPDATE INPUT']))].copy()\n",
    "    df_input = df_input.rename(columns={'Table': 'Input Table',\n",
    "                                        'Node Id': 'Source ID'})\n",
    "    df_input.drop(['Text', 'Dataset type', 'Task Type'], inplace=True, axis=1)\n",
    "\n",
    "    #-------------------------------------------\n",
    "    # 3.3. Prepare info about Output tables\n",
    "    df_output = df_tables.loc[(df_tables['Task Type'].isin(['DATASET']) ) & \n",
    "                              (df_tables['Dataset type'].isin(['OUTPUT', 'UPDATE OUTPUT']))].copy()\n",
    "    df_output = df_output.rename(columns={'Table': 'Output Table',\n",
    "                                          'Node Id': 'Target ID'})\n",
    "    df_output.drop(['Text', 'Dataset type', 'Task Type'], inplace=True, axis=1)\n",
    "\n",
    "    #-------------------------------------------\n",
    "    # 3.4. Prepare info about Time Calculations\n",
    "    # 3.4.a Get Data\n",
    "    df_time = df_tables.loc[df_tables['Task Type'].isin(['OPENTIME', 'TASKSTARTTIME', 'JOBENDTIME'])].copy()\n",
    "\n",
    "    # 3.4.b Add time\n",
    "    df_time['Start Time'] = df_time[['Text','Task Type']].apply(lambda x: x[0].split()[2].replace('DATE:', '')  if x[1]=='OPENTIME'   # Inherit table type\n",
    "                                                                          else x[0].split()[1].replace('DATE:', '')\n",
    "                                                                , axis = 1)\n",
    "    df_time['Start Time']  = pd.to_datetime(df_time['Start Time'], format='%d%b%Y:%H:%M:%S.%f')\n",
    "\n",
    "    # 3.4.c Remove columns and rows\n",
    "    df_time.drop(['Table','Text','Task Type','Dataset type','Node Id'], inplace=True, axis=1)\n",
    "    df_time = df_time.drop_duplicates(subset=['Task ID', 'SubTask ID'], keep='first')\n",
    "\n",
    "    # 3.4.d Calculate time for each step\n",
    "    df_time['Elapsed Time'] = (df_time['Start Time'].shift(-1) - df_time['Start Time']).dt.total_seconds()\n",
    "    df_time['Elapsed Time'] = df_time['Elapsed Time'].round(2)\n",
    "\n",
    "    #-------------------------------------------\n",
    "    # 3.5. Output\n",
    "    # 3.5.a Merge the results for input and output tables + Elapsed time\n",
    "    df = df_input.merge(df_output, on=['Task ID', 'SubTask ID'], how = 'outer')\\\n",
    "                 .merge(df_time, on=['Task ID', 'SubTask ID'], how = 'left')\\\n",
    "                 .sort_values(['Task ID', 'SubTask ID'])\\\n",
    "                 .reset_index(drop = True)\n",
    "\n",
    "    # 3.5.b Fill missing for specific cases\n",
    "    df['Input Table'] = df['Input Table'].fillna('No Input')\n",
    "    df['Output Table'] = df['Output Table'].fillna('_null_')\n",
    "\n",
    "    # 3.5.c Correct Start time\n",
    "    df['Start Time'] = df['Start Time'].fillna(df['Start Time'].shift()) \n",
    "    df['Elapsed Time'] = df['Elapsed Time'].fillna(0)\n",
    "\n",
    "    # 3.5.d Correct Target node ID\n",
    "    df['Target ID'] = df['Target ID'].fillna(df['Task ID'].astype('str') +':'+ df['SubTask ID'].astype('str')+ ':No Output:Empty') \n",
    "\n",
    "    # 3.5.e Correct Source node ID\n",
    "    df['Source ID'] = df[['Input Table','Task ID','SubTask ID','Source ID']].apply(lambda x: str(x[1])+':'+str(int(x[2])-1)+':No Input:Empty' if x[0]=='No Input' \n",
    "                                                                                  else x[3], axis = 1)\n",
    "    \n",
    "    # 3.5.f Reorder columns\n",
    "    df = df[['Task ID','SubTask ID', 'Source ID','Target ID', 'Input Table','Output Table', 'Start Time','Elapsed Time']]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b025ae74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task ID</th>\n",
       "      <th>SubTask ID</th>\n",
       "      <th>Source ID</th>\n",
       "      <th>Target ID</th>\n",
       "      <th>Input Table</th>\n",
       "      <th>Output Table</th>\n",
       "      <th>Start Time</th>\n",
       "      <th>Elapsed Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1:0:No Input:Empty</td>\n",
       "      <td>1:1:WORK.__MTF_PD_PIT_VERSION:DATA</td>\n",
       "      <td>No Input</td>\n",
       "      <td>WORK.__MTF_PD_PIT_VERSION</td>\n",
       "      <td>2021-07-27 10:34:25.720</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1:1:WORK.__MTF_PD_PIT_VERSION:DATA</td>\n",
       "      <td>2:1:No Output:Empty</td>\n",
       "      <td>WORK.__MTF_PD_PIT_VERSION</td>\n",
       "      <td>_null_</td>\n",
       "      <td>2021-07-27 10:34:25.730</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0:0:INPUT.PD_VIEW:DATA</td>\n",
       "      <td>3:1:WORK.__MTF_PD_PIT_DISTINCT_RATING1:DATA</td>\n",
       "      <td>INPUT.PD_VIEW</td>\n",
       "      <td>WORK.__MTF_PD_PIT_DISTINCT_RATING1</td>\n",
       "      <td>2021-07-27 10:34:25.740</td>\n",
       "      <td>2.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0:0:INPUT.PD_VIEW:DATA</td>\n",
       "      <td>3:1:WORK.'SASTMP-000000348':UTILITY</td>\n",
       "      <td>INPUT.PD_VIEW</td>\n",
       "      <td>WORK.'SASTMP-000000348'</td>\n",
       "      <td>2021-07-27 10:34:25.740</td>\n",
       "      <td>2.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0:0:INPUT.PD_RR_RATING:DATA</td>\n",
       "      <td>3:2:WORK.__MTF_PD_PIT_DISTINCT_RATING2:DATA</td>\n",
       "      <td>INPUT.PD_RR_RATING</td>\n",
       "      <td>WORK.__MTF_PD_PIT_DISTINCT_RATING2</td>\n",
       "      <td>2021-07-27 10:34:28.670</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>159:1:WORK.__MTF_PD_PIT_ODR_LONG_DIS:DATA</td>\n",
       "      <td>160:1:WORK.TEST_PD_DIS_IN:DATA</td>\n",
       "      <td>WORK.__MTF_PD_PIT_ODR_LONG_DIS</td>\n",
       "      <td>WORK.TEST_PD_DIS_IN</td>\n",
       "      <td>2021-07-27 10:36:37.210</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>100:1:WORK.__MTF_PD_PIT_MARGINAL_BOTH_PD:DATA</td>\n",
       "      <td>160:1:WORK.TEST_PD_DIS_IN:DATA</td>\n",
       "      <td>WORK.__MTF_PD_PIT_MARGINAL_BOTH_PD</td>\n",
       "      <td>WORK.TEST_PD_DIS_IN</td>\n",
       "      <td>2021-07-27 10:36:37.210</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>161</td>\n",
       "      <td>1</td>\n",
       "      <td>161:0:No Input:Empty</td>\n",
       "      <td>161:1:WORK.'SASTMP-000000636':UTILITY</td>\n",
       "      <td>No Input</td>\n",
       "      <td>WORK.'SASTMP-000000636'</td>\n",
       "      <td>2021-07-27 10:36:37.420</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>162</td>\n",
       "      <td>1</td>\n",
       "      <td>162:0:No Input:Empty</td>\n",
       "      <td>162:1:WORK.'SASTMP-000000638':UTILITY</td>\n",
       "      <td>No Input</td>\n",
       "      <td>WORK.'SASTMP-000000638'</td>\n",
       "      <td>2021-07-27 10:36:37.890</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>163:0:No Input:Empty</td>\n",
       "      <td>163:1:WORK.'SASTMP-000000640':UTILITY</td>\n",
       "      <td>No Input</td>\n",
       "      <td>WORK.'SASTMP-000000640'</td>\n",
       "      <td>2021-07-27 10:36:37.930</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>291 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Task ID  SubTask ID                                      Source ID  \\\n",
       "0          1           1                             1:0:No Input:Empty   \n",
       "1          2           1             1:1:WORK.__MTF_PD_PIT_VERSION:DATA   \n",
       "2          3           1                         0:0:INPUT.PD_VIEW:DATA   \n",
       "3          3           1                         0:0:INPUT.PD_VIEW:DATA   \n",
       "4          3           2                    0:0:INPUT.PD_RR_RATING:DATA   \n",
       "..       ...         ...                                            ...   \n",
       "286      160           1      159:1:WORK.__MTF_PD_PIT_ODR_LONG_DIS:DATA   \n",
       "287      160           1  100:1:WORK.__MTF_PD_PIT_MARGINAL_BOTH_PD:DATA   \n",
       "288      161           1                           161:0:No Input:Empty   \n",
       "289      162           1                           162:0:No Input:Empty   \n",
       "290      163           1                           163:0:No Input:Empty   \n",
       "\n",
       "                                       Target ID  \\\n",
       "0             1:1:WORK.__MTF_PD_PIT_VERSION:DATA   \n",
       "1                            2:1:No Output:Empty   \n",
       "2    3:1:WORK.__MTF_PD_PIT_DISTINCT_RATING1:DATA   \n",
       "3            3:1:WORK.'SASTMP-000000348':UTILITY   \n",
       "4    3:2:WORK.__MTF_PD_PIT_DISTINCT_RATING2:DATA   \n",
       "..                                           ...   \n",
       "286               160:1:WORK.TEST_PD_DIS_IN:DATA   \n",
       "287               160:1:WORK.TEST_PD_DIS_IN:DATA   \n",
       "288        161:1:WORK.'SASTMP-000000636':UTILITY   \n",
       "289        162:1:WORK.'SASTMP-000000638':UTILITY   \n",
       "290        163:1:WORK.'SASTMP-000000640':UTILITY   \n",
       "\n",
       "                            Input Table                        Output Table  \\\n",
       "0                              No Input           WORK.__MTF_PD_PIT_VERSION   \n",
       "1             WORK.__MTF_PD_PIT_VERSION                              _null_   \n",
       "2                         INPUT.PD_VIEW  WORK.__MTF_PD_PIT_DISTINCT_RATING1   \n",
       "3                         INPUT.PD_VIEW             WORK.'SASTMP-000000348'   \n",
       "4                    INPUT.PD_RR_RATING  WORK.__MTF_PD_PIT_DISTINCT_RATING2   \n",
       "..                                  ...                                 ...   \n",
       "286      WORK.__MTF_PD_PIT_ODR_LONG_DIS                 WORK.TEST_PD_DIS_IN   \n",
       "287  WORK.__MTF_PD_PIT_MARGINAL_BOTH_PD                 WORK.TEST_PD_DIS_IN   \n",
       "288                            No Input             WORK.'SASTMP-000000636'   \n",
       "289                            No Input             WORK.'SASTMP-000000638'   \n",
       "290                            No Input             WORK.'SASTMP-000000640'   \n",
       "\n",
       "                 Start Time  Elapsed Time  \n",
       "0   2021-07-27 10:34:25.720          0.01  \n",
       "1   2021-07-27 10:34:25.730          0.01  \n",
       "2   2021-07-27 10:34:25.740          2.93  \n",
       "3   2021-07-27 10:34:25.740          2.93  \n",
       "4   2021-07-27 10:34:28.670          0.00  \n",
       "..                      ...           ...  \n",
       "286 2021-07-27 10:36:37.210          0.21  \n",
       "287 2021-07-27 10:36:37.210          0.21  \n",
       "288 2021-07-27 10:36:37.420          0.47  \n",
       "289 2021-07-27 10:36:37.890          0.04  \n",
       "290 2021-07-27 10:36:37.930          0.01  \n",
       "\n",
       "[291 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_connections = df_to_connections(df_log)\n",
    "df_connections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb34879b",
   "metadata": {},
   "source": [
    "## 2. Graph data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18fa588f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for defining positions of tables\n",
    "def get_coords(G):\n",
    "    \n",
    "    #--------------------------------------------------------------------\n",
    "    # get source nodes \n",
    "    source_nodes = sorted([node for node in G.nodes() if G.in_degree(node) == 0])\n",
    "    \n",
    "    #--------------------------------------------------------------------\n",
    "    # Get nodes in traversal order\n",
    "    list_nodes = []\n",
    "    for i in range(len(source_nodes)):\n",
    "        # Define source node\n",
    "        source = source_nodes[i]\n",
    "        # Get nodes in depth order\n",
    "        list_nodes_depth = list(nx.dfs_preorder_nodes(G, source=source, depth_limit=None))\n",
    "        # Extend main list\n",
    "        list_nodes.extend(list_nodes_depth)\n",
    "        \n",
    "    #--------------------------------------------------------------------\n",
    "    # Add elements if missed\n",
    "    list_nodes_full = sorted(list(G.nodes))\n",
    "    list_nodes.extend(list_nodes_full)\n",
    "\n",
    "    #--------------------------------------------------------------------\n",
    "    # Create df\n",
    "    df_nodes = pd.DataFrame(list_nodes, columns =['Node'])\n",
    "    df_nodes['Task ID'] = df_nodes['Node'].str.split(':').str[0].astype('float')\n",
    "    df_nodes['SubTask ID'] = df_nodes['Node'].str.split(':').str[1].astype('float')\n",
    "    df_nodes = df_nodes.drop_duplicates(subset=['Node'], keep='first')\n",
    "    \n",
    "    #--------------------------------------------------------------------\n",
    "    # Assign y\n",
    "    df_nodes = df_nodes.reset_index(drop=True)\n",
    "    df_nodes['Lag Node'] = df_nodes['Node'].shift()\n",
    "    df_nodes['Lag Task ID'] = df_nodes['Task ID'].shift()\n",
    "    df_nodes['Lag SubTask ID'] = df_nodes['SubTask ID'].shift()\n",
    "    y_list = [0] \n",
    "    for index, row in df_nodes.iterrows():\n",
    "        # Get predecessors\n",
    "        predecessors = [c for c in G.predecessors( row['Node'] )]\n",
    "        if (row['Lag Node'] in predecessors):\n",
    "            if (row['Task ID'] == row['Lag Task ID'])  & (row['SubTask ID'] == row['Lag SubTask ID']):\n",
    "                y_list.append(y_list[index] + 1)\n",
    "            else: \n",
    "                y_list.append(y_list[index])\n",
    "        else:\n",
    "            y_list.append(y_list[index] + 1)\n",
    "    df_nodes['y'] = y_list[1:]\n",
    "    \n",
    "    #--------------------------------------------------------------------\n",
    "    # Reorder nodes\n",
    "    df_nodes = df_nodes.sort_values(by=['Task ID','SubTask ID'])\n",
    "\n",
    "    #--------------------------------------------------------------------\n",
    "    # Assign x\n",
    "    df_nodes = df_nodes.reset_index(drop=True)\n",
    "    df_nodes['Lag Task ID'] = df_nodes['Task ID'].shift()\n",
    "    df_nodes['Lag SubTask ID'] = df_nodes['SubTask ID'].shift()\n",
    "    x_list = [-2] \n",
    "    for index, row in df_nodes.iterrows():\n",
    "        # Move from task to task\n",
    "        if (row['Task ID'] != row ['Lag Task ID']):\n",
    "            x_list.append(x_list[index] + 2)\n",
    "        # Move from subtask to subtask        \n",
    "        elif (row['Task ID'] == row ['Lag Task ID']) & (row['SubTask ID'] != row ['Lag SubTask ID']):\n",
    "            x_list.append(x_list[index] + 1)  \n",
    "        else:\n",
    "            x_list.append(x_list[index])\n",
    "    df_nodes['x'] = x_list[1:]\n",
    "\n",
    "    #--------------------------------------------------------------------\n",
    "    # Coords dict\n",
    "    coords = df_nodes[['Node', 'x' , 'y']].set_index('Node').T.to_dict('list')\n",
    "    \n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6748f5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for extracting data on tables\n",
    "def get_node_df(G):  \n",
    "\n",
    "    node_dict = {'node_x':[],\n",
    "                 'node_y':[],\n",
    "                 'node_label':[],\n",
    "                 'step_id':[],\n",
    "                 'node_group':[],\n",
    "                 'node_color':[],\n",
    "                 'node_shape':[]}\n",
    "    \n",
    "    for node in G.nodes():  \n",
    "        #--------------------------------------------------------------------\n",
    "        # Node Coords\n",
    "        x, y = G.nodes[node]['coords']\n",
    "        node_dict['node_x'].append(x)\n",
    "        node_dict['node_y'].append(y)   \n",
    "\n",
    "        #--------------------------------------------------------------------\n",
    "        # Node name\n",
    "        table_name = node.split(':')[2]\n",
    "        node_dict['node_label'].append(table_name)  \n",
    "        \n",
    "        #--------------------------------------------------------------------\n",
    "        # Step ID\n",
    "        node_dict['step_id'].append(node.split(':')[0])  \n",
    "        \n",
    "        #--------------------------------------------------------------------\n",
    "        # Table Type\n",
    "        table_type = node.split(':')[3]       \n",
    "        \n",
    "        #--------------------------------------------------------------------\n",
    "        # Predesessors\n",
    "        predecessors = [c.split(':')[2] for c in G.predecessors(node)]\n",
    "\n",
    "        #--------------------------------------------------------------------\n",
    "        # Node shape and color\n",
    "        # a) No Input node\n",
    "        if table_name == 'No Input':\n",
    "            node_dict['node_group'].append('No Input')  \n",
    "            node_dict['node_shape'].append('diamond-cross')  \n",
    "            node_dict['node_color'].append('grey')  \n",
    "        # b) No Output node\n",
    "        elif table_name == 'No Output':\n",
    "            node_dict['node_group'].append('No Output')  \n",
    "            node_dict['node_shape'].append('square-cross')  \n",
    "            node_dict['node_color'].append('grey')\n",
    "        # c) Temporary tables\n",
    "        elif (table_type == 'UTILITY') | ('SORTTMP' in table_name):\n",
    "            node_dict['node_group'].append('Technical Table')  \n",
    "            node_dict['node_shape'].append('star-square-dot')  \n",
    "            node_dict['node_color'].append('silver')\n",
    "        # d) Input node\n",
    "        elif G.in_degree(node) == 0:\n",
    "            node_dict['node_group'].append('Input Table')  \n",
    "            node_dict['node_shape'].append('diamond')  \n",
    "            node_dict['node_color'].append('gold')\n",
    "        # e) Output node\n",
    "        elif G.out_degree(node) == 0:\n",
    "            node_dict['node_group'].append('Output Table')  \n",
    "            node_dict['node_shape'].append('square')  \n",
    "            node_dict['node_color'].append('cyan')\n",
    "        # f) Updated node            \n",
    "        elif table_name in predecessors:\n",
    "            node_dict['node_group'].append('Updated Table')  \n",
    "            node_dict['node_shape'].append('cross')  \n",
    "            node_dict['node_color'].append('orange')\n",
    "        # g) Internal nodes\n",
    "        else:\n",
    "            node_dict['node_group'].append('Internal Table')  \n",
    "            node_dict['node_shape'].append('circle')  \n",
    "            node_dict['node_color'].append('blue')\n",
    "\n",
    "    node_df = pd.DataFrame(node_dict)\n",
    "    node_df['step_id'] = node_df['step_id'].astype('int')\n",
    "    \n",
    "    return node_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c19a2cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for extracting data on connections\n",
    "def get_edge_df(G):\n",
    "    \n",
    "    edge_dict = {'edge_x':[],\n",
    "                 'edge_y':[],\n",
    "                 'node_x':[],\n",
    "                 'node_y':[],\n",
    "                 'text_x':[],\n",
    "                 'text_y':[],\n",
    "                 'step_id':[],\n",
    "                 'text_color_values':[],\n",
    "                 'text_labels':[]}\n",
    "\n",
    "    for edge in G.edges():\n",
    "        #--------------------------------------------------------------------\n",
    "        # Get Coords\n",
    "        x0, y0 = G.nodes[edge[0]]['coords']\n",
    "        x1, y1 = G.nodes[edge[1]]['coords']\n",
    "        x_mean = round( (x0+x1)/2, 4)\n",
    "        y_mean = round( (y0+y1)/2, 4)   \n",
    "\n",
    "        #--------------------------------------------------------------------\n",
    "        # Shift central points        \n",
    "        shift = (( (x1-x0)**2 + (y1-y0)**2 )**0.5) * 0.05    \n",
    "        # If Horizontal line\n",
    "        if x0 == x1:\n",
    "            x_mean = x_mean + shift\n",
    "        # If Vertical line            \n",
    "        elif y0 == y1:\n",
    "            y_mean = y_mean - shift\n",
    "\n",
    "        #--------------------------------------------------------------------\n",
    "        # Colorbar values\n",
    "        color_value = G.edges[edge[0],edge[1]]['Elapsed Time'] \n",
    "\n",
    "        #--------------------------------------------------------------------\n",
    "        # Hover text\n",
    "        text_label = 'Task ID: '+str(G.edges[edge[0],edge[1]]['Task ID'])\\\n",
    "                        +' '+\\\n",
    "                        'SubTask ID: '+str(G.edges[edge[0],edge[1]]['SubTask ID'])\\\n",
    "                        +'<br> '+\\\n",
    "                        'Input: '+str(G.edges[edge[0],edge[1]]['Input Table'])\\\n",
    "                        +'<br> '+\\\n",
    "                        'Output: '+str(G.edges[edge[0],edge[1]]['Output Table'])\\\n",
    "                        +'<br> '+\\\n",
    "                        'Elapsed Time: '+str(G.edges[edge[0],edge[1]]['Elapsed Time'])\n",
    "\n",
    "        #--------------------------------------------------------------------\n",
    "        # output\n",
    "        edge_dict['edge_x'].append(x0)\n",
    "        edge_dict['edge_y'].append(y0)    \n",
    "        edge_dict['node_x'].append(x1)\n",
    "        edge_dict['node_y'].append(y1)  \n",
    "        edge_dict['text_x'].append(x_mean)\n",
    "        edge_dict['text_y'].append(y_mean)  \n",
    "        edge_dict['step_id'].append(G.edges[edge[0],edge[1]]['Task ID']) \n",
    "        edge_dict['text_color_values'].append(color_value)   \n",
    "        edge_dict['text_labels'].append(text_label) \n",
    "\n",
    "    edge_df = pd.DataFrame(edge_dict)\n",
    "\n",
    "    return edge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "def10b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiGraph with 241 nodes and 291 edges\n"
     ]
    }
   ],
   "source": [
    "# Function for generating a networkx Graph\n",
    "def get_graph_data(df):\n",
    "\n",
    "    # Create graph\n",
    "    G = nx.from_pandas_edgelist(df,\n",
    "                                'Source ID','Target ID',\n",
    "                                ['Task ID','SubTask ID','Input Table','Output Table','Start Time','Elapsed Time'],\n",
    "                                create_using=nx.DiGraph())\n",
    "    print(nx.info(G))\n",
    "\n",
    "    # Define positions of tables\n",
    "    coords = get_coords(G)\n",
    "    \n",
    "    # Add positions to the graph\n",
    "    nx.set_node_attributes(G, coords, 'coords') \n",
    "\n",
    "    # Create table for connections and label text\n",
    "    edge_df = get_edge_df(G)\n",
    "\n",
    "    # Create table for nodes\n",
    "    node_df = get_node_df(G)\n",
    "\n",
    "    # Combine the two tables\n",
    "    df_graph = edge_df.merge(node_df, on=['step_id', 'node_x', 'node_y'], how = 'outer')\n",
    "    \n",
    "    # Fill empty values \n",
    "    # 1. Edge coords\n",
    "    df_graph['edge_x'] = df_graph['edge_x'].replace(np.nan, 'None')\n",
    "    df_graph['edge_y'] = df_graph['edge_y'].replace(np.nan, 'None')\n",
    "    # 2. Text coords\n",
    "    df_graph['text_x'] = df_graph['text_x'].replace(np.nan, 'None')\n",
    "    df_graph['text_y'] = df_graph['text_y'].replace(np.nan, 'None')\n",
    "    # 3. Labels\n",
    "    df_graph['text_labels'] = df_graph['text_labels'].fillna('')\n",
    "    # 4. Color\n",
    "    df_graph['text_color_values'] = df_graph['text_color_values'].fillna(0)\n",
    "    \n",
    "    # Get color codes\n",
    "    norm = matplotlib.colors.Normalize(vmin=min(df_graph['text_color_values']), \n",
    "                                       vmax=max(df_graph['text_color_values']), \n",
    "                                       clip=True)\n",
    "    mapper = cm.ScalarMappable(norm=norm, cmap='RdYlGn_r')\n",
    "    df_graph['edge_hex'] = df_graph['text_color_values'].apply(lambda x: matplotlib.colors.to_hex(mapper.to_rgba(x), keep_alpha=False))\n",
    "    \n",
    "    df_graph = df_graph\n",
    "    return df_graph.sort_values(by=['step_id'])\n",
    "\n",
    "df_graph = get_graph_data(df_connections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7120ea",
   "metadata": {},
   "source": [
    "## 3. Dash plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dfee18",
   "metadata": {},
   "source": [
    "### 3.1. Network plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ff134f",
   "metadata": {},
   "source": [
    "#### 3.1.a Node Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f822a39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for drawing table positions\n",
    "def get_node_trace(df):\n",
    "    \n",
    "    node_trace = go.Scatter(x = df['node_x'], \n",
    "                            y = df['node_y'],\n",
    "                            mode = 'markers',\n",
    "                            # Marker\n",
    "                            marker=dict(symbol = df['node_shape'], \n",
    "                                        color = df['node_color'],\n",
    "                                        size = 10),\n",
    "                            marker_line_color='black', \n",
    "                            marker_line_width=0.5,\n",
    "                            # Text\n",
    "                            text = df['node_label'],\n",
    "                            textposition = 'top center',                            \n",
    "                            hovertemplate = '%{text}',\n",
    "                            # Legend\n",
    "                            showlegend=False,\n",
    "                            # Meta\n",
    "                            meta = df['step_id']\n",
    "                           )\n",
    "    \n",
    "    return node_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70a10734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# network plot\n",
    "node_trace = get_node_trace(df_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd01c94",
   "metadata": {},
   "source": [
    "#### 3.1.b. Edge Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f6a233e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for drawing table connections\n",
    "def get_edge_trace(df):\n",
    "    \n",
    "    edge_trace = []\n",
    "    edge_trace_outline = []    \n",
    "    for index, row in df.iterrows():\n",
    "        # Outline \n",
    "        edge_trace_outline.append(go.Scatter(x = [row['edge_x'], row['text_x'], row['node_x'], None],\n",
    "                                             y = [row['edge_y'], row['text_y'], row['node_y'], None],\n",
    "                                             mode = 'lines', \n",
    "                                             # line\n",
    "                                             line_shape = 'spline',\n",
    "                                             line = dict(width=3, \n",
    "                                                         dash='dot', \n",
    "                                                         color='grey'),\n",
    "                                             # Text\n",
    "                                             hoverinfo = 'none',\n",
    "                                             # Legend\n",
    "                                             showlegend=False,\n",
    "                                             # Meta\n",
    "                                             meta = row['step_id'] \n",
    "                                            )\n",
    "                         )\n",
    "        # Line\n",
    "        edge_trace.append(go.Scatter(x = [row['edge_x'], row['text_x'], row['node_x'], None],\n",
    "                                     y = [row['edge_y'], row['text_y'], row['node_y'], None],\n",
    "                                     mode = 'lines', \n",
    "                                     # line\n",
    "                                     line_shape = 'spline',\n",
    "                                     line = dict(width=1.5, \n",
    "                                                 dash='dot', \n",
    "                                                 color=row['edge_hex']),\n",
    "                                     # Text\n",
    "                                     hoverinfo = 'none',\n",
    "                                     # Legend\n",
    "                                     showlegend=False,\n",
    "                                     # Meta\n",
    "                                     meta = row['step_id'] \n",
    "                                    )\n",
    "                         )\n",
    "        \n",
    "    return edge_trace, edge_trace_outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "225a1191",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_trace, edge_trace_outline = get_edge_trace(df_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea193db9",
   "metadata": {},
   "source": [
    "#### 3.1.c Text trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "114ab78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for drawing connection info\n",
    "def get_text_trace(df):\n",
    "    \n",
    "    text_trace = go.Scatter(x=df['text_x'], \n",
    "                            y=df['text_y'], \n",
    "                            # Marker\n",
    "                            mode = 'markers', \n",
    "                            marker_symbol = 'hexagram',\n",
    "                            marker=dict(showscale=True, \n",
    "                                        colorscale='RdYlGn', \n",
    "                                        reversescale=True,\n",
    "                                        size = 8, \n",
    "                                        color=df['text_color_values'],\n",
    "                                        colorbar=dict(thickness=15,\n",
    "                                                      title='Execution time (s)',\n",
    "                                                      xanchor='left',\n",
    "                                                      titleside='right')\n",
    "                                       ),                            \n",
    "                            marker_line_color='black', \n",
    "                            marker_line_width=0.5,\n",
    "                            # Text\n",
    "                            text = df['text_labels'],  \n",
    "                            textposition = 'top center',\n",
    "                            hovertemplate = '%{text}',\n",
    "                            # Legend\n",
    "                            showlegend=False,\n",
    "                            # Meta\n",
    "                            meta = df['step_id']                           \n",
    "                           )\n",
    "    \n",
    "    return text_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f07309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_trace = get_text_trace(df_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7648fe4f",
   "metadata": {},
   "source": [
    "#### 3.1.d Network Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85785783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_network(edge_trace_outline, edge_trace, node_trace, text_trace):\n",
    "    fig = go.Figure(edge_trace_outline + edge_trace + [node_trace] + [text_trace]) \n",
    "    fig.update_layout(xaxis=dict(zeroline=False,\n",
    "                                 showticklabels=False),\n",
    "                      yaxis=dict(showgrid=False, \n",
    "                                 zeroline=False,\n",
    "                                 showticklabels=False,\n",
    "                                 autorange='reversed'),\n",
    "                      legend=dict(orientation='h',\n",
    "                                  x=1, y=1.02,\n",
    "                                  xanchor='right', yanchor='bottom'),\n",
    "                      margin=dict(t=0, b=10,\n",
    "                                  l=10, r=0)\n",
    "                     )\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b43ee913",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_net = draw_network(edge_trace_outline, edge_trace, node_trace, text_trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622a929d",
   "metadata": {},
   "source": [
    "#### 3.1.e Legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28f1e3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_legend():\n",
    "    fig = go.Figure(go.Scatter(x=[0,0,0,0,0,0,0],\n",
    "                               y=['No Input','No Output','Technical Table','Input Table','Output Table','Updated Table','Internal Table'] ,\n",
    "                               mode = 'markers',\n",
    "                               # Marker\n",
    "                               marker=dict(symbol = ['diamond-cross','square-cross','star-square-dot','diamond','square','cross','circle'],\n",
    "                                           color = ['grey','grey','silver','gold','cyan','orange','blue'],\n",
    "                                           size = 10),\n",
    "                               marker_line_color='black',\n",
    "                               marker_line_width=0.5,\n",
    "                               text = ['No Input','No Output','Technical Table','Input Table','Output Table','Updated Table','Internal Table'],\n",
    "                               # Legend\n",
    "                               showlegend=False)\n",
    "                          )\n",
    "    fig.update_layout(xaxis=dict(showgrid=False,\n",
    "                                 showticklabels=False),\n",
    "                      yaxis=dict(showgrid=False),\n",
    "                      xaxis_side=\"top\",\n",
    "                      margin=dict(t=0, b=10,\n",
    "                                  l=0, r=0),\n",
    "                      width = 100\n",
    "                     )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4607fdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_legend = draw_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb3dcf7",
   "metadata": {},
   "source": [
    "### 3.2 Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b424f802",
   "metadata": {},
   "source": [
    "#### 3.2.a Table filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64f2ec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operator dict\n",
    "operators = [['ge ', '>='],\n",
    "             ['le ', '<='],\n",
    "             ['lt ', '<'],\n",
    "             ['gt ', '>'],\n",
    "             ['ne ', '!='],\n",
    "             ['eq ', '='],\n",
    "             ['contains '],\n",
    "             ['datestartswith ']]\n",
    "\n",
    "#======================================================================\n",
    "# Filter query syntax split\n",
    "def split_filter_part(filter_part):\n",
    "    for operator_type in operators:\n",
    "        for operator in operator_type:\n",
    "            if operator in filter_part:\n",
    "                name_part, value_part = filter_part.split(operator, 1)\n",
    "                name = name_part[name_part.find('{') + 1: name_part.rfind('}')]\n",
    "\n",
    "                value_part = value_part.strip()\n",
    "                v0 = value_part[0]\n",
    "                if (v0 == value_part[-1] and v0 in (\"'\", '\"', '`')):\n",
    "                    value = value_part[1: -1].replace('\\\\' + v0, v0)\n",
    "                else:\n",
    "                    try:\n",
    "                        value = float(value_part)\n",
    "                    except ValueError:\n",
    "                        value = value_part\n",
    "\n",
    "                return name, operator_type[0].strip(), value\n",
    "\n",
    "    return [None] * 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fb293a",
   "metadata": {},
   "source": [
    "#### 3.2.b Draw Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63c1fd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_table(df):\n",
    "    table = dash_table.DataTable(id='table',\n",
    "                                 columns=[{'name': i, 'id': i} for i in df.columns],\n",
    "                                 data=df.to_dict('records'),\n",
    "                                 # Filtering\n",
    "                                 filter_action='native',\n",
    "                                 filter_query='',\n",
    "                                 # Styles\n",
    "                                 style_header={'fontWeight': 'bold',\n",
    "                                               'backgroundColor': 'rgb(48, 84, 150)',\n",
    "                                               'color': 'white'},\n",
    "                                 style_filter={'backgroundColor': 'rgb(142, 169, 219)',\n",
    "                                               'color': 'white'},\n",
    "                                 style_cell={'backgroundColor': 'rgb(217, 225, 242)',\n",
    "                                             'textAlign': 'left', 'color': 'black',\n",
    "                                             'width': '150px', 'minWidth': '180px', 'maxWidth': '180px',\n",
    "                                             'whiteSpace': 'pre-line'},\n",
    "                                 # Sorting\n",
    "                                 sort_action='native',\n",
    "                                 sort_mode='multi',\n",
    "                                 # Column size\n",
    "                                 style_cell_conditional=[{'if': {'column_id': 'Task ID'}, 'width': '5%'},\n",
    "                                                         {'if': {'column_id': 'Code'}, 'width': '75%'},\n",
    "                                                         {'if': {'column_id': 'Procedure'}, 'width': '5%'},\n",
    "                                                         {'if': {'column_id': 'Start Time'}, 'width': '10%'},\n",
    "                                                         {'if': {'column_id': 'Elapsed Time'}, 'width': '5%'}],\n",
    "                                 # Table size\n",
    "                                 fixed_rows={'headers': True},\n",
    "                                 style_table={'overflowY': 'scroll', \n",
    "                                              'border': 'thin lightgrey solid'}, \n",
    "                                )\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "daaff747",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_table = draw_table(df_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695dd840",
   "metadata": {},
   "source": [
    "### 3.3 Interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ac590c",
   "metadata": {},
   "source": [
    "#### 3.3.a Scatter -> Table interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22eb40a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_query(selectedData):\n",
    "    # Get list of selected Step IDs\n",
    "    x_values = []\n",
    "    for elements in selectedData['points']:\n",
    "        if 'meta' in elements:\n",
    "            if elements['meta'] not in x_values:\n",
    "                x_values.append( int(elements['meta']) )\n",
    "    # Generate filter query\n",
    "    query =''\n",
    "    if len(x_values) != 0:\n",
    "        # 2.1 Formulate query\n",
    "        for filter_value in x_values:\n",
    "            query = query + '{Task ID} = ' + str(filter_value) + ' or '\n",
    "        # 2.2. Remove last or\n",
    "        query = ' '.join(query.split(' ')[:-2])\n",
    "    return query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b292270f",
   "metadata": {},
   "source": [
    "#### 3.3.b Table  -> Scatter interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "326f5c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_scatter(filter_query):\n",
    "    # 1. Make copy of df and figure\n",
    "    dff = copy.copy(df_code) \n",
    "    fig_copy = copy.copy(fig_net) \n",
    "\n",
    "    # 2. Fetch step ids based on filter query\n",
    "    filtering_expressions = filter_query.split(' && ')\n",
    "    for filter_part in filtering_expressions:\n",
    "        col_name, operator, filter_value = split_filter_part(filter_part)\n",
    "        if operator in ('eq', 'ne', 'lt', 'le', 'gt', 'ge'):\n",
    "            dff = dff.loc[getattr(dff[col_name], operator)(filter_value)]\n",
    "        elif operator == 'contains':\n",
    "            dff = dff.loc[dff[col_name].str.contains(filter_value)]   \n",
    "        elif operator == 'datestartswith':\n",
    "            dff = dff.loc[dff[col_name].str.startswith(filter_value)]\n",
    "    step_list = list(dff['Task ID'])\n",
    "    \n",
    "    # 3. Select figure traces that are in the filtered data\n",
    "    selected_points = []\n",
    "    fig_data = fig_copy['data']\n",
    "    for i in range(len(fig_data)):\n",
    "        meta = fig_data[i]['meta']\n",
    "        if isinstance(meta, int):\n",
    "            if meta in step_list:\n",
    "                selected_points.append(i)\n",
    "    \n",
    "    # 4. Update figure\n",
    "    fig_copy.update_traces(selectedpoints = selected_points)\n",
    "\n",
    "    return fig_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304b1ccc",
   "metadata": {},
   "source": [
    "### 3.4. Dash Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74239372",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:8050/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [15/Jun/2022 13:40:02] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [15/Jun/2022 13:40:02] \"\u001b[37mGET /_dash-component-suites/dash_renderer/prop-types@15.v1_9_1m1622715601.7.2.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [15/Jun/2022 13:40:02] \"\u001b[37mGET /_dash-component-suites/dash_renderer/react@16.v1_9_1m1622715601.14.0.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [15/Jun/2022 13:40:02] \"\u001b[37mGET /_dash-component-suites/dash_renderer/react-dom@16.v1_9_1m1622715601.14.0.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [15/Jun/2022 13:40:02] \"\u001b[37mGET /_dash-component-suites/dash_table/bundle.v4_11_3m1622715601.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [15/Jun/2022 13:40:02] \"\u001b[37mGET /_dash-component-suites/dash_renderer/polyfill@7.v1_9_1m1622715601.8.7.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [15/Jun/2022 13:40:02] \"\u001b[37mGET /_dash-component-suites/dash_core_components/dash_core_components-shared.v1_16_0m1622715604.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [15/Jun/2022 13:40:02] \"\u001b[37mGET /_dash-component-suites/dash_core_components/dash_core_components.v1_16_0m1622715604.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [15/Jun/2022 13:40:02] \"\u001b[37mGET /_dash-component-suites/dash_html_components/dash_html_components.v1_1_3m1622715601.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [15/Jun/2022 13:40:02] \"\u001b[37mGET /_dash-component-suites/dash_renderer/dash_renderer.v1_9_1m1622715601.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [15/Jun/2022 13:40:03] \"\u001b[37mGET /_dash-dependencies HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [15/Jun/2022 13:40:03] \"\u001b[37mGET /_favicon.ico?v=1.20.0 HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [15/Jun/2022 13:40:03] \"\u001b[37mGET /_dash-layout HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [15/Jun/2022 13:40:03] \"\u001b[37mGET /_dash-component-suites/dash_core_components/async-graph.v1_16_0m1617903285.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [15/Jun/2022 13:40:03] \"\u001b[37mGET /_dash-component-suites/dash_table/async-highlight.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [15/Jun/2022 13:40:03] \"\u001b[37mGET /_dash-component-suites/dash_table/async-table.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [15/Jun/2022 13:40:03] \"\u001b[37mGET /_dash-component-suites/dash_core_components/async-plotlyjs.v1_16_0m1617903285.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [15/Jun/2022 13:40:06] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [15/Jun/2022 13:41:04] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [15/Jun/2022 13:41:12] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [15/Jun/2022 13:41:16] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [15/Jun/2022 13:41:26] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Server start\n",
    "app = dash.Dash()\n",
    "\n",
    "#======================================================================\n",
    "# Dash plot\n",
    "app.layout = html.Div([\n",
    "    #--------------------------------------------------------------\n",
    "    # 1. First row - Reset Button\n",
    "    html.Div(children=[html.Button('Reset Graphs', id='reset_button', n_clicks=0)],\n",
    "             className='row',\n",
    "             style={'height':'5%', 'display':'inline-block', 'vertical-align':'top', 'horizontal-align':'center'}), \n",
    "    \n",
    "    #--------------------------------------------------------------\n",
    "    # 2. Second row - Legend and Network\n",
    "    html.Div(children=[\n",
    "        # 1.1 first column of first row - Legend\n",
    "        html.Div(children=[dcc.Graph(id='legend', figure=fig_legend)],\n",
    "                 style={'width':'10%', 'display':'inline-block', 'vertical-align':'top', 'horizontal-align':'center'}),\n",
    "        # 1.2 second column of first row - Network\n",
    "        html.Div(children=[dcc.Graph(id='network', figure=fig_net)],\n",
    "                 style={'width':'90%', 'display':'inline-block', 'vertical-align':'top', 'horizontal-align':'center'}),\n",
    "    ], className='row'),\n",
    "    \n",
    "    #--------------------------------------------------------------\n",
    "    # 3. Third row - Table\n",
    "    html.Div(children=[fig_table], \n",
    "             className='row', \n",
    "             style={'width':'100%', 'vertical-align':'top', 'horizontal-align':'center'})\n",
    "])\n",
    "\n",
    "# ======================================================================\n",
    "# Add Scatter-Table-Reset interactions\n",
    "@app.callback([Output('reset_button','n_clicks'), Output('table', 'filter_query'), Output('network', 'selectedData'), Output('network', 'figure')],\n",
    "              [Input('reset_button','n_clicks'), Input('table', 'filter_query'), Input('network', 'selectedData')])\n",
    "def update_figures(n_clicks, filter_query, selectedData):\n",
    "    \n",
    "    # 1. If reset is clicked - restart table and scatter\n",
    "    if n_clicks is not None and n_clicks > 0:  \n",
    "        return 0, '', None, fig_net  \n",
    "    \n",
    "    # 2. If filter is applied to Network -> update Table\n",
    "    elif selectedData is not None:\n",
    "        selected_query = update_query(selectedData)\n",
    "        if filter_query != '':            \n",
    "            full_query = '(' + filter_query + ') and (' + selected_query + ')' # Data selected based on query and scatter\n",
    "            return dash.no_update, full_query, dash.no_update, dash.no_update\n",
    "        else:\n",
    "            return dash.no_update, selected_query, None, dash.no_update\n",
    "        \n",
    "    # 3. If filter is applied to Table - update Network\n",
    "    elif filter_query is not None and filter_query != '': \n",
    "        fig_updated = update_scatter(filter_query)\n",
    "        return dash.no_update, dash.no_update,  None, fig_updated\n",
    "    \n",
    "    # 4. If filter query is reset - update Network\n",
    "    elif filter_query == '' and selectedData is None:\n",
    "        return dash.no_update, dash.no_update,  None, fig_net        \n",
    "    \n",
    "    # 5. No change\n",
    "    else:\n",
    "        raise dash.exceptions.PreventUpdate\n",
    "        \n",
    "#======================================================================\n",
    "app.run_server(debug=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6e549c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4ccf77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
