{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d22e3be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plots\n",
    "import networkx as nx\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.offline as py\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Dash\n",
    "import dash\n",
    "import dash_table\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f494414b",
   "metadata": {},
   "source": [
    "# 1. Log parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78180b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'Data\\New_PIT2.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1489d9a",
   "metadata": {},
   "source": [
    "#### 1.1 Extract df from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62547408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Task Type</th>\n",
       "      <th>Task ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JOBSTARTTIME 27JUL2021:10:34:25.72</td>\n",
       "      <td>JOBSTARTTIME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TASKSTARTTIME 27JUL2021:10:34:25.72</td>\n",
       "      <td>TASKSTARTTIME</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CATALOG INPUT WORK.SASMAC1.MTF_IFRS9_PD_PIT_BA...</td>\n",
       "      <td>CATALOG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LIBNAME WORK V9 '/opt/sas/saswork/SAS_work2019...</td>\n",
       "      <td>LIBNAME</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3976</th>\n",
       "      <td>ELAPSED 8</td>\n",
       "      <td>ELAPSED</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>PROCNAME DATASETS</td>\n",
       "      <td>PROCNAME</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>proc datasets lib = work nolist noprint memty...</td>\n",
       "      <td>STEP</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>JOBENDTIME 27JUL2021:10:36:37.94</td>\n",
       "      <td>JOBENDTIME</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>END</td>\n",
       "      <td>END</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3981 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text      Task Type  \\\n",
       "0                                                                  NaN   \n",
       "1                   JOBSTARTTIME 27JUL2021:10:34:25.72    JOBSTARTTIME   \n",
       "2                  TASKSTARTTIME 27JUL2021:10:34:25.72   TASKSTARTTIME   \n",
       "3     CATALOG INPUT WORK.SASMAC1.MTF_IFRS9_PD_PIT_BA...        CATALOG   \n",
       "4     LIBNAME WORK V9 '/opt/sas/saswork/SAS_work2019...        LIBNAME   \n",
       "...                                                 ...            ...   \n",
       "3976                                        ELAPSED 8          ELAPSED   \n",
       "3977                                 PROCNAME DATASETS        PROCNAME   \n",
       "3978   proc datasets lib = work nolist noprint memty...           STEP   \n",
       "3979                  JOBENDTIME 27JUL2021:10:36:37.94      JOBENDTIME   \n",
       "3980                                               END             END   \n",
       "\n",
       "      Task ID  \n",
       "0           0  \n",
       "1           0  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  \n",
       "...       ...  \n",
       "3976      163  \n",
       "3977      163  \n",
       "3978      163  \n",
       "3979      164  \n",
       "3980      164  \n",
       "\n",
       "[3981 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def txt_to_df(path):\n",
    "\n",
    "    # 1.1 Read Data\n",
    "    f = open(path, 'r')\n",
    "    content = f.read()\n",
    "    content_list = content.split('/* JOBSPLIT: ')\n",
    "    f.close()\n",
    "    df = pd.DataFrame(content_list, columns=['Text'])\n",
    "\n",
    "    # 1.2. Define Task type\n",
    "    df['Task Type'] = df[\"Text\"].str.split().str[0]\n",
    "\n",
    "    # 1.3 Assign Task ID\n",
    "    df = df.reset_index(drop=True)\n",
    "    task_list = [0] \n",
    "    for index, row in df.iterrows():\n",
    "        if (row['Task Type'] == 'TASKSTARTTIME') | (row['Task Type'] == 'JOBENDTIME'):\n",
    "            task_list.append(task_list[index] +1)\n",
    "        else:\n",
    "            task_list.append(task_list[index])   \n",
    "    df['Task ID'] = task_list[1:]\n",
    "\n",
    "    # 1.4 Remove unessesary text\n",
    "    df['Text'] = df[['Text','Task Type']].apply(lambda x: x[0].replace('\\n\\n','\\n').replace('STEP SOURCE FOLLOWS */\\n','') if x[1]=='STEP' \n",
    "                                                          else x[0].replace('*/\\n',''), axis = 1)\n",
    "\n",
    "    return df\n",
    "\n",
    "df_log = txt_to_df(path)\n",
    "df_log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c4d547",
   "metadata": {},
   "source": [
    "#### 1.2. Extract info about Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32a6868e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task ID</th>\n",
       "      <th>Code</th>\n",
       "      <th>Procedure</th>\n",
       "      <th>Start Time</th>\n",
       "      <th>Elapsed Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>/*--------------------------------------------...</td>\n",
       "      <td>DATASTEP</td>\n",
       "      <td>2021-07-27 10:34:25.720</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>data _null_;\\n set __mtf_pd_pit_version;\\n mt...</td>\n",
       "      <td>DATASTEP</td>\n",
       "      <td>2021-07-27 10:34:25.730</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>proc sql noprint;\\n create table __mtf_pd_pit...</td>\n",
       "      <td>SQL</td>\n",
       "      <td>2021-07-27 10:34:25.740</td>\n",
       "      <td>29.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>proc sql noprint;\\n create table __mtf_pd_pit...</td>\n",
       "      <td>SQL</td>\n",
       "      <td>2021-07-27 10:34:28.680</td>\n",
       "      <td>24.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>proc sql noprint;\\n select count(*) into :__i...</td>\n",
       "      <td>SQL</td>\n",
       "      <td>2021-07-27 10:34:31.170</td>\n",
       "      <td>1.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>159</td>\n",
       "      <td>proc transpose data=WORK.__MTF_PD_PIT_ODR_WID...</td>\n",
       "      <td>TRANSPOSE</td>\n",
       "      <td>2021-07-27 10:36:36.550</td>\n",
       "      <td>6.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>160</td>\n",
       "      <td>proc sql noprint _method;\\n create table work...</td>\n",
       "      <td>SQL</td>\n",
       "      <td>2021-07-27 10:36:37.210</td>\n",
       "      <td>2.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>161</td>\n",
       "      <td>proc datasets lib = work nolist noprint memty...</td>\n",
       "      <td>DATASETS</td>\n",
       "      <td>2021-07-27 10:36:37.420</td>\n",
       "      <td>4.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>162</td>\n",
       "      <td>proc datasets lib = work nolist noprint memty...</td>\n",
       "      <td>DATASETS</td>\n",
       "      <td>2021-07-27 10:36:37.890</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>163</td>\n",
       "      <td>proc datasets lib = work nolist noprint memty...</td>\n",
       "      <td>DATASETS</td>\n",
       "      <td>2021-07-27 10:36:37.930</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Task ID                                               Code  Procedure  \\\n",
       "0          1  /*--------------------------------------------...   DATASTEP   \n",
       "1          2   data _null_;\\n set __mtf_pd_pit_version;\\n mt...   DATASTEP   \n",
       "2          3   proc sql noprint;\\n create table __mtf_pd_pit...        SQL   \n",
       "3          4   proc sql noprint;\\n create table __mtf_pd_pit...        SQL   \n",
       "4          5   proc sql noprint;\\n select count(*) into :__i...        SQL   \n",
       "..       ...                                                ...        ...   \n",
       "158      159   proc transpose data=WORK.__MTF_PD_PIT_ODR_WID...  TRANSPOSE   \n",
       "159      160   proc sql noprint _method;\\n create table work...        SQL   \n",
       "160      161   proc datasets lib = work nolist noprint memty...   DATASETS   \n",
       "161      162   proc datasets lib = work nolist noprint memty...   DATASETS   \n",
       "162      163   proc datasets lib = work nolist noprint memty...   DATASETS   \n",
       "\n",
       "                 Start Time  Elapsed Time  \n",
       "0   2021-07-27 10:34:25.720          0.06  \n",
       "1   2021-07-27 10:34:25.730          0.07  \n",
       "2   2021-07-27 10:34:25.740         29.41  \n",
       "3   2021-07-27 10:34:28.680         24.90  \n",
       "4   2021-07-27 10:34:31.170          1.28  \n",
       "..                      ...           ...  \n",
       "158 2021-07-27 10:36:36.550          6.59  \n",
       "159 2021-07-27 10:36:37.210          2.08  \n",
       "160 2021-07-27 10:36:37.420          4.68  \n",
       "161 2021-07-27 10:36:37.890          0.44  \n",
       "162 2021-07-27 10:36:37.930          0.08  \n",
       "\n",
       "[163 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def df_to_code(df):\n",
    "\n",
    "    #-------------------------------------------\n",
    "    # 2.1 Extract the Code Syntax\n",
    "    df_code = df.loc[(df_log['Task Type'].isin(['STEP']))].copy()\n",
    "    df_code.drop(['Task Type'], inplace=True, axis=1)\n",
    "    df_code = df_code.rename(columns={'Text': 'Code'})\n",
    "    df_code = df_code[['Task ID', 'Code']]\n",
    "\n",
    "    #-------------------------------------------\n",
    "    # 2.2. Prepare info about Start Time\n",
    "    df_taskstarttime = df_log.loc[(df_log['Task Type'].isin(['TASKSTARTTIME']))].copy()\n",
    "    df_taskstarttime['Start Time'] = df_taskstarttime['Text'].str.split().str[1]\n",
    "    df_taskstarttime['Start Time'] = pd.to_datetime(df_taskstarttime['Start Time'], format='%d%b%Y:%H:%M:%S.%f')\n",
    "    df_taskstarttime.drop(['Text', 'Task Type'], inplace=True, axis=1)\n",
    "\n",
    "    #-------------------------------------------\n",
    "    # 2.3. Prepare info about Elapsed Time\n",
    "    df_elapsedtime = df_log.loc[(df_log['Task Type'].isin(['ELAPSED']))].copy()\n",
    "    df_elapsedtime['Elapsed Time'] = df_elapsedtime['Text'].str.split().str[1].astype('int')/100\n",
    "    df_elapsedtime.drop(['Text', 'Task Type'], inplace=True, axis=1)\n",
    "\n",
    "    #-------------------------------------------\n",
    "    # 2.4. Prepare info about Procedure Names\n",
    "    df_procedure = df_log.loc[(df_log['Task Type'].isin(['PROCNAME']))].copy()\n",
    "    df_procedure['Procedure'] = df_procedure['Text'].str.split().str[1]\n",
    "    df_procedure.drop(['Text', 'Task Type'], inplace=True, axis=1)\n",
    "\n",
    "    #-------------------------------------------\n",
    "    # 2.5 Output\n",
    "    df_code = df_code.merge(df_procedure, on=['Task ID'], how = 'outer')\\\n",
    "                     .merge(df_taskstarttime, on=['Task ID'], how = 'outer')\\\n",
    "                     .merge(df_elapsedtime, on=['Task ID'], how = 'outer')\n",
    "    \n",
    "    return df_code\n",
    "\n",
    "df_code = df_to_code(df_log)\n",
    "df_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d1ed38",
   "metadata": {},
   "source": [
    "#### 1.3. Extract Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b3953c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task ID</th>\n",
       "      <th>SubTask ID</th>\n",
       "      <th>Source ID</th>\n",
       "      <th>Target ID</th>\n",
       "      <th>Input Table</th>\n",
       "      <th>Output Table</th>\n",
       "      <th>Start Time</th>\n",
       "      <th>Elapsed Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1:0:No Input:Empty</td>\n",
       "      <td>1:1:WORK.__MTF_PD_PIT_VERSION:DATA</td>\n",
       "      <td>No Input</td>\n",
       "      <td>WORK.__MTF_PD_PIT_VERSION</td>\n",
       "      <td>2021-07-27 10:34:25.720</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1:1:WORK.__MTF_PD_PIT_VERSION:DATA</td>\n",
       "      <td>2:1:No Output:Empty</td>\n",
       "      <td>WORK.__MTF_PD_PIT_VERSION</td>\n",
       "      <td>_null_</td>\n",
       "      <td>2021-07-27 10:34:25.730</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0:0:INPUT.PD_VIEW:DATA</td>\n",
       "      <td>3:1:WORK.__MTF_PD_PIT_DISTINCT_RATING1:DATA</td>\n",
       "      <td>INPUT.PD_VIEW</td>\n",
       "      <td>WORK.__MTF_PD_PIT_DISTINCT_RATING1</td>\n",
       "      <td>2021-07-27 10:34:25.740</td>\n",
       "      <td>2.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0:0:INPUT.PD_VIEW:DATA</td>\n",
       "      <td>3:1:WORK.'SASTMP-000000348':UTILITY</td>\n",
       "      <td>INPUT.PD_VIEW</td>\n",
       "      <td>WORK.'SASTMP-000000348'</td>\n",
       "      <td>2021-07-27 10:34:25.740</td>\n",
       "      <td>2.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0:0:INPUT.PD_RR_RATING:DATA</td>\n",
       "      <td>3:2:WORK.__MTF_PD_PIT_DISTINCT_RATING2:DATA</td>\n",
       "      <td>INPUT.PD_RR_RATING</td>\n",
       "      <td>WORK.__MTF_PD_PIT_DISTINCT_RATING2</td>\n",
       "      <td>2021-07-27 10:34:28.670</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>159:1:WORK.__MTF_PD_PIT_ODR_LONG_DIS:DATA</td>\n",
       "      <td>160:1:WORK.TEST_PD_DIS_IN:DATA</td>\n",
       "      <td>WORK.__MTF_PD_PIT_ODR_LONG_DIS</td>\n",
       "      <td>WORK.TEST_PD_DIS_IN</td>\n",
       "      <td>2021-07-27 10:36:37.210</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>100:1:WORK.__MTF_PD_PIT_MARGINAL_BOTH_PD:DATA</td>\n",
       "      <td>160:1:WORK.TEST_PD_DIS_IN:DATA</td>\n",
       "      <td>WORK.__MTF_PD_PIT_MARGINAL_BOTH_PD</td>\n",
       "      <td>WORK.TEST_PD_DIS_IN</td>\n",
       "      <td>2021-07-27 10:36:37.210</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>161</td>\n",
       "      <td>1</td>\n",
       "      <td>161:0:No Input:Empty</td>\n",
       "      <td>161:1:WORK.'SASTMP-000000636':UTILITY</td>\n",
       "      <td>No Input</td>\n",
       "      <td>WORK.'SASTMP-000000636'</td>\n",
       "      <td>2021-07-27 10:36:37.420</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>162</td>\n",
       "      <td>1</td>\n",
       "      <td>162:0:No Input:Empty</td>\n",
       "      <td>162:1:WORK.'SASTMP-000000638':UTILITY</td>\n",
       "      <td>No Input</td>\n",
       "      <td>WORK.'SASTMP-000000638'</td>\n",
       "      <td>2021-07-27 10:36:37.890</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>163:0:No Input:Empty</td>\n",
       "      <td>163:1:WORK.'SASTMP-000000640':UTILITY</td>\n",
       "      <td>No Input</td>\n",
       "      <td>WORK.'SASTMP-000000640'</td>\n",
       "      <td>2021-07-27 10:36:37.930</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>291 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Task ID  SubTask ID                                      Source ID  \\\n",
       "0          1           1                             1:0:No Input:Empty   \n",
       "1          2           1             1:1:WORK.__MTF_PD_PIT_VERSION:DATA   \n",
       "2          3           1                         0:0:INPUT.PD_VIEW:DATA   \n",
       "3          3           1                         0:0:INPUT.PD_VIEW:DATA   \n",
       "4          3           2                    0:0:INPUT.PD_RR_RATING:DATA   \n",
       "..       ...         ...                                            ...   \n",
       "286      160           1      159:1:WORK.__MTF_PD_PIT_ODR_LONG_DIS:DATA   \n",
       "287      160           1  100:1:WORK.__MTF_PD_PIT_MARGINAL_BOTH_PD:DATA   \n",
       "288      161           1                           161:0:No Input:Empty   \n",
       "289      162           1                           162:0:No Input:Empty   \n",
       "290      163           1                           163:0:No Input:Empty   \n",
       "\n",
       "                                       Target ID  \\\n",
       "0             1:1:WORK.__MTF_PD_PIT_VERSION:DATA   \n",
       "1                            2:1:No Output:Empty   \n",
       "2    3:1:WORK.__MTF_PD_PIT_DISTINCT_RATING1:DATA   \n",
       "3            3:1:WORK.'SASTMP-000000348':UTILITY   \n",
       "4    3:2:WORK.__MTF_PD_PIT_DISTINCT_RATING2:DATA   \n",
       "..                                           ...   \n",
       "286               160:1:WORK.TEST_PD_DIS_IN:DATA   \n",
       "287               160:1:WORK.TEST_PD_DIS_IN:DATA   \n",
       "288        161:1:WORK.'SASTMP-000000636':UTILITY   \n",
       "289        162:1:WORK.'SASTMP-000000638':UTILITY   \n",
       "290        163:1:WORK.'SASTMP-000000640':UTILITY   \n",
       "\n",
       "                            Input Table                        Output Table  \\\n",
       "0                              No Input           WORK.__MTF_PD_PIT_VERSION   \n",
       "1             WORK.__MTF_PD_PIT_VERSION                              _null_   \n",
       "2                         INPUT.PD_VIEW  WORK.__MTF_PD_PIT_DISTINCT_RATING1   \n",
       "3                         INPUT.PD_VIEW             WORK.'SASTMP-000000348'   \n",
       "4                    INPUT.PD_RR_RATING  WORK.__MTF_PD_PIT_DISTINCT_RATING2   \n",
       "..                                  ...                                 ...   \n",
       "286      WORK.__MTF_PD_PIT_ODR_LONG_DIS                 WORK.TEST_PD_DIS_IN   \n",
       "287  WORK.__MTF_PD_PIT_MARGINAL_BOTH_PD                 WORK.TEST_PD_DIS_IN   \n",
       "288                            No Input             WORK.'SASTMP-000000636'   \n",
       "289                            No Input             WORK.'SASTMP-000000638'   \n",
       "290                            No Input             WORK.'SASTMP-000000640'   \n",
       "\n",
       "                 Start Time  Elapsed Time  \n",
       "0   2021-07-27 10:34:25.720          0.01  \n",
       "1   2021-07-27 10:34:25.730          0.01  \n",
       "2   2021-07-27 10:34:25.740          2.93  \n",
       "3   2021-07-27 10:34:25.740          2.93  \n",
       "4   2021-07-27 10:34:28.670          0.00  \n",
       "..                      ...           ...  \n",
       "286 2021-07-27 10:36:37.210          0.21  \n",
       "287 2021-07-27 10:36:37.210          0.21  \n",
       "288 2021-07-27 10:36:37.420          0.47  \n",
       "289 2021-07-27 10:36:37.890          0.04  \n",
       "290 2021-07-27 10:36:37.930          0.01  \n",
       "\n",
       "[291 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def df_to_edges(df):\n",
    "    \n",
    "    #-------------------------------------------\n",
    "    # 3.1 Extract Table info\n",
    "    # 3.1.a Get data\n",
    "    df_tables = df.loc[(df['Task Type'].isin(['DATASET', 'OPENTIME', 'TASKSTARTTIME',  'JOBENDTIME']))].copy()   \n",
    "\n",
    "    # 3.1.b # Extract table name and type\n",
    "    df_tables['Table'] = np.where(df_tables['Task Type'].isin(['DATASET']),\n",
    "                                  df_tables['Text'].str.split().str[3],\n",
    "                                  np.where(df_tables['Task Type'].isin(['OPENTIME']),\n",
    "                                           df_tables['Text'].str.split().str[1],\n",
    "                                           ''))\n",
    "    df_tables['Table type'] = df_tables['Table'].str.split('.').str[-1]                          # Extract table type\n",
    "    df_tables['Table'] = df_tables['Table'].apply(lambda x: '.'.join(x.split('.')[:-1]))         # Extract table name\n",
    "\n",
    "    # 3.1.c Define table type (Input, Output, Update)\n",
    "    df_tables['Dataset type'] = np.where(df_tables['Task Type'].isin(['DATASET']),\n",
    "                                          df_tables['Text'].str.split().str[1],                  # Define Input, Output, Update tables\n",
    "                                          '')\n",
    "    df_tables['Dataset type'] = np.where(df_tables['Task Type'].isin(['OPENTIME']),\n",
    "                                          df_tables['Dataset type'].shift(),                     # Inherit table type\n",
    "                                          df_tables['Dataset type'])\n",
    "\n",
    "    # 3.1.d Add sub-step indicator\n",
    "    df_tables = df_tables.reset_index(drop=True)\n",
    "    df_tables['Lag Task ID'] = df_tables['Task ID'].shift()\n",
    "    df_tables['Lag Dataset type'] = df_tables['Dataset type'].shift()\n",
    "    sub_step_list = [1]\n",
    "    for index, row in df_tables.iterrows():\n",
    "        if (row['Task ID'] != row['Lag Task ID']):\n",
    "            sub_step_list.append(1)                       # Reset sub-step\n",
    "        elif ((row['Lag Dataset type'] == 'OUTPUT') & (row['Dataset type'] == 'INPUT')) | \\\n",
    "             ((row['Lag Dataset type'] == 'OUTPUT') & (row['Dataset type'] == 'UPDATE')) | \\\n",
    "             ((row['Lag Dataset type'] == 'UPDATE') & (row['Dataset type'] == 'INPUT')):\n",
    "            sub_step_list.append(sub_step_list[index] +1) # Increase sub-step\n",
    "        else:\n",
    "            sub_step_list.append(sub_step_list[index])    # Keep sub-step\n",
    "    df_tables['SubTask ID'] = sub_step_list[1:]\n",
    "\n",
    "    # 3.1.e Correct case for updated tables\n",
    "    df_tables['Dataset type'] = df_tables['Dataset type'].replace({'UPDATE': 'UPDATE INPUT'})\n",
    "    df_update = df_tables.loc[df_tables['Dataset type'].isin(['UPDATE INPUT'])].copy()\n",
    "    df_update['Dataset type'] = df_update['Dataset type'].replace({'UPDATE INPUT': 'UPDATE OUTPUT'})\n",
    "    df_tables = df_tables.append(df_update).sort_values(['Task ID', 'SubTask ID', 'Dataset type'])\n",
    "    \n",
    "    # 3.1.f Add node index\n",
    "    node_id_dict = {}\n",
    "    node_id_list = []\n",
    "    for index, row in df_tables.iterrows():\n",
    "        # If update or output:\n",
    "        if (row['Dataset type'] == 'OUTPUT') | (row['Dataset type'] == 'UPDATE OUTPUT') :\n",
    "            # create node ID\n",
    "            node_id = str(row['Task ID']) +':'+ \\\n",
    "                      str(row['SubTask ID']) +':'+ \\\n",
    "                      row['Table'] +':'+ \\\n",
    "                      row['Table type']   \n",
    "            # update column\n",
    "            node_id_list.append(node_id)       \n",
    "            # update dict\n",
    "            node_id_dict[row['Table']] = node_id                                                                    \n",
    "\n",
    "        # If source table:\n",
    "        elif row['Table'] not in node_id_dict:\n",
    "            # create node ID\n",
    "            node_id = '0:0:' + \\\n",
    "                      row['Table']  +':'+ \\\n",
    "                      row['Table type']\n",
    "            # update column\n",
    "            node_id_list.append(node_id)                                                           \n",
    "            # update dict\n",
    "            node_id_dict[row['Table']] = node_id  \n",
    "        # If input:\n",
    "        else: \n",
    "            # use previous node ID \n",
    "            node_id_list.append(node_id_dict[row['Table']])                                                         \n",
    "    df_tables['Node Id'] = node_id_list\n",
    "\n",
    "    # 3.1.g Remove leftover tables\n",
    "    df_tables.drop(['Table type','Lag Task ID','Lag Dataset type'], inplace=True, axis=1)\n",
    "\n",
    "    #-------------------------------------------\n",
    "    # 3.2. Prepare info about Input tables\n",
    "    df_input = df_tables.loc[(df_tables['Task Type'].isin(['DATASET']) ) & \n",
    "                             (df_tables['Dataset type'].isin(['INPUT', 'UPDATE INPUT']))].copy()\n",
    "    df_input = df_input.rename(columns={'Table': 'Input Table',\n",
    "                                        'Node Id': 'Source ID'})\n",
    "    df_input.drop(['Text', 'Dataset type', 'Task Type'], inplace=True, axis=1)\n",
    "\n",
    "    #-------------------------------------------\n",
    "    # 3.3. Prepare info about Output tables\n",
    "    df_output = df_tables.loc[(df_tables['Task Type'].isin(['DATASET']) ) & \n",
    "                              (df_tables['Dataset type'].isin(['OUTPUT', 'UPDATE OUTPUT']))].copy()\n",
    "    df_output = df_output.rename(columns={'Table': 'Output Table',\n",
    "                                          'Node Id': 'Target ID'})\n",
    "    df_output.drop(['Text', 'Dataset type', 'Task Type'], inplace=True, axis=1)\n",
    "\n",
    "    #-------------------------------------------\n",
    "    # 3.4. Prepare info about Time Calculations\n",
    "    # 3.4.a Get Data\n",
    "    df_time = df_tables.loc[df_tables['Task Type'].isin(['OPENTIME', 'TASKSTARTTIME', 'JOBENDTIME'])].copy()\n",
    "\n",
    "    # 3.4.b Add time\n",
    "    df_time['Start Time'] = np.where(df_time['Task Type'].isin(['OPENTIME']),\n",
    "                                     df_time['Text'].str.split().str[2].str.replace('DATE:', ''),\n",
    "                                     df_time['Text'].str.split().str[1].str.replace('DATE:', ''))\n",
    "    df_time['Start Time']  = pd.to_datetime(df_time['Start Time'], format='%d%b%Y:%H:%M:%S.%f')\n",
    "\n",
    "    # 3.4.c Remove columns and rows\n",
    "    df_time.drop(['Table','Text','Task Type','Dataset type','Node Id'], inplace=True, axis=1)\n",
    "    df_time = df_time.drop_duplicates(subset=['Task ID', 'SubTask ID'], keep='first')\n",
    "\n",
    "    # 3.4.d Calculate time for each step\n",
    "    df_time['Elapsed Time'] = (df_time['Start Time'].shift(-1) - df_time['Start Time']).dt.total_seconds()\n",
    "    df_time['Elapsed Time'] = df_time['Elapsed Time'].round(2)\n",
    "\n",
    "    #-------------------------------------------\n",
    "    # 3.5. Output\n",
    "    # 3.5.a Merge the results for input and output tables + Elapsed time\n",
    "    df = df_input.merge(df_output, on=['Task ID', 'SubTask ID'], how = 'outer')\\\n",
    "                 .merge(df_time, on=['Task ID', 'SubTask ID'], how = 'left')\\\n",
    "                 .sort_values(['Task ID', 'SubTask ID'])\\\n",
    "                 .reset_index(drop = True)\n",
    "\n",
    "    # 3.5.b Fill missing for specific cases\n",
    "    df['Input Table'] = df['Input Table'].fillna('No Input')\n",
    "    df['Output Table'] = df['Output Table'].fillna('_null_')\n",
    "\n",
    "    # 3.5.c Correct Start time\n",
    "    df['Start Time'] = df['Start Time'].fillna(df['Start Time'].shift()) \n",
    "    df['Elapsed Time'] = df['Elapsed Time'].fillna(0)\n",
    "\n",
    "    # 3.5.d Correct Target node ID\n",
    "    df['Target ID'] = df['Target ID'].fillna(df['Task ID'].astype('str') +':'+ df['SubTask ID'].astype('str')+ ':No Output:Empty') \n",
    "\n",
    "    # 3.5.e Correct Source node ID\n",
    "    df['Source ID'] = df[['Input Table','Task ID','SubTask ID','Source ID']].apply(lambda x: str(x[1])+':'+str(int(x[2])-1)+':No Input:Empty' if x[0]=='No Input' \n",
    "                                                                                  else x[3], axis = 1)\n",
    "    \n",
    "    # 3.5.f Reorder columns\n",
    "    df = df[['Task ID','SubTask ID', 'Source ID','Target ID', 'Input Table','Output Table', 'Start Time','Elapsed Time']]\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_edges = df_to_edges(df_log)\n",
    "df_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb34879b",
   "metadata": {},
   "source": [
    "## 2. Network plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b18de48",
   "metadata": {},
   "source": [
    "#### 2.1. Create Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d5fec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_edgelist(df_edges,\n",
    "                            'Source ID','Target ID',\n",
    "                            ['Task ID','SubTask ID',\n",
    "                             'Input Table','Output Table',\n",
    "                             'Start Time','Elapsed Time'],\n",
    "                            create_using=nx.DiGraph())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb54f6c",
   "metadata": {},
   "source": [
    "#### 2.2 Define positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15581700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coords(G):\n",
    "    # get a list of all nodes \n",
    "    list_nodes_full = sorted(list(G.nodes))\n",
    "\n",
    "    def setdiff_sorted(list_append, list_result):\n",
    "        ans = np.setdiff1d(list_append, list_result, False).tolist()\n",
    "        list_result.extend(ans)\n",
    "        return ans\n",
    "\n",
    "    # get source nodes \n",
    "    source_nodes = sorted([node for node in G.nodes() if G.in_degree(node) == 0])\n",
    "\n",
    "    list_nodes = []\n",
    "    for i in range(len(source_nodes)):\n",
    "\n",
    "        # Define source node\n",
    "        source = source_nodes[i]\n",
    "\n",
    "        # Get nodes in depth order\n",
    "        list_nodes_depth = list(nx.dfs_preorder_nodes(G, source=source, depth_limit=None))\n",
    "\n",
    "        # Keep nodes not already in list\n",
    "        list_nodes_unique = setdiff_sorted(list_nodes_depth, list_nodes)\n",
    "\n",
    "    # Get missed nodes\n",
    "    list_nodes_miss = setdiff_sorted(list_nodes, list_nodes_full)\n",
    "\n",
    "    # Create df\n",
    "    df_nodes = pd.DataFrame(list_nodes, columns =['Node'])\n",
    "    df_nodes['Task ID'] = df_nodes['Node'].str.split(':').str[0].astype('int')\n",
    "    df_nodes['SubTask ID'] = df_nodes['Node'].str.split(':').str[1].astype('int')\n",
    "\n",
    "    # Assign x\n",
    "    df_nodes['x'] = df_nodes['Task ID']\n",
    "\n",
    "    # Assign y\n",
    "    df_nodes = df_nodes.reset_index(drop=True)\n",
    "    df_nodes['Lag Task ID'] = df_nodes['Task ID'].shift()\n",
    "    df_nodes['Lag SubTask ID'] = df_nodes['SubTask ID'].shift()\n",
    "    x_list = [10] \n",
    "    for index, row in df_nodes.iterrows():\n",
    "        if   ( (row['Task ID']-row['Lag Task ID'])==0  & (row['SubTask ID'] != row['Lag SubTask ID']) ):\n",
    "            x_list.append(x_list[index] + 1)\n",
    "        elif ( (row['Task ID']-row['Lag Task ID'])<= 0 ):\n",
    "            x_list.append(x_list[index] + 1)        \n",
    "        else:\n",
    "            x_list.append(x_list[index]) \n",
    "    df_nodes['y'] = x_list[1:]\n",
    "\n",
    "    # Coords dict\n",
    "    coords = df_nodes[['Node', 'x' , 'y']].set_index('Node').T.to_dict('list')\n",
    "    return coords\n",
    "\n",
    "\n",
    "# Add coords\n",
    "coords = get_coords(G)\n",
    "# Add attributes\n",
    "nx.set_node_attributes(G, coords, 'coords') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ed5aa5",
   "metadata": {},
   "source": [
    "#### 2.3. Create Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ee85ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_trace(G):\n",
    "    #====================================================================================        \n",
    "    # Edge info\n",
    "    edge_x = []\n",
    "    edge_y = []\n",
    "    edge_text = []\n",
    "    edge_x_text = []\n",
    "    edge_y_text = []\n",
    "    edge_color_values = []\n",
    "    for edge in G.edges():\n",
    "        #--------------------------------------------------------------------\n",
    "        # Coords\n",
    "        x0, y0 = G.nodes[edge[0]]['coords']\n",
    "        x1, y1 = G.nodes[edge[1]]['coords']\n",
    "        x_mean = round( (x0+x1)/2, 4)\n",
    "        y_mean = round( (y0+y1)/2, 4)   \n",
    "        edge_x.append([x0, x_mean, x1, None])\n",
    "        edge_y.append([y0, y_mean, y1, None])   \n",
    "        \n",
    "        #--------------------------------------------------------------------\n",
    "        # Hover text\n",
    "        edge_text.append('Task ID: '+str(G.edges[edge[0],edge[1]]['Task ID']) \n",
    "                         +' '+\n",
    "                         'SubTask ID: '+str(G.edges[edge[0],edge[1]]['SubTask ID'])\n",
    "                         +'<br> '+\n",
    "                         'Input: '+str(G.edges[edge[0],edge[1]]['Input Table'])\n",
    "                         +'<br> '+   \n",
    "                         'Output: '+str(G.edges[edge[0],edge[1]]['Output Table'])     \n",
    "                         +'<br> '+                     \n",
    "                         'Elapsed Time: '+str(G.edges[edge[0],edge[1]]['Elapsed Time']) \n",
    "                        )\n",
    "        edge_x_text.append(x_mean)\n",
    "        edge_y_text.append(y_mean) \n",
    "        \n",
    "        #--------------------------------------------------------------------\n",
    "        # Colorbar\n",
    "        edge_color_values.append(G.edges[edge[0],edge[1]]['Elapsed Time'])\n",
    "        \n",
    "    #====================================================================================        \n",
    "    # b) Edges color\n",
    "    minima = min(edge_color_values)\n",
    "    maxima = max(edge_color_values)\n",
    "    norm = matplotlib.colors.Normalize(vmin=minima, vmax=maxima, clip=True)\n",
    "    mapper = cm.ScalarMappable(norm=norm, cmap='RdYlGn_r')\n",
    "    edge_color = []\n",
    "    for v in edge_color_values:\n",
    "        rgba = mapper.to_rgba(v)\n",
    "        edge_color.append( matplotlib.colors.to_hex(rgba, keep_alpha=False))\n",
    "        \n",
    "    #====================================================================================        \n",
    "    # c) Edges lines\n",
    "    edge_trace = []  \n",
    "    for i in range(len(edge_color)):\n",
    "        edge_trace.append(go.Scatter(x=edge_x[i], y=edge_y[i],\n",
    "                                     mode = 'lines', \n",
    "                                     line_shape = 'spline',\n",
    "                                     line = dict(width=1, \n",
    "                                                 dash='dot', \n",
    "                                                 color=edge_color[i]),\n",
    "                                     hoverinfo = 'none',\n",
    "                                     showlegend=False))\n",
    "        \n",
    "    #====================================================================================        \n",
    "    # Text\n",
    "    edge_text_trace = go.Scatter(x=edge_x_text, y=edge_y_text, \n",
    "                                 # Marker\n",
    "                                 mode = 'markers', \n",
    "                                 marker_symbol = 'hexagram',\n",
    "                                 marker=dict(showscale=True, \n",
    "                                             colorscale='RdYlGn', \n",
    "                                             reversescale=True,\n",
    "                                             size = 8, \n",
    "                                             color=edge_color_values,\n",
    "                                             colorbar=dict(thickness=15,\n",
    "                                                           title='Execution time (s)',\n",
    "                                                           xanchor='left',\n",
    "                                                           titleside='right')\n",
    "                                            ),\n",
    "                                 # Text\n",
    "                                 text = edge_text,  \n",
    "                                 textposition = 'top center', \n",
    "                                 hovertemplate = ' %{text}',\n",
    "                                 showlegend=False)\n",
    "    \n",
    "    return edge_trace, edge_text_trace\n",
    "\n",
    "edge_trace, edge_text_trace = get_edge_trace(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3fec2a",
   "metadata": {},
   "source": [
    "#### 2.4 Create Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0dbfa6f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_node_trace(G):\n",
    "    #====================================================================================            \n",
    "    # 1. Node Attributes\n",
    "    node_x = []\n",
    "    node_y = []\n",
    "    node_group = []  \n",
    "    node_label = []\n",
    "    node_color = []\n",
    "    node_shape = []\n",
    "    step_id = []    \n",
    "    for node in G.nodes():  \n",
    "        #--------------------------------------------------------------------\n",
    "        # Node Coords\n",
    "        x, y = G.nodes[node]['coords']\n",
    "        node_x.append(x)\n",
    "        node_y.append(y)        \n",
    "\n",
    "        #--------------------------------------------------------------------\n",
    "        # Node name\n",
    "        table_name = node.split(':')[2]\n",
    "        node_label.append(table_name)\n",
    "        \n",
    "        #--------------------------------------------------------------------\n",
    "        # Step ID\n",
    "        step_id.append(node.split(':')[0])    \n",
    "        \n",
    "        #--------------------------------------------------------------------\n",
    "        # Table Type\n",
    "        table_type = node.split(':')[3]       \n",
    "        \n",
    "        #--------------------------------------------------------------------\n",
    "        # Predesessors\n",
    "        predecessors = [c.split(':')[2] for c in G.predecessors(node)]\n",
    "\n",
    "        \n",
    "        #--------------------------------------------------------------------\n",
    "        # Node shape and color\n",
    "        # a) No Input node\n",
    "        if table_name == 'No Input':\n",
    "            node_group.append('No Input')\n",
    "            node_shape.append('diamond-cross')\n",
    "            node_color.append('grey')\n",
    "        # b) No Output node\n",
    "        elif table_name == 'No Output':\n",
    "            node_group.append('No Output')\n",
    "            node_shape.append('square-cross')\n",
    "            node_color.append('grey') \n",
    "        # c) Temporary tables\n",
    "        elif table_type == 'UTILITY':\n",
    "            node_group.append('Technical Table')            \n",
    "            node_shape.append('star-square-dot')\n",
    "            node_color.append('silver')    \n",
    "        # d) Input node\n",
    "        elif G.in_degree(node) == 0:\n",
    "            node_group.append('Input Table')              \n",
    "            node_shape.append('diamond')\n",
    "            node_color.append('gold')\n",
    "        # e) Output node\n",
    "        elif G.out_degree(node) == 0:\n",
    "            node_group.append('Output Table')                \n",
    "            node_shape.append('square')\n",
    "            node_color.append('cyan') \n",
    "        # f) Updated node            \n",
    "        elif table_name in predecessors:\n",
    "            node_group.append('Updated Table')             \n",
    "            node_shape.append('cross')\n",
    "            node_color.append('orange')\n",
    "        # g) Internal nodes\n",
    "        else:\n",
    "            node_group.append('Internal Table')                   \n",
    "            node_shape.append('circle')\n",
    "            node_color.append('blue')\n",
    "\n",
    "    #====================================================================================        \n",
    "    # 2. Node plot\n",
    "    node_trace = []\n",
    "    for elements in ['No Input', 'No Output', 'Technical Table', 'Input Table', 'Output Table', 'Updated Table', 'Internal Table']:\n",
    "        # Get indices of nodes\n",
    "        indices = [i for i, j in enumerate(node_group) if j == elements]\n",
    "        node_x_group = [node_x[i] for i in indices]\n",
    "        node_y_group = [node_y[i] for i in indices]\n",
    "        node_label_group = [node_label[i] for i in indices]\n",
    "        node_color_group = [node_color[i] for i in indices]\n",
    "        node_shape_group = [node_shape[i] for i in indices]\n",
    "        step_id_group = [step_id[i] for i in indices]\n",
    "        \n",
    "        node_trace.append(go.Scatter(x = node_x_group, \n",
    "                                     y = node_y_group,\n",
    "                                     mode = 'markers',\n",
    "                                     marker=dict(symbol = node_shape_group, \n",
    "                                                 color = node_color_group,\n",
    "                                                 size = 10\n",
    "                                                ),\n",
    "                                     name = elements,\n",
    "                                     marker_line_color='black', \n",
    "                                     marker_line_width=0.5,\n",
    "                                     text = node_label_group,\n",
    "                                     textposition = 'top center',\n",
    "                                     hovertemplate = ' %{text}',\n",
    "                                     meta = step_id_group,\n",
    "                                     showlegend=True)\n",
    "                        ) \n",
    "    return node_trace\n",
    "\n",
    "\n",
    "node_trace = get_node_trace(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7120ea",
   "metadata": {},
   "source": [
    "## 3. Dash plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0826cf28",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:8050/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [10/Aug/2021 19:49:04] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [10/Aug/2021 19:49:04] \"\u001b[37mGET /_dash-dependencies HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [10/Aug/2021 19:49:04] \"\u001b[37mGET /_dash-layout HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [10/Aug/2021 19:49:04] \"\u001b[37mGET /_dash-component-suites/dash_table/async-highlight.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [10/Aug/2021 19:49:04] \"\u001b[37mGET /_dash-component-suites/dash_table/async-table.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [10/Aug/2021 19:49:05] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [10/Aug/2021 19:49:10] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [10/Aug/2021 19:49:13] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [10/Aug/2021 19:49:17] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [10/Aug/2021 19:49:28] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [10/Aug/2021 19:49:45] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Server start\n",
    "app = dash.Dash()\n",
    "\n",
    "# network plot\n",
    "fig_net = go.Figure(edge_trace + node_trace+[edge_text_trace]) \n",
    "fig_net.update_layout(xaxis=dict(showgrid=False, \n",
    "                                 zeroline=False),\n",
    "                      yaxis=dict(showgrid=False, \n",
    "                                 zeroline=False),\n",
    "                     legend=dict(orientation=\"h\",\n",
    "                                 x=1, y=1.02,\n",
    "                                 xanchor=\"right\", yanchor=\"bottom\")\n",
    "                     )\n",
    "\n",
    "# Dash plot\n",
    "app.layout = html.Div([\n",
    "    # Network plot\n",
    "    dcc.Graph(id='basic_graph',\n",
    "              figure=fig_net),\n",
    "    # Table base\n",
    "    html.Div(className='row', \n",
    "             children=[\n",
    "                       # Table\n",
    "                       dash_table.DataTable(id='table',\n",
    "                                            columns=[{\"name\": i, \"id\": i} for i in df_code.columns],\n",
    "                                            data=df_code.to_dict('records'),\n",
    "                                            fixed_rows={'headers': True},\n",
    "                                            style_table={'height': 450,\n",
    "                                                         'overflowY': 'scroll',\n",
    "                                                         'border': 'thin lightgrey solid'},  \n",
    "                                            style_cell={'textAlign': 'left',\n",
    "                                                        'whiteSpace': 'pre-line',\n",
    "                                                        'backgroundColor': 'rgb(153, 204, 255)',\n",
    "                                                        'color': 'black',\n",
    "                                                        'minWidth': '10px', \n",
    "                                                        'maxWidth': '800px'},\n",
    "                                            style_header={'fontWeight': 'bold',\n",
    "                                                          'backgroundColor': 'rgb(0, 0, 153)',\n",
    "                                                          'color': 'white'}\n",
    "                                           )\n",
    "             ])\n",
    "])\n",
    "\n",
    "# https://community.plotly.com/t/update-a-dash-datatable-with-callbacks/21382/3\n",
    "# https://dash.plotly.com/datatable/editable\n",
    "\n",
    "# Add interactive table\n",
    "@app.callback(\n",
    "    Output('table', 'data'),\n",
    "    Input('basic_graph', 'selectedData'))\n",
    "def display_relayout_data(selectedData):\n",
    "    if selectedData is not None:\n",
    "        x_values = []\n",
    "        for elements in selectedData['points']:\n",
    "             if 'meta' in elements:\n",
    "                if elements['meta'] not in x_values:\n",
    "                    x_values.append( int(elements['meta']) )\n",
    "        df = df_code.loc[ df_code['Task ID'].isin(x_values) ]\n",
    "    else:\n",
    "        df = df_code\n",
    "    return df.to_dict('records')\n",
    "\n",
    "app.run_server(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e61990a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
