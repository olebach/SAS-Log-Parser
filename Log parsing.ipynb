{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d22e3be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plots\n",
    "import networkx as nx\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.offline as py\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Dash\n",
    "import dash\n",
    "import dash_table\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f494414b",
   "metadata": {},
   "source": [
    "# 1. Log parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78180b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'Data\\New_PIT2.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1489d9a",
   "metadata": {},
   "source": [
    "#### 1.1 Extract df from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62547408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Task Type</th>\n",
       "      <th>Task ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JOBSTARTTIME 27JUL2021:10:34:25.72</td>\n",
       "      <td>JOBSTARTTIME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TASKSTARTTIME 27JUL2021:10:34:25.72</td>\n",
       "      <td>TASKSTARTTIME</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CATALOG INPUT WORK.SASMAC1.MTF_IFRS9_PD_PIT_BA...</td>\n",
       "      <td>CATALOG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LIBNAME WORK V9 '/opt/sas/saswork/SAS_work2019...</td>\n",
       "      <td>LIBNAME</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3976</th>\n",
       "      <td>ELAPSED 8</td>\n",
       "      <td>ELAPSED</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>PROCNAME DATASETS</td>\n",
       "      <td>PROCNAME</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>proc datasets lib = work nolist noprint memty...</td>\n",
       "      <td>STEP</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>JOBENDTIME 27JUL2021:10:36:37.94</td>\n",
       "      <td>JOBENDTIME</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>END</td>\n",
       "      <td>END</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3981 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text      Task Type  \\\n",
       "0                                                                  NaN   \n",
       "1                   JOBSTARTTIME 27JUL2021:10:34:25.72    JOBSTARTTIME   \n",
       "2                  TASKSTARTTIME 27JUL2021:10:34:25.72   TASKSTARTTIME   \n",
       "3     CATALOG INPUT WORK.SASMAC1.MTF_IFRS9_PD_PIT_BA...        CATALOG   \n",
       "4     LIBNAME WORK V9 '/opt/sas/saswork/SAS_work2019...        LIBNAME   \n",
       "...                                                 ...            ...   \n",
       "3976                                        ELAPSED 8          ELAPSED   \n",
       "3977                                 PROCNAME DATASETS        PROCNAME   \n",
       "3978   proc datasets lib = work nolist noprint memty...           STEP   \n",
       "3979                  JOBENDTIME 27JUL2021:10:36:37.94      JOBENDTIME   \n",
       "3980                                               END             END   \n",
       "\n",
       "      Task ID  \n",
       "0           0  \n",
       "1           0  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  \n",
       "...       ...  \n",
       "3976      163  \n",
       "3977      163  \n",
       "3978      163  \n",
       "3979      164  \n",
       "3980      164  \n",
       "\n",
       "[3981 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def txt_to_df(path):\n",
    "\n",
    "    # 1.1 Read Data\n",
    "    f = open(path, 'r')\n",
    "    content = f.read()\n",
    "    content_list = content.split('/* JOBSPLIT: ')\n",
    "    f.close()\n",
    "    df = pd.DataFrame(content_list, columns=['Text'])\n",
    "\n",
    "    # 1.2. Define Task type\n",
    "    df['Task Type'] = df[\"Text\"].str.split().str[0]\n",
    "\n",
    "    # 1.3 Assign Task ID\n",
    "    df = df.reset_index(drop=True)\n",
    "    task_list = [0] \n",
    "    for index, row in df.iterrows():\n",
    "        if (row['Task Type'] == 'TASKSTARTTIME') | (row['Task Type'] == 'JOBENDTIME'):\n",
    "            task_list.append(task_list[index] +1)\n",
    "        else:\n",
    "            task_list.append(task_list[index])   \n",
    "    df['Task ID'] = task_list[1:]\n",
    "\n",
    "    # 1.4 Remove unessesary text\n",
    "    df['Text'] = df[['Text','Task Type']].apply(lambda x: x[0].replace('\\n\\n','\\n').replace('STEP SOURCE FOLLOWS */\\n','') if x[1]=='STEP' \n",
    "                                                          else x[0].replace('*/\\n',''), axis = 1)\n",
    "\n",
    "    df['Task ID'] = df['Task ID'].astype('int')\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_log = txt_to_df(path)\n",
    "df_log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c4d547",
   "metadata": {},
   "source": [
    "#### 1.2. Extract info about Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32a6868e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task ID</th>\n",
       "      <th>Code</th>\n",
       "      <th>Procedure</th>\n",
       "      <th>Start Time</th>\n",
       "      <th>Elapsed Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>/*--------------------------------------------...</td>\n",
       "      <td>DATASTEP</td>\n",
       "      <td>2021-07-27 10:34:25.720</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>data _null_;\\n set __mtf_pd_pit_version;\\n mt...</td>\n",
       "      <td>DATASTEP</td>\n",
       "      <td>2021-07-27 10:34:25.730</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>proc sql noprint;\\n create table __mtf_pd_pit...</td>\n",
       "      <td>SQL</td>\n",
       "      <td>2021-07-27 10:34:25.740</td>\n",
       "      <td>2.941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>proc sql noprint;\\n create table __mtf_pd_pit...</td>\n",
       "      <td>SQL</td>\n",
       "      <td>2021-07-27 10:34:28.680</td>\n",
       "      <td>2.490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>proc sql noprint;\\n select count(*) into :__i...</td>\n",
       "      <td>SQL</td>\n",
       "      <td>2021-07-27 10:34:31.170</td>\n",
       "      <td>0.128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>159</td>\n",
       "      <td>proc transpose data=WORK.__MTF_PD_PIT_ODR_WID...</td>\n",
       "      <td>TRANSPOSE</td>\n",
       "      <td>2021-07-27 10:36:36.550</td>\n",
       "      <td>0.659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>160</td>\n",
       "      <td>proc sql noprint _method;\\n create table work...</td>\n",
       "      <td>SQL</td>\n",
       "      <td>2021-07-27 10:36:37.210</td>\n",
       "      <td>0.208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>161</td>\n",
       "      <td>proc datasets lib = work nolist noprint memty...</td>\n",
       "      <td>DATASETS</td>\n",
       "      <td>2021-07-27 10:36:37.420</td>\n",
       "      <td>0.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>162</td>\n",
       "      <td>proc datasets lib = work nolist noprint memty...</td>\n",
       "      <td>DATASETS</td>\n",
       "      <td>2021-07-27 10:36:37.890</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>163</td>\n",
       "      <td>proc datasets lib = work nolist noprint memty...</td>\n",
       "      <td>DATASETS</td>\n",
       "      <td>2021-07-27 10:36:37.930</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Task ID                                               Code  Procedure  \\\n",
       "0          1  /*--------------------------------------------...   DATASTEP   \n",
       "1          2   data _null_;\\n set __mtf_pd_pit_version;\\n mt...   DATASTEP   \n",
       "2          3   proc sql noprint;\\n create table __mtf_pd_pit...        SQL   \n",
       "3          4   proc sql noprint;\\n create table __mtf_pd_pit...        SQL   \n",
       "4          5   proc sql noprint;\\n select count(*) into :__i...        SQL   \n",
       "..       ...                                                ...        ...   \n",
       "158      159   proc transpose data=WORK.__MTF_PD_PIT_ODR_WID...  TRANSPOSE   \n",
       "159      160   proc sql noprint _method;\\n create table work...        SQL   \n",
       "160      161   proc datasets lib = work nolist noprint memty...   DATASETS   \n",
       "161      162   proc datasets lib = work nolist noprint memty...   DATASETS   \n",
       "162      163   proc datasets lib = work nolist noprint memty...   DATASETS   \n",
       "\n",
       "                  Start Time  Elapsed Time  \n",
       "0    2021-07-27 10:34:25.720         0.006  \n",
       "1    2021-07-27 10:34:25.730         0.007  \n",
       "2    2021-07-27 10:34:25.740         2.941  \n",
       "3    2021-07-27 10:34:28.680         2.490  \n",
       "4    2021-07-27 10:34:31.170         0.128  \n",
       "..                       ...           ...  \n",
       "158  2021-07-27 10:36:36.550         0.659  \n",
       "159  2021-07-27 10:36:37.210         0.208  \n",
       "160  2021-07-27 10:36:37.420         0.468  \n",
       "161  2021-07-27 10:36:37.890         0.044  \n",
       "162  2021-07-27 10:36:37.930         0.008  \n",
       "\n",
       "[163 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def df_to_code(df):\n",
    "\n",
    "    #-------------------------------------------\n",
    "    # 2.1 Extract the Code Syntax\n",
    "    df_code = df.loc[(df_log['Task Type'].isin(['STEP']))].copy()\n",
    "    df_code.drop(['Task Type'], inplace=True, axis=1)\n",
    "    df_code = df_code.rename(columns={'Text': 'Code'})\n",
    "    df_code = df_code[['Task ID', 'Code']]\n",
    "\n",
    "    #-------------------------------------------\n",
    "    # 2.2. Prepare info about Start Time\n",
    "    df_taskstarttime = df_log.loc[(df_log['Task Type'].isin(['TASKSTARTTIME']))].copy()\n",
    "    df_taskstarttime['Start Time'] = df_taskstarttime['Text'].str.split().str[1]\n",
    "    df_taskstarttime['Start Time'] = pd.to_datetime(df_taskstarttime['Start Time'], format='%d%b%Y:%H:%M:%S.%f')\n",
    "    df_taskstarttime.drop(['Text', 'Task Type'], inplace=True, axis=1)\n",
    "\n",
    "    #-------------------------------------------\n",
    "    # 2.3. Prepare info about Elapsed Time\n",
    "    df_elapsedtime = df_log.loc[(df_log['Task Type'].isin(['ELAPSED']))].copy()\n",
    "    df_elapsedtime['Elapsed Time'] = df_elapsedtime['Text'].str.split().str[1].astype('int')/1000\n",
    "    df_elapsedtime.drop(['Text', 'Task Type'], inplace=True, axis=1)\n",
    "\n",
    "    #-------------------------------------------\n",
    "    # 2.4. Prepare info about Procedure Names\n",
    "    df_procedure = df_log.loc[(df_log['Task Type'].isin(['PROCNAME']))].copy()\n",
    "    df_procedure['Procedure'] = df_procedure['Text'].str.split().str[1]\n",
    "    df_procedure.drop(['Text', 'Task Type'], inplace=True, axis=1)\n",
    "\n",
    "    #-------------------------------------------\n",
    "    # 2.5 Output\n",
    "    df_code = df_code.merge(df_procedure, on=['Task ID'], how = 'outer')\\\n",
    "                     .merge(df_taskstarttime, on=['Task ID'], how = 'outer')\\\n",
    "                     .merge(df_elapsedtime, on=['Task ID'], how = 'outer')\n",
    "    \n",
    "    df_code['Start Time'] = df_code['Start Time'].astype('str')\n",
    "    df_code['Task ID'] = df_code['Task ID'].astype('int')\n",
    "    \n",
    "    return df_code\n",
    "\n",
    "df_code = df_to_code(df_log)\n",
    "df_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d1ed38",
   "metadata": {},
   "source": [
    "#### 1.3. Extract Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b3953c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task ID</th>\n",
       "      <th>SubTask ID</th>\n",
       "      <th>Source ID</th>\n",
       "      <th>Target ID</th>\n",
       "      <th>Input Table</th>\n",
       "      <th>Output Table</th>\n",
       "      <th>Start Time</th>\n",
       "      <th>Elapsed Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1:0:No Input:Empty</td>\n",
       "      <td>1:1:WORK.__MTF_PD_PIT_VERSION:DATA</td>\n",
       "      <td>No Input</td>\n",
       "      <td>WORK.__MTF_PD_PIT_VERSION</td>\n",
       "      <td>2021-07-27 10:34:25.720</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1:1:WORK.__MTF_PD_PIT_VERSION:DATA</td>\n",
       "      <td>2:1:No Output:Empty</td>\n",
       "      <td>WORK.__MTF_PD_PIT_VERSION</td>\n",
       "      <td>_null_</td>\n",
       "      <td>2021-07-27 10:34:25.730</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0:0:INPUT.PD_VIEW:DATA</td>\n",
       "      <td>3:1:WORK.__MTF_PD_PIT_DISTINCT_RATING1:DATA</td>\n",
       "      <td>INPUT.PD_VIEW</td>\n",
       "      <td>WORK.__MTF_PD_PIT_DISTINCT_RATING1</td>\n",
       "      <td>2021-07-27 10:34:25.740</td>\n",
       "      <td>2.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0:0:INPUT.PD_VIEW:DATA</td>\n",
       "      <td>3:1:WORK.'SASTMP-000000348':UTILITY</td>\n",
       "      <td>INPUT.PD_VIEW</td>\n",
       "      <td>WORK.'SASTMP-000000348'</td>\n",
       "      <td>2021-07-27 10:34:25.740</td>\n",
       "      <td>2.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0:0:INPUT.PD_RR_RATING:DATA</td>\n",
       "      <td>3:2:WORK.__MTF_PD_PIT_DISTINCT_RATING2:DATA</td>\n",
       "      <td>INPUT.PD_RR_RATING</td>\n",
       "      <td>WORK.__MTF_PD_PIT_DISTINCT_RATING2</td>\n",
       "      <td>2021-07-27 10:34:28.670</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>159:1:WORK.__MTF_PD_PIT_ODR_LONG_DIS:DATA</td>\n",
       "      <td>160:1:WORK.TEST_PD_DIS_IN:DATA</td>\n",
       "      <td>WORK.__MTF_PD_PIT_ODR_LONG_DIS</td>\n",
       "      <td>WORK.TEST_PD_DIS_IN</td>\n",
       "      <td>2021-07-27 10:36:37.210</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>100:1:WORK.__MTF_PD_PIT_MARGINAL_BOTH_PD:DATA</td>\n",
       "      <td>160:1:WORK.TEST_PD_DIS_IN:DATA</td>\n",
       "      <td>WORK.__MTF_PD_PIT_MARGINAL_BOTH_PD</td>\n",
       "      <td>WORK.TEST_PD_DIS_IN</td>\n",
       "      <td>2021-07-27 10:36:37.210</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>161</td>\n",
       "      <td>1</td>\n",
       "      <td>161:0:No Input:Empty</td>\n",
       "      <td>161:1:WORK.'SASTMP-000000636':UTILITY</td>\n",
       "      <td>No Input</td>\n",
       "      <td>WORK.'SASTMP-000000636'</td>\n",
       "      <td>2021-07-27 10:36:37.420</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>162</td>\n",
       "      <td>1</td>\n",
       "      <td>162:0:No Input:Empty</td>\n",
       "      <td>162:1:WORK.'SASTMP-000000638':UTILITY</td>\n",
       "      <td>No Input</td>\n",
       "      <td>WORK.'SASTMP-000000638'</td>\n",
       "      <td>2021-07-27 10:36:37.890</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>163:0:No Input:Empty</td>\n",
       "      <td>163:1:WORK.'SASTMP-000000640':UTILITY</td>\n",
       "      <td>No Input</td>\n",
       "      <td>WORK.'SASTMP-000000640'</td>\n",
       "      <td>2021-07-27 10:36:37.930</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>291 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Task ID  SubTask ID                                      Source ID  \\\n",
       "0          1           1                             1:0:No Input:Empty   \n",
       "1          2           1             1:1:WORK.__MTF_PD_PIT_VERSION:DATA   \n",
       "2          3           1                         0:0:INPUT.PD_VIEW:DATA   \n",
       "3          3           1                         0:0:INPUT.PD_VIEW:DATA   \n",
       "4          3           2                    0:0:INPUT.PD_RR_RATING:DATA   \n",
       "..       ...         ...                                            ...   \n",
       "286      160           1      159:1:WORK.__MTF_PD_PIT_ODR_LONG_DIS:DATA   \n",
       "287      160           1  100:1:WORK.__MTF_PD_PIT_MARGINAL_BOTH_PD:DATA   \n",
       "288      161           1                           161:0:No Input:Empty   \n",
       "289      162           1                           162:0:No Input:Empty   \n",
       "290      163           1                           163:0:No Input:Empty   \n",
       "\n",
       "                                       Target ID  \\\n",
       "0             1:1:WORK.__MTF_PD_PIT_VERSION:DATA   \n",
       "1                            2:1:No Output:Empty   \n",
       "2    3:1:WORK.__MTF_PD_PIT_DISTINCT_RATING1:DATA   \n",
       "3            3:1:WORK.'SASTMP-000000348':UTILITY   \n",
       "4    3:2:WORK.__MTF_PD_PIT_DISTINCT_RATING2:DATA   \n",
       "..                                           ...   \n",
       "286               160:1:WORK.TEST_PD_DIS_IN:DATA   \n",
       "287               160:1:WORK.TEST_PD_DIS_IN:DATA   \n",
       "288        161:1:WORK.'SASTMP-000000636':UTILITY   \n",
       "289        162:1:WORK.'SASTMP-000000638':UTILITY   \n",
       "290        163:1:WORK.'SASTMP-000000640':UTILITY   \n",
       "\n",
       "                            Input Table                        Output Table  \\\n",
       "0                              No Input           WORK.__MTF_PD_PIT_VERSION   \n",
       "1             WORK.__MTF_PD_PIT_VERSION                              _null_   \n",
       "2                         INPUT.PD_VIEW  WORK.__MTF_PD_PIT_DISTINCT_RATING1   \n",
       "3                         INPUT.PD_VIEW             WORK.'SASTMP-000000348'   \n",
       "4                    INPUT.PD_RR_RATING  WORK.__MTF_PD_PIT_DISTINCT_RATING2   \n",
       "..                                  ...                                 ...   \n",
       "286      WORK.__MTF_PD_PIT_ODR_LONG_DIS                 WORK.TEST_PD_DIS_IN   \n",
       "287  WORK.__MTF_PD_PIT_MARGINAL_BOTH_PD                 WORK.TEST_PD_DIS_IN   \n",
       "288                            No Input             WORK.'SASTMP-000000636'   \n",
       "289                            No Input             WORK.'SASTMP-000000638'   \n",
       "290                            No Input             WORK.'SASTMP-000000640'   \n",
       "\n",
       "                 Start Time  Elapsed Time  \n",
       "0   2021-07-27 10:34:25.720          0.01  \n",
       "1   2021-07-27 10:34:25.730          0.01  \n",
       "2   2021-07-27 10:34:25.740          2.93  \n",
       "3   2021-07-27 10:34:25.740          2.93  \n",
       "4   2021-07-27 10:34:28.670          0.00  \n",
       "..                      ...           ...  \n",
       "286 2021-07-27 10:36:37.210          0.21  \n",
       "287 2021-07-27 10:36:37.210          0.21  \n",
       "288 2021-07-27 10:36:37.420          0.47  \n",
       "289 2021-07-27 10:36:37.890          0.04  \n",
       "290 2021-07-27 10:36:37.930          0.01  \n",
       "\n",
       "[291 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def df_to_edges(df):\n",
    "    \n",
    "    #-------------------------------------------\n",
    "    # 3.1 Extract Table info\n",
    "    # 3.1.a Get data\n",
    "    df_tables = df.loc[(df['Task Type'].isin(['DATASET', 'OPENTIME', 'TASKSTARTTIME',  'JOBENDTIME']))].copy()   \n",
    "\n",
    "    # 3.1.b # Extract table name and type\n",
    "    df_tables['Table'] = np.where(df_tables['Task Type'].isin(['DATASET']),\n",
    "                                  df_tables['Text'].str.split().str[3],\n",
    "                                  np.where(df_tables['Task Type'].isin(['OPENTIME']),\n",
    "                                           df_tables['Text'].str.split().str[1],\n",
    "                                           ''))\n",
    "    df_tables['Table type'] = df_tables['Table'].str.split('.').str[-1]                          # Extract table type\n",
    "    df_tables['Table'] = df_tables['Table'].apply(lambda x: '.'.join(x.split('.')[:-1]))         # Extract table name\n",
    "\n",
    "    # 3.1.c Define table type (Input, Output, Update)\n",
    "    df_tables['Dataset type'] = np.where(df_tables['Task Type'].isin(['DATASET']),\n",
    "                                          df_tables['Text'].str.split().str[1],                  # Define Input, Output, Update tables\n",
    "                                          '')\n",
    "    df_tables['Dataset type'] = np.where(df_tables['Task Type'].isin(['OPENTIME']),\n",
    "                                          df_tables['Dataset type'].shift(),                     # Inherit table type\n",
    "                                          df_tables['Dataset type'])\n",
    "\n",
    "    # 3.1.d Add sub-step indicator\n",
    "    df_tables = df_tables.reset_index(drop=True)\n",
    "    df_tables['Lag Task ID'] = df_tables['Task ID'].shift()\n",
    "    df_tables['Lag Dataset type'] = df_tables['Dataset type'].shift()\n",
    "    sub_step_list = [1]\n",
    "    for index, row in df_tables.iterrows():\n",
    "        if (row['Task ID'] != row['Lag Task ID']):\n",
    "            sub_step_list.append(1)                       # Reset sub-step\n",
    "        elif ((row['Lag Dataset type'] == 'OUTPUT') & (row['Dataset type'] == 'INPUT')) | \\\n",
    "             ((row['Lag Dataset type'] == 'OUTPUT') & (row['Dataset type'] == 'UPDATE')) | \\\n",
    "             ((row['Lag Dataset type'] == 'UPDATE') & (row['Dataset type'] == 'INPUT')):\n",
    "            sub_step_list.append(sub_step_list[index] +1) # Increase sub-step\n",
    "        else:\n",
    "            sub_step_list.append(sub_step_list[index])    # Keep sub-step\n",
    "    df_tables['SubTask ID'] = sub_step_list[1:]\n",
    "\n",
    "    # 3.1.e Correct case for updated tables\n",
    "    df_tables['Dataset type'] = df_tables['Dataset type'].replace({'UPDATE': 'UPDATE INPUT'})\n",
    "    df_update = df_tables.loc[df_tables['Dataset type'].isin(['UPDATE INPUT'])].copy()\n",
    "    df_update['Dataset type'] = df_update['Dataset type'].replace({'UPDATE INPUT': 'UPDATE OUTPUT'})\n",
    "    df_tables = df_tables.append(df_update).sort_values(['Task ID', 'SubTask ID', 'Dataset type'])\n",
    "    \n",
    "    # 3.1.f Add node index\n",
    "    node_id_dict = {}\n",
    "    node_id_list = []\n",
    "    for index, row in df_tables.iterrows():\n",
    "        # If update or output:\n",
    "        if (row['Dataset type'] == 'OUTPUT') | (row['Dataset type'] == 'UPDATE OUTPUT') :\n",
    "            # create node ID\n",
    "            node_id = str(row['Task ID']) +':'+ \\\n",
    "                      str(row['SubTask ID']) +':'+ \\\n",
    "                      row['Table'] +':'+ \\\n",
    "                      row['Table type']   \n",
    "            # update column\n",
    "            node_id_list.append(node_id)       \n",
    "            # update dict\n",
    "            node_id_dict[row['Table']] = node_id                                                                    \n",
    "\n",
    "        # If source table:\n",
    "        elif row['Table'] not in node_id_dict:\n",
    "            # create node ID\n",
    "            node_id = '0:0:' + \\\n",
    "                      row['Table']  +':'+ \\\n",
    "                      row['Table type']\n",
    "            # update column\n",
    "            node_id_list.append(node_id)                                                           \n",
    "            # update dict\n",
    "            node_id_dict[row['Table']] = node_id  \n",
    "        # If input:\n",
    "        else: \n",
    "            # use previous node ID \n",
    "            node_id_list.append(node_id_dict[row['Table']])                                                         \n",
    "    df_tables['Node Id'] = node_id_list\n",
    "\n",
    "    # 3.1.g Remove leftover tables\n",
    "    df_tables.drop(['Table type','Lag Task ID','Lag Dataset type'], inplace=True, axis=1)\n",
    "\n",
    "    #-------------------------------------------\n",
    "    # 3.2. Prepare info about Input tables\n",
    "    df_input = df_tables.loc[(df_tables['Task Type'].isin(['DATASET']) ) & \n",
    "                             (df_tables['Dataset type'].isin(['INPUT', 'UPDATE INPUT']))].copy()\n",
    "    df_input = df_input.rename(columns={'Table': 'Input Table',\n",
    "                                        'Node Id': 'Source ID'})\n",
    "    df_input.drop(['Text', 'Dataset type', 'Task Type'], inplace=True, axis=1)\n",
    "\n",
    "    #-------------------------------------------\n",
    "    # 3.3. Prepare info about Output tables\n",
    "    df_output = df_tables.loc[(df_tables['Task Type'].isin(['DATASET']) ) & \n",
    "                              (df_tables['Dataset type'].isin(['OUTPUT', 'UPDATE OUTPUT']))].copy()\n",
    "    df_output = df_output.rename(columns={'Table': 'Output Table',\n",
    "                                          'Node Id': 'Target ID'})\n",
    "    df_output.drop(['Text', 'Dataset type', 'Task Type'], inplace=True, axis=1)\n",
    "\n",
    "    #-------------------------------------------\n",
    "    # 3.4. Prepare info about Time Calculations\n",
    "    # 3.4.a Get Data\n",
    "    df_time = df_tables.loc[df_tables['Task Type'].isin(['OPENTIME', 'TASKSTARTTIME', 'JOBENDTIME'])].copy()\n",
    "\n",
    "    # 3.4.b Add time\n",
    "    df_time['Start Time'] = np.where(df_time['Task Type'].isin(['OPENTIME']),\n",
    "                                     df_time['Text'].str.split().str[2].str.replace('DATE:', ''),\n",
    "                                     df_time['Text'].str.split().str[1].str.replace('DATE:', ''))\n",
    "    df_time['Start Time']  = pd.to_datetime(df_time['Start Time'], format='%d%b%Y:%H:%M:%S.%f')\n",
    "\n",
    "    # 3.4.c Remove columns and rows\n",
    "    df_time.drop(['Table','Text','Task Type','Dataset type','Node Id'], inplace=True, axis=1)\n",
    "    df_time = df_time.drop_duplicates(subset=['Task ID', 'SubTask ID'], keep='first')\n",
    "\n",
    "    # 3.4.d Calculate time for each step\n",
    "    df_time['Elapsed Time'] = (df_time['Start Time'].shift(-1) - df_time['Start Time']).dt.total_seconds()\n",
    "    df_time['Elapsed Time'] = df_time['Elapsed Time'].round(2)\n",
    "\n",
    "    #-------------------------------------------\n",
    "    # 3.5. Output\n",
    "    # 3.5.a Merge the results for input and output tables + Elapsed time\n",
    "    df = df_input.merge(df_output, on=['Task ID', 'SubTask ID'], how = 'outer')\\\n",
    "                 .merge(df_time, on=['Task ID', 'SubTask ID'], how = 'left')\\\n",
    "                 .sort_values(['Task ID', 'SubTask ID'])\\\n",
    "                 .reset_index(drop = True)\n",
    "\n",
    "    # 3.5.b Fill missing for specific cases\n",
    "    df['Input Table'] = df['Input Table'].fillna('No Input')\n",
    "    df['Output Table'] = df['Output Table'].fillna('_null_')\n",
    "\n",
    "    # 3.5.c Correct Start time\n",
    "    df['Start Time'] = df['Start Time'].fillna(df['Start Time'].shift()) \n",
    "    df['Elapsed Time'] = df['Elapsed Time'].fillna(0)\n",
    "\n",
    "    # 3.5.d Correct Target node ID\n",
    "    df['Target ID'] = df['Target ID'].fillna(df['Task ID'].astype('str') +':'+ df['SubTask ID'].astype('str')+ ':No Output:Empty') \n",
    "\n",
    "    # 3.5.e Correct Source node ID\n",
    "    df['Source ID'] = df[['Input Table','Task ID','SubTask ID','Source ID']].apply(lambda x: str(x[1])+':'+str(int(x[2])-1)+':No Input:Empty' if x[0]=='No Input' \n",
    "                                                                                  else x[3], axis = 1)\n",
    "    \n",
    "    # 3.5.f Reorder columns\n",
    "    df = df[['Task ID','SubTask ID', 'Source ID','Target ID', 'Input Table','Output Table', 'Start Time','Elapsed Time']]\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_edges = df_to_edges(df_log)\n",
    "df_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb34879b",
   "metadata": {},
   "source": [
    "## 2. Graph data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18fa588f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for defining positions of tables\n",
    "#====================================================================================  \n",
    "\n",
    "def get_coords(G):\n",
    "    \n",
    "    #--------------------------------------------------------------------\n",
    "    # get source nodes \n",
    "    source_nodes = sorted([node for node in G.nodes() if G.in_degree(node) == 0])\n",
    "    \n",
    "    #--------------------------------------------------------------------\n",
    "    # Get nodes in traversal order\n",
    "    list_nodes = []\n",
    "    for i in range(len(source_nodes)):\n",
    "        # Define source node\n",
    "        source = source_nodes[i]\n",
    "        # Get nodes in depth order\n",
    "        list_nodes_depth = list(nx.dfs_preorder_nodes(G, source=source, depth_limit=None))\n",
    "        # Extend main list\n",
    "        list_nodes.extend(list_nodes_depth)\n",
    "        \n",
    "    #--------------------------------------------------------------------\n",
    "    # Add elements if missed\n",
    "    list_nodes_full = sorted(list(G.nodes))\n",
    "    list_nodes.extend(list_nodes_full)\n",
    "\n",
    "    #--------------------------------------------------------------------\n",
    "    # Create df\n",
    "    df_nodes = pd.DataFrame(list_nodes, columns =['Node'])\n",
    "    df_nodes['Task ID'] = df_nodes['Node'].str.split(':').str[0].astype('float')\n",
    "    df_nodes['SubTask ID'] = df_nodes['Node'].str.split(':').str[1].astype('float')\n",
    "    df_nodes = df_nodes.drop_duplicates(subset=['Node'], keep='first')\n",
    "    \n",
    "    #--------------------------------------------------------------------\n",
    "    # Assign y\n",
    "    df_nodes = df_nodes.reset_index(drop=True)\n",
    "    df_nodes['Lag Node'] = df_nodes['Node'].shift()\n",
    "    df_nodes['Lag Task ID'] = df_nodes['Task ID'].shift()\n",
    "    df_nodes['Lag SubTask ID'] = df_nodes['SubTask ID'].shift()\n",
    "    y_list = [0] \n",
    "    for index, row in df_nodes.iterrows():\n",
    "        # Get predecessors\n",
    "        predecessors = [c for c in G.predecessors( row['Node'] )]\n",
    "        if (row['Lag Node'] in predecessors):\n",
    "            if (row['Task ID'] == row['Lag Task ID'])  & (row['SubTask ID'] == row['Lag SubTask ID']):\n",
    "                y_list.append(y_list[index] + 1)\n",
    "            else: \n",
    "                y_list.append(y_list[index])\n",
    "        else:\n",
    "            y_list.append(y_list[index] + 1)\n",
    "    df_nodes['y'] = y_list[1:]\n",
    "    \n",
    "    #--------------------------------------------------------------------\n",
    "    # Reorder nodes\n",
    "    df_nodes = df_nodes.sort_values(by=['Task ID','SubTask ID'])\n",
    "\n",
    "    #--------------------------------------------------------------------\n",
    "    # Assign x\n",
    "    df_nodes = df_nodes.reset_index(drop=True)\n",
    "    df_nodes['Lag Task ID'] = df_nodes['Task ID'].shift()\n",
    "    df_nodes['Lag SubTask ID'] = df_nodes['SubTask ID'].shift()\n",
    "    x_list = [-2] \n",
    "    for index, row in df_nodes.iterrows():\n",
    "        # Move from task to task\n",
    "        if (row['Task ID'] != row ['Lag Task ID']):\n",
    "            x_list.append(x_list[index] + 2)\n",
    "        # Move from subtask to subtask        \n",
    "        elif (row['Task ID'] == row ['Lag Task ID']) & (row['SubTask ID'] != row ['Lag SubTask ID']):\n",
    "            x_list.append(x_list[index] + 1)  \n",
    "        else:\n",
    "            x_list.append(x_list[index])\n",
    "    df_nodes['x'] = x_list[1:]\n",
    "\n",
    "    #--------------------------------------------------------------------\n",
    "    # Coords dict\n",
    "    coords = df_nodes[['Node', 'x' , 'y']].set_index('Node').T.to_dict('list')\n",
    "    \n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c19a2cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for extracting data on connections\n",
    "#====================================================================================  \n",
    "\n",
    "def get_edge_df(G):\n",
    "    \n",
    "    edge_dict = {'x0':[],\n",
    "                 'y0':[],\n",
    "                 'x1':[],\n",
    "                 'y1':[],\n",
    "                 'x_mean':[],\n",
    "                 'y_mean':[],\n",
    "                 'step_id':[],\n",
    "                 'color_values':[],\n",
    "                 'text_labels':[]}\n",
    "\n",
    "    for edge in G.edges():\n",
    "        #--------------------------------------------------------------------\n",
    "        # Get Coords\n",
    "        x0, y0 = G.nodes[edge[0]]['coords']\n",
    "        x1, y1 = G.nodes[edge[1]]['coords']\n",
    "        x_mean = round( (x0+x1)/2, 4)\n",
    "        y_mean = round( (y0+y1)/2, 4)   \n",
    "\n",
    "        #--------------------------------------------------------------------\n",
    "        # Shift central points        \n",
    "        shift = (( (x1-x0)**2 + (y1-y0)**2 )**0.5) * 0.05    \n",
    "        # If Horizontal line\n",
    "        if x0 == x1:\n",
    "            x_mean = x_mean + shift\n",
    "        # If Vertical line            \n",
    "        elif y0 == y1:\n",
    "            y_mean = y_mean - shift\n",
    "\n",
    "        #--------------------------------------------------------------------\n",
    "        # Colorbar values\n",
    "        color_value = G.edges[edge[0],edge[1]]['Elapsed Time'] \n",
    "\n",
    "        #--------------------------------------------------------------------\n",
    "        # Hover text\n",
    "        text_label = 'Task ID: '+str(G.edges[edge[0],edge[1]]['Task ID'])\\\n",
    "                        +' '+\\\n",
    "                        'SubTask ID: '+str(G.edges[edge[0],edge[1]]['SubTask ID'])\\\n",
    "                        +'<br> '+\\\n",
    "                        'Input: '+str(G.edges[edge[0],edge[1]]['Input Table'])\\\n",
    "                        +'<br> '+\\\n",
    "                        'Output: '+str(G.edges[edge[0],edge[1]]['Output Table'])\\\n",
    "                        +'<br> '+\\\n",
    "                        'Elapsed Time: '+str(G.edges[edge[0],edge[1]]['Elapsed Time'])\n",
    "\n",
    "        #--------------------------------------------------------------------\n",
    "        # output\n",
    "        edge_dict['x0'].append(x0)\n",
    "        edge_dict['y0'].append(y0)    \n",
    "        edge_dict['x1'].append(x1)\n",
    "        edge_dict['y1'].append(y1)  \n",
    "        edge_dict['x_mean'].append(x_mean)\n",
    "        edge_dict['y_mean'].append(y_mean)  \n",
    "        edge_dict['step_id'].append(G.edges[edge[0],edge[1]]['Task ID']) \n",
    "        edge_dict['color_values'].append(color_value)   \n",
    "        edge_dict['text_labels'].append(text_label) \n",
    "\n",
    "    edge_df = pd.DataFrame(edge_dict)\n",
    "\n",
    "    #====================================================================================        \n",
    "    # Get color codes\n",
    "    norm = matplotlib.colors.Normalize(vmin=min(edge_df['color_values']), \n",
    "                                       vmax=max(edge_df['color_values']), \n",
    "                                       clip=True)\n",
    "    mapper = cm.ScalarMappable(norm=norm, cmap='RdYlGn_r')\n",
    "    edge_df['hex'] = edge_df['color_values'].apply(lambda x: matplotlib.colors.to_hex(mapper.to_rgba(x), keep_alpha=False))\n",
    "    \n",
    "    return edge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adfc2e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for extracting data on connections\n",
    "#====================================================================================  \n",
    "\n",
    "def get_node_df(G):  \n",
    "\n",
    "    node_dict = {'x':[],\n",
    "                 'y':[],\n",
    "                 'label':[],\n",
    "                 'step_id':[],\n",
    "                 'group':[],\n",
    "                 'color':[],\n",
    "                 'shape':[]}\n",
    "    \n",
    "    for node in G.nodes():  \n",
    "        #--------------------------------------------------------------------\n",
    "        # Node Coords\n",
    "        x, y = G.nodes[node]['coords']\n",
    "        node_dict['x'].append(x)\n",
    "        node_dict['y'].append(y)   \n",
    "\n",
    "        #--------------------------------------------------------------------\n",
    "        # Node name\n",
    "        table_name = node.split(':')[2]\n",
    "        node_dict['label'].append(table_name)  \n",
    "        \n",
    "        #--------------------------------------------------------------------\n",
    "        # Step ID\n",
    "        node_dict['step_id'].append(node.split(':')[0])  \n",
    "        \n",
    "        #--------------------------------------------------------------------\n",
    "        # Table Type\n",
    "        table_type = node.split(':')[3]       \n",
    "        \n",
    "        #--------------------------------------------------------------------\n",
    "        # Predesessors\n",
    "        predecessors = [c.split(':')[2] for c in G.predecessors(node)]\n",
    "\n",
    "        #--------------------------------------------------------------------\n",
    "        # Node shape and color\n",
    "        # a) No Input node\n",
    "        if table_name == 'No Input':\n",
    "            node_dict['group'].append('No Input')  \n",
    "            node_dict['shape'].append('diamond-cross')  \n",
    "            node_dict['color'].append('grey')  \n",
    "        # b) No Output node\n",
    "        elif table_name == 'No Output':\n",
    "            node_dict['group'].append('No Output')  \n",
    "            node_dict['shape'].append('square-cross')  \n",
    "            node_dict['color'].append('grey')\n",
    "        # c) Temporary tables\n",
    "        elif table_type == 'UTILITY':\n",
    "            node_dict['group'].append('Technical Table')  \n",
    "            node_dict['shape'].append('star-square-dot')  \n",
    "            node_dict['color'].append('silver')\n",
    "        # d) Input node\n",
    "        elif G.in_degree(node) == 0:\n",
    "            node_dict['group'].append('Input Table')  \n",
    "            node_dict['shape'].append('diamond')  \n",
    "            node_dict['color'].append('gold')\n",
    "        # e) Output node\n",
    "        elif G.out_degree(node) == 0:\n",
    "            node_dict['group'].append('Output Table')  \n",
    "            node_dict['shape'].append('square')  \n",
    "            node_dict['color'].append('cyan')\n",
    "        # f) Updated node            \n",
    "        elif table_name in predecessors:\n",
    "            node_dict['group'].append('Updated Table')  \n",
    "            node_dict['shape'].append('cross')  \n",
    "            node_dict['color'].append('orange')\n",
    "        # g) Internal nodes\n",
    "        else:\n",
    "            node_dict['group'].append('Internal Table')  \n",
    "            node_dict['shape'].append('circle')  \n",
    "            node_dict['color'].append('blue')\n",
    "\n",
    "    node_df = pd.DataFrame(node_dict)\n",
    "    node_df['step_id'] = node_df['step_id'].astype('int')\n",
    "    \n",
    "    return node_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "def10b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiGraph with 241 nodes and 291 edges\n"
     ]
    }
   ],
   "source": [
    "def get_graph_data(df):\n",
    "\n",
    "    # Create graph\n",
    "    G = nx.from_pandas_edgelist(df,\n",
    "                                'Source ID','Target ID',\n",
    "                                ['Task ID','SubTask ID','Input Table','Output Table','Start Time','Elapsed Time'],\n",
    "                                create_using=nx.DiGraph())\n",
    "    print(nx.info(G))\n",
    "\n",
    "    # Define positions of tables\n",
    "    coords = get_coords(G)\n",
    "    # Add positions to the graph\n",
    "    nx.set_node_attributes(G, coords, 'coords') \n",
    "\n",
    "    # Create table for connections and label text\n",
    "    edge_df = get_edge_df(G)\n",
    "\n",
    "    # Create table for nodes\n",
    "    node_df = get_node_df(G)\n",
    "\n",
    "    return node_df, edge_df\n",
    "\n",
    "node_df, edge_df = get_graph_data(df_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "419e7cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241\n",
      "291\n"
     ]
    }
   ],
   "source": [
    "print(len(node_df))\n",
    "print(len(edge_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4a7b359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>y0</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x_mean</th>\n",
       "      <th>y_mean</th>\n",
       "      <th>step_id</th>\n",
       "      <th>color_values</th>\n",
       "      <th>text_labels</th>\n",
       "      <th>hex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>78</td>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>2.5</td>\n",
       "      <td>77.95</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>Task ID: 1 SubTask ID: 1&lt;br&gt; Input: No Input&lt;b...</td>\n",
       "      <td>#006837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "      <td>4.0</td>\n",
       "      <td>77.90</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>Task ID: 2 SubTask ID: 1&lt;br&gt; Input: WORK.__MTF...</td>\n",
       "      <td>#006837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>3.5</td>\n",
       "      <td>29.65</td>\n",
       "      <td>3</td>\n",
       "      <td>2.93</td>\n",
       "      <td>Task ID: 3 SubTask ID: 1&lt;br&gt; Input: INPUT.PD_V...</td>\n",
       "      <td>#249d53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>3.5</td>\n",
       "      <td>30.50</td>\n",
       "      <td>3</td>\n",
       "      <td>2.93</td>\n",
       "      <td>Task ID: 3 SubTask ID: 1&lt;br&gt; Input: INPUT.PD_V...</td>\n",
       "      <td>#249d53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>32</td>\n",
       "      <td>5.5</td>\n",
       "      <td>31.00</td>\n",
       "      <td>4</td>\n",
       "      <td>2.46</td>\n",
       "      <td>Task ID: 4 SubTask ID: 1&lt;br&gt; Input: INPUT.PD_V...</td>\n",
       "      <td>#18954f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>353</td>\n",
       "      <td>41</td>\n",
       "      <td>355</td>\n",
       "      <td>41</td>\n",
       "      <td>354.0</td>\n",
       "      <td>40.90</td>\n",
       "      <td>159</td>\n",
       "      <td>0.32</td>\n",
       "      <td>Task ID: 159 SubTask ID: 1&lt;br&gt; Input: WORK.__M...</td>\n",
       "      <td>#036e3a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>355</td>\n",
       "      <td>41</td>\n",
       "      <td>358</td>\n",
       "      <td>17</td>\n",
       "      <td>356.5</td>\n",
       "      <td>29.00</td>\n",
       "      <td>160</td>\n",
       "      <td>0.21</td>\n",
       "      <td>Task ID: 160 SubTask ID: 1&lt;br&gt; Input: WORK.__M...</td>\n",
       "      <td>#026c39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>360</td>\n",
       "      <td>75</td>\n",
       "      <td>361</td>\n",
       "      <td>75</td>\n",
       "      <td>360.5</td>\n",
       "      <td>74.95</td>\n",
       "      <td>161</td>\n",
       "      <td>0.47</td>\n",
       "      <td>Task ID: 161 SubTask ID: 1&lt;br&gt; Input: No Input...</td>\n",
       "      <td>#04703b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>363</td>\n",
       "      <td>76</td>\n",
       "      <td>364</td>\n",
       "      <td>76</td>\n",
       "      <td>363.5</td>\n",
       "      <td>75.95</td>\n",
       "      <td>162</td>\n",
       "      <td>0.04</td>\n",
       "      <td>Task ID: 162 SubTask ID: 1&lt;br&gt; Input: No Input...</td>\n",
       "      <td>#006837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>366</td>\n",
       "      <td>77</td>\n",
       "      <td>367</td>\n",
       "      <td>77</td>\n",
       "      <td>366.5</td>\n",
       "      <td>76.95</td>\n",
       "      <td>163</td>\n",
       "      <td>0.01</td>\n",
       "      <td>Task ID: 163 SubTask ID: 1&lt;br&gt; Input: No Input...</td>\n",
       "      <td>#006837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>291 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      x0  y0   x1  y1  x_mean  y_mean  step_id  color_values  \\\n",
       "0      2  78    3  78     2.5   77.95        1          0.01   \n",
       "1      3  78    5  78     4.0   77.90        2          0.01   \n",
       "2      0  30    7  30     3.5   29.65        3          2.93   \n",
       "3      0  30    7  31     3.5   30.50        3          2.93   \n",
       "4      0  30   11  32     5.5   31.00        4          2.46   \n",
       "..   ...  ..  ...  ..     ...     ...      ...           ...   \n",
       "286  353  41  355  41   354.0   40.90      159          0.32   \n",
       "287  355  41  358  17   356.5   29.00      160          0.21   \n",
       "288  360  75  361  75   360.5   74.95      161          0.47   \n",
       "289  363  76  364  76   363.5   75.95      162          0.04   \n",
       "290  366  77  367  77   366.5   76.95      163          0.01   \n",
       "\n",
       "                                           text_labels      hex  \n",
       "0    Task ID: 1 SubTask ID: 1<br> Input: No Input<b...  #006837  \n",
       "1    Task ID: 2 SubTask ID: 1<br> Input: WORK.__MTF...  #006837  \n",
       "2    Task ID: 3 SubTask ID: 1<br> Input: INPUT.PD_V...  #249d53  \n",
       "3    Task ID: 3 SubTask ID: 1<br> Input: INPUT.PD_V...  #249d53  \n",
       "4    Task ID: 4 SubTask ID: 1<br> Input: INPUT.PD_V...  #18954f  \n",
       "..                                                 ...      ...  \n",
       "286  Task ID: 159 SubTask ID: 1<br> Input: WORK.__M...  #036e3a  \n",
       "287  Task ID: 160 SubTask ID: 1<br> Input: WORK.__M...  #026c39  \n",
       "288  Task ID: 161 SubTask ID: 1<br> Input: No Input...  #04703b  \n",
       "289  Task ID: 162 SubTask ID: 1<br> Input: No Input...  #006837  \n",
       "290  Task ID: 163 SubTask ID: 1<br> Input: No Input...  #006837  \n",
       "\n",
       "[291 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49dc9ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = edge_df.merge(node_df, on=['step_id'], how = 'outer')\n",
    "df_test.to_csv('test.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7120ea",
   "metadata": {},
   "source": [
    "## 3. Dash plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ff134f",
   "metadata": {},
   "source": [
    "### 1. Node Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f822a39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_trace(df):\n",
    "    \n",
    "    node_trace = []\n",
    "    for index, row in df.iterrows():\n",
    "        \n",
    "        node_trace.append(go.Scatter(x = [row['x']], \n",
    "                                     y = [row['y']],\n",
    "                                     mode = 'markers',\n",
    "                                     # Marker\n",
    "                                     marker=dict(symbol = row['shape'], \n",
    "                                                 color = row['color'],\n",
    "                                                 size = 10),\n",
    "                                     name = row['group'],\n",
    "                                     marker_line_color='black', \n",
    "                                     marker_line_width=0.5,\n",
    "                                     # Text\n",
    "                                     text = str(row['label']),\n",
    "                                     textposition = 'top center',\n",
    "                                     # Legend\n",
    "                                     showlegend=True,\n",
    "                                     # Meta\n",
    "                                     meta = row['step_id']\n",
    "                                    )\n",
    "                        ) \n",
    "    return node_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a10734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# network plot\n",
    "node_trace = get_node_trace(node_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd01c94",
   "metadata": {},
   "source": [
    "### 2. Edge Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6a233e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_trace(df):\n",
    "    \n",
    "    edge_trace = []\n",
    "    for index, row in df.iterrows():\n",
    "        edge_trace.append(go.Scatter(x = [row['x0'], row['x_mean'], row['x1'], None],\n",
    "                                     y = [row['y0'], row['y_mean'], row['y1'], None],\n",
    "                                     mode = 'lines', \n",
    "                                     # line\n",
    "                                     line_shape = 'spline',\n",
    "                                     line = dict(width=1, \n",
    "                                                 dash='dot', \n",
    "                                                 color=row['hex']),\n",
    "                                     # Text\n",
    "                                     hoverinfo = 'none',\n",
    "                                     # Legend\n",
    "                                     showlegend=False,\n",
    "                                     # Meta\n",
    "                                     meta = row['step_id']\n",
    "                                    )\n",
    "                         )\n",
    "        \n",
    "    return edge_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225a1191",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_trace = get_edge_trace(edge_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea193db9",
   "metadata": {},
   "source": [
    "### 3. Text trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114ab78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_trace(df):\n",
    "    \n",
    "    text_trace = go.Scatter(x=df['x_mean'], \n",
    "                            y=df['y_mean'], \n",
    "                            # Marker\n",
    "                            mode = 'markers', \n",
    "                            marker_symbol = 'hexagram',\n",
    "                            marker=dict(showscale=True, \n",
    "                                        colorscale='RdYlGn', \n",
    "                                        reversescale=True,\n",
    "                                        size = 8, \n",
    "                                        color=df['color_values'],\n",
    "                                        colorbar=dict(thickness=15,\n",
    "                                                      title='Execution time (s)',\n",
    "                                                      xanchor='left',\n",
    "                                                      titleside='right')\n",
    "                                       ),\n",
    "                            # Text\n",
    "                            text = df['text_labels'],  \n",
    "                            textposition = 'top center',\n",
    "                            # Legend\n",
    "                            showlegend=False,\n",
    "                            # Meta\n",
    "                            meta = df['step_id']                           \n",
    "                           )\n",
    "    \n",
    "    return text_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f07309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_trace = get_text_trace(edge_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b424f802",
   "metadata": {},
   "source": [
    "### 4. Table filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f2ec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operator dict\n",
    "operators = [['ge ', '>='],\n",
    "             ['le ', '<='],\n",
    "             ['lt ', '<'],\n",
    "             ['gt ', '>'],\n",
    "             ['ne ', '!='],\n",
    "             ['eq ', '='],\n",
    "             ['contains '],\n",
    "             ['datestartswith ']]\n",
    "\n",
    "#======================================================================\n",
    "# Filter query syntax split\n",
    "def split_filter_part(filter_part):\n",
    "    for operator_type in operators:\n",
    "        for operator in operator_type:\n",
    "            if operator in filter_part:\n",
    "                name_part, value_part = filter_part.split(operator, 1)\n",
    "                name = name_part[name_part.find('{') + 1: name_part.rfind('}')]\n",
    "\n",
    "                value_part = value_part.strip()\n",
    "                v0 = value_part[0]\n",
    "                if (v0 == value_part[-1] and v0 in (\"'\", '\"', '`')):\n",
    "                    value = value_part[1: -1].replace('\\\\' + v0, v0)\n",
    "                else:\n",
    "                    try:\n",
    "                        value = float(value_part)\n",
    "                    except ValueError:\n",
    "                        value = value_part\n",
    "\n",
    "                # word operators need spaces after them in the filter string,\n",
    "                # but we don't want these later\n",
    "                return name, operator_type[0].strip(), value\n",
    "\n",
    "    return [None] * 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304b1ccc",
   "metadata": {},
   "source": [
    "### 5. Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86494088",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_net = go.Figure(edge_trace + node_trace + [text_trace])\n",
    "for elements in fig_net:\n",
    "    print(fig_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01b3082",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Server start\n",
    "app = dash.Dash()\n",
    "\n",
    "fig_net = go.Figure(edge_trace + node_trace + [text_trace]) \n",
    "fig_net.update_layout(xaxis=dict(showgrid=False, \n",
    "                                 zeroline=False),\n",
    "                      yaxis=dict(showgrid=False, \n",
    "                                 zeroline=False,\n",
    "                                 autorange='reversed'),\n",
    "                      legend=dict(orientation='h',\n",
    "                                  x=1, y=1.02,\n",
    "                                  xanchor='right', yanchor='bottom'),\n",
    "                      height=450)\n",
    "\n",
    "#======================================================================\n",
    "# Supress duplicate legend entries\n",
    "names_legend = set()\n",
    "fig_net.for_each_trace(lambda trace: trace.update(showlegend=False)\n",
    "                       if (trace.name in names_legend) else names_legend.add(trace.name))\n",
    "\n",
    "#======================================================================\n",
    "# Dash plot\n",
    "app.layout = html.Div([\n",
    "    # Network plot\n",
    "    dcc.Graph(id='graph',\n",
    "              figure=fig_net),\n",
    "    # Table base\n",
    "    html.Div(className='row', \n",
    "             children=[\n",
    "                       # Table\n",
    "                       dash_table.DataTable(id='table',\n",
    "                                            columns=[{'name': i, 'id': i} for i in df_code.columns],\n",
    "                                            data=df_code.to_dict('records'),\n",
    "                                            # Filtering\n",
    "                                            filter_action='native',\n",
    "                                            # Sorting\n",
    "                                            sort_action='native',\n",
    "                                            sort_mode='multi',\n",
    "                                            # Table size\n",
    "                                            fixed_rows={\n",
    "                                                'headers': True},\n",
    "                                            style_table={\n",
    "                                                'height': 450,\n",
    "                                                'overflowY': 'scroll',\n",
    "                                                'border': 'thin lightgrey solid'}, \n",
    "                                            # Column size\n",
    "                                            style_cell_conditional=[\n",
    "                                                {'if': {'column_id': 'Task ID'},\n",
    "                                                 'width': '5%'},\n",
    "                                                {'if': {'column_id': 'Code'},\n",
    "                                                 'width': '75%'},\n",
    "                                                {'if': {'column_id': 'Procedure'},\n",
    "                                                 'width': '5%'},\n",
    "                                                {'if': {'column_id': 'Start Time'},\n",
    "                                                 'width': '10%'},\n",
    "                                                {'if': {'column_id': 'Elapsed Time'},\n",
    "                                                 'width': '5%'}],\n",
    "                                            # Cell colors\n",
    "                                            style_header={\n",
    "                                                'fontWeight': 'bold',\n",
    "                                                'backgroundColor': 'rgb(48, 84, 150)',\n",
    "                                                'color': 'white'},\n",
    "                                            style_filter={\n",
    "                                                'backgroundColor': 'rgb(142, 169, 219)',\n",
    "                                                'color': 'white'},\n",
    "                                            style_cell={\n",
    "                                                'textAlign': 'left',\n",
    "                                                'whiteSpace': 'pre-line',\n",
    "                                                'height': 'auto',\n",
    "                                                'backgroundColor': 'rgb(217, 225, 242)',\n",
    "                                                'color': 'black',\n",
    "                                                'minWidth': '10px', \n",
    "                                                'maxWidth': '800px'}\n",
    "                                           )\n",
    "             ])\n",
    "])\n",
    "\n",
    "#======================================================================\n",
    "# Add Scatter -> Table interactions\n",
    "@app.callback(\n",
    "    Output('table', 'data'),\n",
    "    Input('graph', 'selectedData'))\n",
    "def update_table(selectedData):\n",
    "    if selectedData is not None:\n",
    "        x_values = []\n",
    "        print('selectedData', selectedData)\n",
    "        for elements in selectedData['points']:\n",
    "            print('elements', elements)\n",
    "            if 'meta' in elements:\n",
    "                if elements['meta'] not in x_values:\n",
    "                    x_values.append( int(elements['meta']) )\n",
    "        df = df_code.loc[ df_code['Task ID'].isin(x_values) ]\n",
    "    else:\n",
    "        df = df_code\n",
    "    return df.to_dict('records')\n",
    "    \n",
    "#======================================================================\n",
    "# Add Table -> Scatter interactions\n",
    "@app.callback(\n",
    "    Output('graph', 'figure'),\n",
    "    Input('table', 'filter_query'))\n",
    "def update_scatter2(filter_query):\n",
    "    #--------------------------------------------------------------------\n",
    "    # 1. If data was filtered:\n",
    "    if filter_query is not None:\n",
    "        \n",
    "        #--------------------------------------------------------------------\n",
    "        # 1.1. Fetch step ids based on filter query\n",
    "        filtering_expressions = filter_query.split(' && ')\n",
    "        dff = df_code\n",
    "        for filter_part in filtering_expressions:\n",
    "            col_name, operator, filter_value = split_filter_part(filter_part)\n",
    "            if operator in ('eq', 'ne', 'lt', 'le', 'gt', 'ge'):\n",
    "                dff = dff.loc[getattr(dff[col_name], operator)(filter_value)]\n",
    "            elif operator == 'contains':\n",
    "                dff = dff.loc[dff[col_name].str.contains(filter_value)]   \n",
    "            elif operator == 'datestartswith':\n",
    "                dff = dff.loc[dff[col_name].str.startswith(filter_value)]\n",
    "        step_list = list(dff['Task ID'])\n",
    "        \n",
    "        #--------------------------------------------------------------------\n",
    "        # 1.2 Select figure traces that are in the filtered data\n",
    "        selected_points = []\n",
    "        fig_data = fig_net['data']\n",
    "        for i in range(len(fig_data)):\n",
    "            meta = fig_data[i]['meta']\n",
    "            print('=============================================')\n",
    "            print(i)\n",
    "            print(fig_data[i])\n",
    "            \n",
    "            if isinstance(meta, int):\n",
    "                if meta in step_list:\n",
    "                    selected_points.append(i)\n",
    "        print(selected_points)\n",
    "        \n",
    "        #--------------------------------------------------------------------\n",
    "        # 1.3. Update figure\n",
    "        fig_net.update_traces(selectedpoints = selected_points)\n",
    "    \n",
    "    return fig_net\n",
    "\n",
    "#======================================================================\n",
    "app.run_server(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb0e14f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
